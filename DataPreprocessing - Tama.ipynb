{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "listOfFileNames = []\n",
    "listOfClassNames = []\n",
    "listOfDataPerClass = []\n",
    "files = []\n",
    "classNames = []\n",
    "\n",
    "classNames = glob.glob(\"/Users/user/Desktop/datathesis/placeholder/*\")\n",
    "\n",
    "for c in classNames:\n",
    "    className = c.split(\"\\\\\")[1]\n",
    "    listOfClassNames.append(c.split(\"\\\\\")[1])\n",
    "    files = glob.glob(\"/Users/user/Desktop/Thesis/placeholder/\"+className+\"/*.csv\")\n",
    "    listOfFileNames = []\n",
    "    for f in files:\n",
    "        listOfFileNames.append(f.split(\"\\\\\")[1])\n",
    "    listOfDataPerClass.append(listOfFileNames)\n",
    "\n",
    "    \n",
    "#listOfClassNames\n",
    "#listOfDataPerClass[0]\n",
    "print(\"Done listing the class and file names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notfirstday = []\n",
    "for i in listOfClassNames:\n",
    "    if i not in firstDay:\n",
    "        notfirstday.append(i)\n",
    "\n",
    "notsday = []\n",
    "for i in notfirstday:\n",
    "    if i not in secondDay1:\n",
    "        notsday.append(i)\n",
    "        \n",
    "notsday2 = []\n",
    "for i in notsday:\n",
    "    if i not in secondDay2:\n",
    "        notsday2.append(i)\n",
    "\n",
    "nottday = []\n",
    "for i in notsday2:\n",
    "    if i not in thirdDay:\n",
    "        nottday.append(i)\n",
    "\n",
    "print(nottday)\n",
    "print(len(listOfClassNames))\n",
    "\n",
    "print(len(firstDay))\n",
    "print(len(secondDay1))\n",
    "print(len(secondDay2))\n",
    "print(len(thirdDay))\n",
    "print(len(firstDay)+len(secondDay1)+len(secondDay2)+len(thirdDay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(listOfDataPerClass)\n",
    "#listOfDataPerClass[3]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "listOfDataFramesPerClass = {}\n",
    "dataFrameDictionary = {}\n",
    "dataFrames = []\n",
    "\n",
    "for c, d in zip(listOfClassNames, listOfDataPerClass):\n",
    "    print(\"----------------- Word \" + c + \"-----------------\")\n",
    "    emgDataFrames = {}\n",
    "    emgDataFrames['right'] = []\n",
    "    emgDataFrames['left'] = []\n",
    "    \n",
    "    accDataFrames = {}\n",
    "    accDataFrames['right'] = []\n",
    "    accDataFrames['left'] = []\n",
    "\n",
    "    gyroDataFrames = {}\n",
    "    gyroDataFrames['right'] = []\n",
    "    gyroDataFrames['left'] = []\n",
    "\n",
    "    dataFrameDictionary = {}\n",
    "    className = c\n",
    "    leftctr = 0\n",
    "    rightctr = 0\n",
    "    for fileName in d:\n",
    "        fileLocation = \"/Users/user/Desktop/Thesis/placeholder/\"+className+\"/\"+fileName + \"\"\n",
    "        df = pd.read_csv(fileLocation)\n",
    "        \n",
    "        if \"emg\" in fileName:   \n",
    "            if \"-0-\" in fileName:\n",
    "                emgDataFrames['right'].append(df)\n",
    "                leftctr+=1\n",
    "            else:\n",
    "                emgDataFrames['left'].append(df)\n",
    "                rightctr+=1\n",
    "        elif (\"accelerometer\") in fileName:\n",
    "            if \"-0-\" in fileName:\n",
    "                accDataFrames['right'].append(df)\n",
    "                leftctr+=1\n",
    "            else:\n",
    "                accDataFrames['left'].append(df)\n",
    "                rightctr+=1\n",
    "        elif (\"gyro\") in fileName:\n",
    "            if \"-0-\" in fileName:\n",
    "                gyroDataFrames['right'].append(df)\n",
    "                leftctr+=1\n",
    "            else:\n",
    "                gyroDataFrames['left'].append(df)\n",
    "                rightctr+=1\n",
    "    \n",
    "    dataFrameDictionary[\"emg\"] = emgDataFrames\n",
    "    dataFrameDictionary[\"acc\"] = accDataFrames\n",
    "    dataFrameDictionary[\"gyro\"] = gyroDataFrames\n",
    "\n",
    "    listOfDataFramesPerClass[className] = dataFrameDictionary\n",
    "    print(\"Total of \" + str(leftctr) + \" left arm files and \" + str(rightctr) + \" right arm files.\")\n",
    "\n",
    "\n",
    "print(\"Done converting to dataframes!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For EMG Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a in listOfDataFramesPerClass[k]['emg']:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "listOfTrimmedDataFramesPerArm = {}\n",
    "listOfTrimmedDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    trimmedDataFramesPerClass = {}\n",
    "    trimmedDataFramesPerClass['left'] = []\n",
    "    trimmedDataFramesPerClass['right'] = []\n",
    "    \n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['emg']:\n",
    "        for d in listOfDataFramesPerClass[k]['emg'][a]:\n",
    "            keep_col = ['emg1','emg2','emg3','emg4','emg5','emg6','emg7','emg8']\n",
    "            new_df = d[keep_col]\n",
    "            new_df = new_df[:-49]\n",
    "            trimmed_df = new_df.iloc[49:]\n",
    "            if len(trimmed_df) < 100:\n",
    "                print(str(ctr) + \" \" + k)\n",
    "            trimmedDataFramesPerClass[a].append(trimmed_df)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"emg\"] = trimmedDataFramesPerClass\n",
    "    listOfTrimmedDataFramesPerClass[k] = dataFrameDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfTrimmedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    \n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        for d in listOfDataFramesPerClass[k]['emg'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "        print(\"Done Normalizing \" + str(ctr) + a + \" arm files\")\n",
    "    dataFrameDictionary[\"emg\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "\n",
    "listOfVarianceDataFramePerClass = {}\n",
    "listOfVarianceDataFramePerClass['right'] = []\n",
    "listOfVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMavDataFramePerClass = {}\n",
    "listOfMavDataFramePerClass['right'] = []\n",
    "listOfMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMeanDataFramePerClass = {}\n",
    "listOfMeanDataFramePerClass['right'] = []\n",
    "listOfMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfSdDataFramePerClass = {}\n",
    "listOfSdDataFramePerClass['right'] = []\n",
    "listOfSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfRmsDataFramePerClass = {}\n",
    "listOfRmsDataFramePerClass['right'] = []\n",
    "listOfRmsDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        varianceDataFrame = pd.DataFrame(columns = ['Variance of EMG1', 'Variance of EMG2', 'Variance of EMG3', 'Variance of EMG4',\n",
    "                                 'Variance of EMG5', 'Variance of EMG6', 'Variance of EMG7', 'Variance of EMG8'])\n",
    "        mavDataFrame = pd.DataFrame(columns = ['Mav of EMG1', 'Mav of EMG2', 'Mav of EMG3', 'Mav of EMG4',\n",
    "                                     'Mav of EMG5', 'Mav of EMG6', 'Mav of EMG7', 'Mav of EMG8'])\n",
    "        meanDataFrame = pd.DataFrame(columns = ['Mean of EMG1', 'Mean of EMG2', 'Mean of EMG3', 'Mean of EMG4',\n",
    "                                     'Mean of EMG5', 'Mean of EMG6', 'Mean of EMG7', 'Mean of EMG8'])\n",
    "        sdDataFrame = pd.DataFrame(columns = ['Sd of EMG1', 'Sd of EMG2', 'Sd of EMG3', 'Sd of EMG4',\n",
    "                                     'Sd of EMG5', 'Sd of EMG6', 'Sd of EMG7', 'Sd of EMG8'])\n",
    "        rmsDataFrame = pd.DataFrame(columns = ['Rms of EMG1', 'Rms of EMG2', 'Rms of EMG3', 'Rms of EMG4',\n",
    "                                     'Rms of EMG5', 'Rms of EMG6', 'Rms of EMG7', 'Rms of EMG8'])\n",
    "        for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg'][a]:\n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[0], df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3], df_normalized.var()[4], df_normalized.var()[5], df_normalized.var()[6], df_normalized.var()[7]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[0], robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3], robust.mad(df_normalized)[4], robust.mad(df_normalized)[5], robust.mad(df_normalized)[6], robust.mad(df_normalized)[7]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[0], np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3], np.mean(df_normalized)[4], np.mean(df_normalized)[5], np.mean(df_normalized)[6], np.mean(df_normalized)[7]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[0], np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3], np.std(df_normalized)[4], np.std(df_normalized)[5], np.std(df_normalized)[6], np.std(df_normalized)[7]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[0].values**2)), np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2)), np.sqrt(np.mean(df_normalized[4].values**2)), np.sqrt(np.mean(df_normalized[5].values**2)), robust.mad(df_normalized)[6], np.sqrt(np.mean(df_normalized[7].values**2))]\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "    \n",
    "        print(\"Done computing the var, mav, mean , sd, and rms of \" + str(ctr) + a + \" arm files\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mean and Median Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "listOfMeanFreqDataFramePerClass = {}\n",
    "listOfMeanFreqDataFramePerClass['right'] = []\n",
    "listOfMeanFreqDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMedFreqDataFramePerClass = {}\n",
    "listOfMedFreqDataFramePerClass['right'] = []\n",
    "listOfMedFreqDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    \n",
    "    for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        meanFreqDataFrame = pd.DataFrame(columns = ['MeanFreq of EMG1', 'MeanFreq of EMG2', 'MeanFreq of EMG3', 'MeanFreq of EMG4',\n",
    "                                 'MeanFreq of EMG5', 'MeanFreq of EMG6', 'MeanFreq of EMG7', 'MeanFreq of EMG8']) \n",
    "\n",
    "        medFreqDataFrame = pd.DataFrame(columns = ['MedianFreq of EMG1', 'MedianFreq of EMG2', 'MedianFreq of EMG3', 'MedianFreq of EMG4',\n",
    "                                     'MedianFreq of EMG5', 'MedianFreq of EMG6', 'MedianFreq of EMG7', 'MedianFreq of EMG8'])\n",
    "\n",
    "        for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg'][a]:\n",
    "            meanFreq = []\n",
    "            medFreq = []\n",
    "\n",
    "            for i in range(0, 8):\n",
    "                data = df_normalized[i].values\n",
    "                ps = np.abs(np.fft.fft(data))**2\n",
    "\n",
    "                freqs = np.fft.fftfreq(data.size, 1/100)\n",
    "\n",
    "                sumProd = 0\n",
    "                sumPs = 0\n",
    "\n",
    "                for f, p in zip(freqs,ps):\n",
    "                    sumProd += f*p\n",
    "                    sumPs += p\n",
    "\n",
    "                meanFreq.append(sumProd/sumPs)\n",
    "                medFreq.append(sumPs/2)\n",
    "\n",
    "            meanFreqDataFrame.loc[ctr] = [meanFreq[0], meanFreq[1], meanFreq[2], meanFreq[3], meanFreq[4], meanFreq[5], meanFreq[6], meanFreq[7]]\n",
    "            medFreqDataFrame.loc[ctr] = [medFreq[0], medFreq[1], medFreq[2], medFreq[3], medFreq[4], medFreq[5], medFreq[6], medFreq[7]]\n",
    "\n",
    "            ctr+=1\n",
    "        listOfMeanFreqDataFramePerClass[a].append(meanFreqDataFrame)\n",
    "        listOfMedFreqDataFramePerClass[a].append(medFreqDataFrame)\n",
    "        print(\"Done computing Mean and Median Frequency of \" + str(ctr) + a + \" arm files\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "ctr = 0\n",
    "\n",
    "listOfLabeledDataPerClass = {}\n",
    "listOfLabeledDataPerClass['right'] = {}\n",
    "listOfLabeledDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "\n",
    "    dataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfTrimmedDataFramesPerClass.keys():\n",
    "        dataFramesPerFeature['variance'] = listOfVarianceDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['mav'] = listOfMavDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['rms'] = listOfRmsDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['sd'] = listOfSdDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['mean'] = listOfMeanDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['medFreq'] = listOfMedFreqDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['meanFreq'] = listOfMeanFreqDataFramePerClass[a][ctr]\n",
    "    \n",
    "\n",
    "        for k2 in dataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in dataFramesPerFeature[k2].columns:\n",
    "                    dataFramesPerFeature['variance'][i] = dataFramesPerFeature[k2][i]\n",
    "        \n",
    "        dataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledDataPerClass[a][k] = dataFramesPerFeature['variance']\n",
    "        print(\"Done labeling emg data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Consolidation (save to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "    newDf = listOfLabeledDataPerClass[a]['ano']\n",
    "    for k in listOfTrimmedDataFramesPerClass.keys():\n",
    "        if k != 'ano':\n",
    "            print(k)\n",
    "            newDf= newDf.append(listOfLabeledDataPerClass[a][k])\n",
    "    newDf.to_csv('/Users/user/Desktop/'+ a + 'ArmConsolidatedEMG.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For IMU values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming (For Acceleration and Gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listOfDataFramesPerClass['isa']['gyro']['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "listOfTrimmedAccDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    trimmedDataFramesPerClass = {}\n",
    "    trimmedDataFramesPerClass['left'] = []\n",
    "    trimmedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "    \n",
    "    for a in listOfDataFramesPerClass[k]['emg']:\n",
    "        for d in listOfDataFramesPerClass[k]['acc'][a]:\n",
    "            keep_col = ['x','y','z']\n",
    "            new_df = d[keep_col]\n",
    "            new_df = new_df[:-24]\n",
    "            trimmed_df = new_df.iloc[24:]\n",
    "            if len(trimmed_df) < 50:\n",
    "                print(str(ctr) + \" \" + str(len(trimmed_df)))\n",
    "            trimmedDataFramesPerClass[a].append(trimmed_df)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"acc\"] = trimmedDataFramesPerClass\n",
    "    listOfTrimmedAccDataFramesPerClass[k] = dataFrameDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "listOfTrimmedGyroDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    trimmedDataFramesPerClass = {}\n",
    "    trimmedDataFramesPerClass['left'] = []\n",
    "    trimmedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "    \n",
    "    for a in listOfDataFramesPerClass[k]['gyro']:\n",
    "        for d in listOfDataFramesPerClass[k]['gyro'][a]:\n",
    "            keep_col = ['x','y','z']\n",
    "            new_df = d[keep_col]\n",
    "            new_df = new_df[:-24]\n",
    "            trimmed_df = new_df.iloc[24:]\n",
    "            if len(trimmed_df) < 50:\n",
    "                print(str(ctr) + \" \" + str(len(trimmed_df)))\n",
    "            trimmedDataFramesPerClass[a].append(trimmed_df)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"gyro\"] = trimmedDataFramesPerClass\n",
    "    listOfTrimmedGyroDataFramesPerClass[k] = dataFrameDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization (For Acceleration and Gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedAccDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['gyro']:\n",
    "        for d in listOfTrimmedAccDataFramesPerClass[k]['acc'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"acc\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedAccDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedGyroDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfTrimmedGyroDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['gyro']:\n",
    "        for d in listOfTrimmedGyroDataFramesPerClass[k]['gyro'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"gyro\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedGyroDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "\n",
    "listOfLabeledAccDataPerClass = {}\n",
    "listOfLabeledImuDataPerClass['right'] = {}\n",
    "listOfLabeledImuDataPerClass['left'] = {}\n",
    "\n",
    "for p in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "\n",
    "    for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "        ctr = 0\n",
    "\n",
    "        labeledDataFramePerClass = []\n",
    "        labeledDataFrame = pd.DataFrame(columns = ['X of Accelerometer', 'Y of Accelerometer', 'Z of Accelerometer', \n",
    "                                                   'X of Gyroscope', 'Y of Gyroscope', 'Z of Gyroscope', 'Class'])\n",
    "        \n",
    "        for a, g in zip(listOfNormalizedAccDataFramesPerClass[k]['acc'][p], listOfNormalizedGyroDataFramesPerClass[k]['gyro'][p]):\n",
    "            xAV = a[0].values\n",
    "            yAV = a[1].values\n",
    "            zAV = a[2].values\n",
    "            xGV = g[2].values\n",
    "            yGV = g[2].values\n",
    "            zGV = g[2].values\n",
    "                        \n",
    "            \n",
    "            for x, y, z, xG, yG, zG in zip(xAV, yAV, zAV, xGV, yGV, zGV):\n",
    "                #print(str(x) + \" \" + str(y) + \" \" +str(z))\n",
    "                labeledDataFrame.loc[ctr] = [x, y, z, xG, yG, zG, k]\n",
    "                ctr+=1\n",
    "            print(ctr)\n",
    "\n",
    "        listOfLabeledImuDataPerClass[p][k] = labeledDataFrame\n",
    "        print(\"Done labeling \" + p +\" imu data of \" + k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listOfLabeledImuDataPerClass['left']['ano']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "\n",
    "listOfLabeledImuDataPerClass = {}\n",
    "listOfLabeledImuDataPerClass['right'] = {}\n",
    "listOfLabeledImuDataPerClass['left'] = {}\n",
    "\n",
    "for p in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "\n",
    "    for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "        ctr = 0\n",
    "\n",
    "        labeledDataFramePerClass = []\n",
    "        labeledDataFrame = pd.DataFrame(columns = ['X of Accelerometer', 'Y of Accelerometer', 'Z of Accelerometer', \n",
    "                                                   'X of Gyroscope', 'Y of Gyroscope', 'Z of Gyroscope', 'Class'])\n",
    "        \n",
    "        for a, g in zip(listOfNormalizedAccDataFramesPerClass[k]['acc'][p],listOfNormalizedGyroDataFramesPerClass[k]['gyro'][p]):\n",
    "            \n",
    "            for i in range(0, len(a[0])):\n",
    "                labeledDataFrame.loc[ctr] = [a[0][i], a[1][i], a[2][i], g[0][i], g[1][i], g[2][i], k]\n",
    "                ctr+=1\n",
    "            \n",
    "\n",
    "        listOfLabeledImuDataPerClass[p][k] = labeledDataFrame\n",
    "        print(\"Done labeling \" + p +\" imu data of \" + k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Consolidation (save to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "    newDf = listOfLabeledImuDataPerClass[a]['ano']\n",
    "    for k in listOfTrimmedDataFramesPerClass.keys():\n",
    "        if k != 'ano':\n",
    "            print(k)\n",
    "            newDf= newDf.append(listOfLabeledImuDataPerClass[a][k])\n",
    "    newDf.to_csv('/Users/user/Desktop/'+ a +'ArmConsolidatedIMU.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "listOfFileNames = []\n",
    "listOfClassNames = []\n",
    "listOfDataPerClass = []\n",
    "files = []\n",
    "classNames = []\n",
    "\n",
    "files = glob.glob(\"/Users/user/Desktop/datathesis/placeholder/hello/*.csv\")\n",
    "print(len(files))\n",
    "listOfFileNames = []\n",
    "for f in files:\n",
    "    listOfFileNames.append(f.split(\"\\\\\")[1])\n",
    "    \n",
    "emgDataFrames = {}\n",
    "emgDataFrames['right'] = []\n",
    "emgDataFrames['left'] = []\n",
    "    \n",
    "accDataFrames = {}\n",
    "accDataFrames['right'] = []\n",
    "accDataFrames['left'] = []\n",
    "\n",
    "gyroDataFrames = {}\n",
    "gyroDataFrames['right'] = []\n",
    "gyroDataFrames['left'] = []\n",
    "\n",
    "dataFrameDictionary = {}\n",
    "leftctr = 0\n",
    "rightctr = 0\n",
    "print(len(listOfFileNames))\n",
    "for fileName in listOfFileNames:\n",
    "    fileLocation = \"/Users/user/Desktop/datathesis/placeholder/hello/\"+fileName \n",
    "    #print(fileLocation)\n",
    "    df = pd.read_csv(fileLocation)\n",
    "    \n",
    "    if \"emg\" in fileName:   \n",
    "        if \"-0-\" in fileName:\n",
    "            emgDataFrames['right'].append(df)\n",
    "            leftctr+=1\n",
    "        else:\n",
    "            emgDataFrames['left'].append(df)\n",
    "            rightctr+=1\n",
    "    elif (\"accelerometer\") in fileName:\n",
    "        if \"-0-\" in fileName:\n",
    "            accDataFrames['right'].append(df)\n",
    "            leftctr+=1\n",
    "        else:\n",
    "            accDataFrames['left'].append(df)\n",
    "            rightctr+=1\n",
    "    elif (\"gyro\") in fileName:\n",
    "        if \"-0-\" in fileName:\n",
    "            gyroDataFrames['right'].append(df)\n",
    "            leftctr+=1\n",
    "        else:\n",
    "            gyroDataFrames['left'].append(df)      \n",
    "            rightctr+=1\n",
    "\n",
    "print(\"Total of \" + str(leftctr) + \" left arm files and \" + str(rightctr) + \" right arm files.\")\n",
    "\n",
    "    \n",
    "#listOfClassNames\n",
    "#listOfDataPerClass[0]\n",
    "print(\"Done listing the class and file names\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
