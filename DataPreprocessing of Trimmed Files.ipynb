{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "listOfFileNames = []\n",
    "listOfClassNames = []\n",
    "listOfDataPerClass = []\n",
    "files = []\n",
    "classNames = []\n",
    "#path = \"/Users/user/Desktop/asd/thesis/placeholder/\"\n",
    "#path = \"/Users/user/Desktop/pinakalatest/thesis/placeholder/\"\n",
    "path = \"trimmed_data/\"\n",
    "classNames = glob.glob(path + \"*\")\n",
    "\n",
    "for c in classNames:\n",
    "    className = c.split(\"\\\\\")[1]\n",
    "    listOfClassNames.append(c.split(\"\\\\\")[1])\n",
    "    files = glob.glob(path + className+\"/*\") \n",
    "    listOfFileNames = []\n",
    "    for f in files:\n",
    "        listOfFileNames.append(f.split(\"\\\\\")[1])\n",
    "        \n",
    "    listOfDataPerClass.append(listOfFileNames)\n",
    "\n",
    "    \n",
    "#listOfClassNames\n",
    "#listOfDataPerClass[0]\n",
    "print(\"Done listing the class and file names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#len(listOfDataPerClass)\n",
    "#listOfDataPerClass[3]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "listOfDataFramesPerClass = {}\n",
    "dataFrameDictionary = {}\n",
    "dataFrames = []\n",
    "\n",
    "# firstDay = ['mayroon', 'kayo', 'black', 'ano', 'niyo', 'kape', 'magkano', 'bibili', 'oras', 'tubig', 'maliit(thing)', \n",
    "#             'kulay', 'isa', 'dito', 'pagkain']\n",
    "# secondDay = ['nagbubukas', 'ate', 'isda', 'itlog', 'kuya', 'baboy', 't-shirt', 'blue', 'wala', 'dalawa', 'tatlo', 'nagsasara', 'shorts', 'red', 'mahal', \n",
    "#               'tawad', 'small(shirt)', 'medium(shirt)', 'large(shirt)', 'sari-sari-store', 'mantika', 'juice', 'size']\n",
    "# thirdDay = ['saging', 'nito', 'kanin', 'ito', 'spaghetti', 'gusto', 'tinapay', 'manok', 'poloshirt', 'extra', 'kilo', 'salamat', 'binebenta', 'puwede', 'welcome', 'utang', 'gulay',\n",
    "#            'softdrinks', 'sorry', 'hello', 'malaki', 'supot(plastik)']\n",
    "\n",
    "for c, d in zip(listOfClassNames, listOfDataPerClass):\n",
    "    print(\"----------------- Word \" + c + \"-----------------\")\n",
    "    emgDataFrames = {}\n",
    "    emgDataFrames['right'] = []\n",
    "    emgDataFrames['left'] = []\n",
    "    \n",
    "    accDataFrames = {}\n",
    "    accDataFrames['right'] = []\n",
    "    accDataFrames['left'] = []\n",
    "\n",
    "    gyroDataFrames = {}\n",
    "    gyroDataFrames['right'] = []\n",
    "    gyroDataFrames['left'] = []\n",
    "\n",
    "    dataFrameDictionary = {}\n",
    "    className = c\n",
    "    emgleftctr = 0\n",
    "    emgrightctr = 0\n",
    "    accleftctr = 0\n",
    "    accrightctr = 0\n",
    "    gyroleftctr = 0\n",
    "    gyrorightctr = 0\n",
    "    for fileName in d:\n",
    "        fileLocation = path + className + \"/\" + fileName + \"\"\n",
    "        #print(fileLocation)\n",
    "        df = pd.read_csv(fileLocation)\n",
    "\n",
    "        if \"emg\" in fileName:   \n",
    "            if \"-Right\" in fileName:\n",
    "                emgDataFrames['right'].append(df)\n",
    "                emgrightctr+=1\n",
    "            else:\n",
    "                emgDataFrames['left'].append(df)\n",
    "                emgleftctr+=1\n",
    "        elif (\"acc\") in fileName:\n",
    "            if \"-Right\" in fileName:\n",
    "                accDataFrames['right'].append(df)\n",
    "                accrightctr+=1\n",
    "            else:\n",
    "                accDataFrames['left'].append(df)\n",
    "                accleftctr+=1\n",
    "        elif (\"gyro\") in fileName:\n",
    "            if \"-Right\" in fileName:\n",
    "                gyroDataFrames['right'].append(df)\n",
    "                gyrorightctr+=1\n",
    "            else:\n",
    "                gyroDataFrames['left'].append(df)\n",
    "                gyroleftctr+=1\n",
    "    \n",
    "    dataFrameDictionary[\"emg\"] = emgDataFrames\n",
    "    dataFrameDictionary[\"acc\"] = accDataFrames\n",
    "    dataFrameDictionary[\"gyro\"] = gyroDataFrames\n",
    "\n",
    "    listOfDataFramesPerClass[className] = dataFrameDictionary\n",
    "    print(\"Total of \" + str(emgleftctr) + \" left arm emg files and \" + str(emgrightctr) + \" right arm emg files.\")\n",
    "    print(\"Total of \" + str(accleftctr) + \" left arm acc files and \" + str(accrightctr) + \" right arm acc files.\")\n",
    "    print(\"Total of \" + str(gyroleftctr) + \" left arm gyro files and \" + str(gyrorightctr) + \" right arm gyro files.\")\n",
    "\n",
    "\n",
    "print(\"Done converting to dataframes!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For EMG Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# listOfTrimmedDataFramesPerClass = {}\n",
    "\n",
    "# for k in listOfDataFramesPerClass.keys():\n",
    "#     print(\"----------------- Word \" + k + \"-----------------\")\n",
    "#     ctr = 0\n",
    "#     trimmedDataFramesPerClass = {}\n",
    "#     trimmedDataFramesPerClass['left'] = []\n",
    "#     trimmedDataFramesPerClass['right'] = []\n",
    "    \n",
    "#     dataFrameDictionary = {}\n",
    "\n",
    "#     for a in listOfDataFramesPerClass[k]['emg']:\n",
    "#         for d in listOfDataFramesPerClass[k]['emg'][a]:\n",
    "# #             keep_col = ['emg1','emg2','emg3','emg4','emg5','emg6','emg7','emg8']\n",
    "# #             new_df = d[keep_col]\n",
    "#             new_df = d\n",
    "#             new_df = new_df[:-49]\n",
    "#             trimmed_df = new_df.iloc[49:]\n",
    "#             if len(trimmed_df) < 100:\n",
    "#                 print(str(ctr) + \" \" + k)\n",
    "#             trimmedDataFramesPerClass[a].append(trimmed_df)\n",
    "#             ctr += 1\n",
    "        \n",
    "#     print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "#     dataFrameDictionary[\"emg\"] = trimmedDataFramesPerClass\n",
    "#     listOfTrimmedDataFramesPerClass[k] = dataFrameDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    \n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        for d in listOfDataFramesPerClass[k]['emg'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "\n",
    "        print(\"Done Normalizing \" + str(ctr) + a + \" arm files\")\n",
    "    dataFrameDictionary[\"emg\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "\n",
    "listOfVarianceDataFramePerClass = {}\n",
    "listOfVarianceDataFramePerClass['right'] = []\n",
    "listOfVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMavDataFramePerClass = {}\n",
    "listOfMavDataFramePerClass['right'] = []\n",
    "listOfMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMeanDataFramePerClass = {}\n",
    "listOfMeanDataFramePerClass['right'] = []\n",
    "listOfMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfSdDataFramePerClass = {}\n",
    "listOfSdDataFramePerClass['right'] = []\n",
    "listOfSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfRmsDataFramePerClass = {}\n",
    "listOfRmsDataFramePerClass['right'] = []\n",
    "listOfRmsDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "\n",
    "    for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm + 'variance of EMG1'), (arm + 'variance of EMG2'), (arm + 'variance of EMG3'), (arm + 'variance of EMG4'),\n",
    "                                 (arm + 'variance of EMG5'), (arm + 'variance of EMG6'), (arm + 'variance of EMG7'), (arm + 'variance of EMG8')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm + 'Mav of EMG1'), (arm + 'Mav of EMG2'), (arm + 'Mav of EMG3'), (arm + 'Mav of EMG4'),\n",
    "                                     (arm + 'Mav of EMG5'), (arm + 'Mav of EMG6'), (arm + 'Mav of EMG7'), (arm + 'Mav of EMG8')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm + 'Mean of EMG1'), (arm + 'Mean of EMG2'), (arm + 'Mean of EMG3'), (arm + 'Mean of EMG4'),\n",
    "                                     (arm + 'Mean of EMG5'), (arm + 'Mean of EMG6'), (arm + 'Mean of EMG7'), (arm + 'Mean of EMG8')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm + 'Sd of EMG1'), (arm + 'Sd of EMG2'), (arm + 'Sd of EMG3'), (arm + 'Sd of EMG4'),\n",
    "                                     (arm + 'Sd of EMG5'), (arm + 'Sd of EMG6'), (arm + 'Sd of EMG7'), (arm + 'Sd of EMG8')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm + 'Rms of EMG1'), (arm + 'Rms of EMG2'), (arm + 'Rms of EMG3'), (arm + 'Rms of EMG4'),\n",
    "                                     (arm + 'Rms of EMG5'), (arm + 'Rms of EMG6'), (arm + 'Rms of EMG7'), (arm + 'Rms of EMG8')])\n",
    "        for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg'][a]:\n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3], df_normalized.var()[4], df_normalized.var()[5], df_normalized.var()[6], df_normalized.var()[7], df_normalized.var()[8]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3], robust.mad(df_normalized)[4], robust.mad(df_normalized)[5], robust.mad(df_normalized)[6], robust.mad(df_normalized)[7], robust.mad(df_normalized)[8]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3], np.mean(df_normalized)[4], np.mean(df_normalized)[5], np.mean(df_normalized)[6], np.mean(df_normalized)[7], np.mean(df_normalized)[8]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3], np.std(df_normalized)[4], np.std(df_normalized)[5], np.std(df_normalized)[6], np.std(df_normalized)[7], np.std(df_normalized)[8]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2)), np.sqrt(np.mean(df_normalized[4].values**2)), np.sqrt(np.mean(df_normalized[5].values**2)), np.sqrt(np.mean(df_normalized[6].values**2)), robust.mad(df_normalized)[7], np.sqrt(np.mean(df_normalized[8].values**2))]\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "    \n",
    "        print(\"Done computing the var, mav, mean , sd, and rms of \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing emg features!\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mean and Median Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "listOfMeanFreqDataFramePerClass = {}\n",
    "listOfMeanFreqDataFramePerClass['right'] = []\n",
    "listOfMeanFreqDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMedFreqDataFramePerClass = {}\n",
    "listOfMedFreqDataFramePerClass['right'] = []\n",
    "listOfMedFreqDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    \n",
    "    for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        meanFreqDataFrame = pd.DataFrame(columns = [(arm + 'MeanFreq of EMG1'), (arm + 'MeanFreq of EMG2'), (arm + 'MeanFreq of EMG3'), (arm + 'MeanFreq of EMG4'),\n",
    "                                 (arm + 'MeanFreq of EMG5'), (arm + 'MeanFreq of EMG6'), (arm + 'MeanFreq of EMG7'), (arm + 'MeanFreq of EMG8')]) \n",
    "\n",
    "        medFreqDataFrame = pd.DataFrame(columns = [(arm + 'MedianFreq of EMG1'), (arm + 'MedianFreq of EMG2'), (arm + 'MedianFreq of EMG3'), (arm + 'MedianFreq of EMG4'),\n",
    "                                     (arm + 'MedianFreq of EMG5'), (arm + 'MedianFreq of EMG6'), (arm + 'MedianFreq of EMG7'), (arm + 'MedianFreq of EMG8')])\n",
    "\n",
    "        for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg'][a]:\n",
    "            meanFreq = []\n",
    "            medFreq = []\n",
    "\n",
    "            for i in range(1, 9):\n",
    "                data = df_normalized[i].values\n",
    "                ps = np.abs(np.fft.fft(data))**2\n",
    "\n",
    "                freqs = np.fft.fftfreq(data.size, 1/100)\n",
    "\n",
    "                sumProd = 0\n",
    "                sumPs = 0\n",
    "\n",
    "                for f, p in zip(freqs,ps):\n",
    "                    sumProd += f*p\n",
    "                    sumPs += p\n",
    "\n",
    "                meanFreq.append(sumProd/sumPs)\n",
    "                medFreq.append(sumPs/2)\n",
    "                \n",
    "#             if k == \"tatlo\":\n",
    "#                 print(ctr)\n",
    "            \n",
    "            meanFreqDataFrame.loc[ctr] = [meanFreq[0], meanFreq[1], meanFreq[2], meanFreq[3], meanFreq[4], meanFreq[5], meanFreq[6], meanFreq[7]]\n",
    "            medFreqDataFrame.loc[ctr] = [medFreq[0], medFreq[1], medFreq[2], medFreq[3], medFreq[4], medFreq[5], medFreq[6], medFreq[7]]\n",
    "\n",
    "            ctr+=1\n",
    "        listOfMeanFreqDataFramePerClass[a].append(meanFreqDataFrame)\n",
    "        listOfMedFreqDataFramePerClass[a].append(medFreqDataFrame)\n",
    "        print(\"Done computing Mean and Median Frequency of \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing emg features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "\n",
    "listOfLabeledDataPerClass = {}\n",
    "listOfLabeledDataPerClass['right'] = {}\n",
    "listOfLabeledDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "\n",
    "    dataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        dataFramesPerFeature['variance'] = listOfVarianceDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['mav'] = listOfMavDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['rms'] = listOfRmsDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['sd'] = listOfSdDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['mean'] = listOfMeanDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['medFreq'] = listOfMedFreqDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['meanFreq'] = listOfMeanFreqDataFramePerClass[a][ctr]\n",
    "    \n",
    "\n",
    "        for k2 in dataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in dataFramesPerFeature[k2].columns:\n",
    "                    dataFramesPerFeature['variance'][i] = dataFramesPerFeature[k2][i]\n",
    "        \n",
    "        dataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledDataPerClass[a][k] = dataFramesPerFeature['variance']\n",
    "        print(\"Done labeling emg data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For IMU values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming (For Acceleration and Gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# listOfTrimmedAccDataFramesPerClass = {}\n",
    "\n",
    "# for k in listOfDataFramesPerClass.keys():\n",
    "#     print(\"----------------- Word \" + k + \"-----------------\")\n",
    "#     ctr = 0\n",
    "#     trimmedDataFramesPerClass = {}\n",
    "#     trimmedDataFramesPerClass['left'] = []\n",
    "#     trimmedDataFramesPerClass['right'] = []\n",
    "#     dataFrameDictionary = {}\n",
    "    \n",
    "#     for a in listOfDataFramesPerClass[k]['emg']:\n",
    "#         for d in listOfDataFramesPerClass[k]['acc'][a]:\n",
    "# #             keep_col = ['x','y','z']\n",
    "# #             new_df = d[keep_col]\n",
    "#             new_df = d\n",
    "#             new_df = new_df[:-24]\n",
    "#             trimmed_df = new_df.iloc[24:]\n",
    "#             if len(trimmed_df) < 50:\n",
    "#                 print(str(ctr) + \" \" + str(len(trimmed_df)))\n",
    "#             trimmedDataFramesPerClass[a].append(trimmed_df)\n",
    "#             ctr += 1\n",
    "        \n",
    "#     print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "#     dataFrameDictionary[\"acc\"] = trimmedDataFramesPerClass\n",
    "#     listOfTrimmedAccDataFramesPerClass[k] = dataFrameDictionary\n",
    "    \n",
    "# print(\"Done Trimming Acc data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# listOfTrimmedGyroDataFramesPerClass = {}\n",
    "# #\n",
    "# for k in listOfDataFramesPerClass.keys():\n",
    "#     print(\"----------------- Word \" + k + \"-----------------\")\n",
    "#     ctr = 0\n",
    "#     trimmedDataFramesPerClass = {}\n",
    "#     trimmedDataFramesPerClass['left'] = []\n",
    "#     trimmedDataFramesPerClass['right'] = []\n",
    "#     dataFrameDictionary = {}\n",
    "    \n",
    "#     for a in listOfDataFramesPerClass[k]['gyro']:\n",
    "#         for d in listOfDataFramesPerClass[k]['gyro'][a]:\n",
    "# #             keep_col = ['x','y','z']\n",
    "# #             new_df = d[keep_col]\n",
    "#             new_df = d\n",
    "#             new_df = new_df[:-24]\n",
    "#             trimmed_df = new_df.iloc[24:]\n",
    "#             if len(trimmed_df) < 50:\n",
    "#                 print(str(ctr) + \" \" + str(len(trimmed_df)))\n",
    "#             trimmedDataFramesPerClass[a].append(trimmed_df)\n",
    "#             ctr += 1\n",
    "        \n",
    "#     print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "#     dataFrameDictionary[\"gyro\"] = trimmedDataFramesPerClass\n",
    "#     listOfTrimmedGyroDataFramesPerClass[k] = dataFrameDictionary\n",
    "    \n",
    "# print(\"Done Trimming Gyro data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization (For Acceleration and Gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedAccDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['acc']:\n",
    "        for d in listOfDataFramesPerClass[k]['acc'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"acc\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedAccDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Acc Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#listOfDataFramesPerClass['ate']['acc']['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedGyroDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['gyro']:\n",
    "        for d in listOfDataFramesPerClass[k]['gyro'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"gyro\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedGyroDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Gyro Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "#kurtosis\n",
    "#standarddev\n",
    "#mean\n",
    "#variance\n",
    "#entropy\n",
    "#meanabsval\n",
    "#rootmeansquare\n",
    "#Signal Magnitude Area\n",
    "#Integration\n",
    "\n",
    "listOfGyroVarianceDataFramePerClass = {}\n",
    "listOfGyroVarianceDataFramePerClass['right'] = []\n",
    "listOfGyroVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroMavDataFramePerClass = {}\n",
    "listOfGyroMavDataFramePerClass['right'] = []\n",
    "listOfGyroMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroMeanDataFramePerClass = {}\n",
    "listOfGyroMeanDataFramePerClass['right'] = []\n",
    "listOfGyroMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSdDataFramePerClass = {}\n",
    "listOfGyroSdDataFramePerClass['right'] = []\n",
    "listOfGyroSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroRmsDataFramePerClass = {}\n",
    "listOfGyroRmsDataFramePerClass['right'] = []\n",
    "listOfGyroRmsDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroEntropyDataFramePerClass = {}\n",
    "listOfGyroEntropyDataFramePerClass['right'] = []\n",
    "listOfGyroEntropyDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroKurtosisDataFramePerClass = {}\n",
    "listOfGyroKurtosisDataFramePerClass['right'] = []\n",
    "listOfGyroKurtosisDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSkewnessDataFramePerClass = {}\n",
    "listOfGyroSkewnessDataFramePerClass['right'] = []\n",
    "listOfGyroSkewnessDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSmaDataFramePerClass = {}\n",
    "listOfGyroSmaDataFramePerClass['right'] = []\n",
    "listOfGyroSmaDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroIntegrationDataFramePerClass = {}\n",
    "listOfGyroIntegrationDataFramePerClass['right'] = []\n",
    "listOfGyroIntegrationDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedGyroDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm + 'Variance of Gyro x'), (arm+ 'Variance of Gyro y'), (arm+ 'Variance of Gyro z')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm+ 'Mav of Gyro x'), (arm+ 'Mav of Gyro y'), (arm+ 'Mav of Gyro z')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm+ 'Mean of Gyro x'), (arm+ 'Mean of Gyro y'), (arm+ 'Mean of Gyro z')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm+ 'Sd of Gyro x'), (arm+ 'Sd of Gyro y'), (arm+ 'Sd of Gyro z')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm+ 'Rms of Gyro x'), (arm+ 'Rms of Gyro y'), (arm+ 'Rms of Gyro z')])\n",
    "        entropyDataFrame = pd.DataFrame(columns = [(arm+ 'Entropy of Gyro x'), (arm+ 'Entropy of Gyro y'), (arm+ 'Entropy of Gyro z')])\n",
    "        kurtosisDataFrame = pd.DataFrame(columns = [(arm+ 'Kurtosis of Gyro x'), (arm+ 'Kurtosis of Gyro y'), (arm+ 'Kurtosis of Gyro z')])\n",
    "        skewnessDataFrame = pd.DataFrame(columns = [(arm+ 'Skewness of Gyro x'), (arm+ 'Skewness of Gyro y'), (arm+ 'Skewness of Gyro z')])\n",
    "        smaDataFrame = pd.DataFrame(columns = [(arm+ 'SMA of Gyro')])\n",
    "        integrationDataFrame = pd.DataFrame(columns = [(arm+ 'Integration of Gyro x'), (arm+ 'Integration of Gyro y'), (arm+ 'Integration of Gyro z')])\n",
    "\n",
    "        \n",
    "        for df_normalized in listOfNormalizedGyroDataFramesPerClass[k]['gyro'][a]:\n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2))]\n",
    "            entropyDataFrame.loc[ctr] = [sp.stats.entropy(df_normalized)[1], sp.stats.entropy(df_normalized)[2], sp.stats.entropy(df_normalized)[3],]\n",
    "            kurtosisDataFrame.loc[ctr] = [df_normalized.kurtosis()[1], df_normalized.kurtosis()[2], df_normalized.kurtosis()[3]]\n",
    "            skewnessDataFrame.loc[ctr] = [df_normalized.skew(axis=0)[1], df_normalized.skew(axis=0)[2], df_normalized.skew(axis=0)[3]]\n",
    "            length = df_normalized.shape[1]\n",
    "            sma = 0\n",
    "            for x in range(0, length):\n",
    "                # .iloc[x,0] is Gyroessing row, column\n",
    "                sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "            sma = sma / length\n",
    "            smaDataFrame.loc[ctr] = [sma]\n",
    "            integrationDataFrame.loc[ctr] = [sp.integrate.simps(df_normalized, axis=0)[1],sp.integrate.simps(df_normalized, axis=0)[2], sp.integrate.simps(df_normalized, axis=0)[3]]\n",
    "\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfGyroVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfGyroMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfGyroMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfGyroSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfGyroRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "        listOfGyroEntropyDataFramePerClass[a].append(entropyDataFrame) \n",
    "        listOfGyroKurtosisDataFramePerClass[a].append(kurtosisDataFrame) \n",
    "        listOfGyroSkewnessDataFramePerClass[a].append(skewnessDataFrame) \n",
    "        listOfGyroSmaDataFramePerClass[a].append(smaDataFrame) \n",
    "        listOfGyroIntegrationDataFramePerClass[a].append(integrationDataFrame) \n",
    "        \n",
    "        print(\"Done computing Gyro features \" + str(ctr) + a + \" arm files\")\n",
    "        \n",
    "print(\"Done computing gyro features!!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "ctr = 0\n",
    "\n",
    "listOfLabeledAccDataPerClass = {}\n",
    "listOfLabeledAccDataPerClass['right'] = {}\n",
    "listOfLabeledAccDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfDataFramesPerClass[k]['acc']:\n",
    "\n",
    "    accDataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        accDataFramesPerFeature['variance'] = listOfAccVarianceDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['mav'] = listOfAccMavDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['rms'] = listOfAccRmsDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['sd'] = listOfAccSdDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['mean'] = listOfAccMeanDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['entropy'] = listOfAccEntropyDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['kurtosis'] = listOfAccKurtosisDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['skewness'] = listOfAccSkewnessDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['sma'] = listOfAccSmaDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['integration'] = listOfAccIntegrationDataFramePerClass[a][ctr]\n",
    "\n",
    "        for k2 in accDataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in accDataFramesPerFeature[k2].columns:\n",
    "                    accDataFramesPerFeature['variance'][i] = accDataFramesPerFeature[k2][i]\n",
    "        \n",
    "        accDataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledAccDataPerClass[a][k] = accDataFramesPerFeature['variance']\n",
    "        print(\"Done labeling acc data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "\n",
    "listOfLabeledGyroDataPerClass = {}\n",
    "listOfLabeledGyroDataPerClass['right'] = {}\n",
    "listOfLabeledGyroDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "\n",
    "    GyroDataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        GyroDataFramesPerFeature['variance'] = listOfGyroVarianceDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['mav'] = listOfGyroMavDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['rms'] = listOfGyroRmsDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['sd'] = listOfGyroSdDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['mean'] = listOfGyroMeanDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['entropy'] = listOfGyroEntropyDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['kurtosis'] = listOfGyroKurtosisDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['skewness'] = listOfGyroSkewnessDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['sma'] = listOfGyroSmaDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['integration'] = listOfGyroIntegrationDataFramePerClass[a][ctr]\n",
    "\n",
    "        for k2 in GyroDataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in GyroDataFramesPerFeature[k2].columns:\n",
    "                    GyroDataFramesPerFeature['variance'][i] = GyroDataFramesPerFeature[k2][i]\n",
    "        \n",
    "        GyroDataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledGyroDataPerClass[a][k] = GyroDataFramesPerFeature['variance']\n",
    "        print(\"Done labeling Gyro data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = listOfLabeledGyroDataPerClass['left']['ano']\n",
    "testPerClass = {}\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    #print(('%s %s') % (a, k))\n",
    "    testPerClass[k] = []\n",
    "    test = listOfLabeledGyroDataPerClass['left'][k]\n",
    "    for i in listOfLabeledGyroDataPerClass['right'][k]:\n",
    "        test[i] = listOfLabeledGyroDataPerClass['right'][k][i]\n",
    "    for i in listOfLabeledAccDataPerClass['left'][k].columns:\n",
    "        test[i] = listOfLabeledAccDataPerClass['left'][k][i]\n",
    "    for i in listOfLabeledAccDataPerClass['right'][k].columns:\n",
    "        test[i] = listOfLabeledAccDataPerClass['right'][k][i]\n",
    "    for i in listOfLabeledDataPerClass['left'][k].columns:\n",
    "        test[i] = listOfLabeledDataPerClass['left'][k][i]\n",
    "    for i in listOfLabeledDataPerClass['right'][k].columns:\n",
    "        test[i] = listOfLabeledDataPerClass['right'][k][i]                        #emg data\n",
    "    testPerClass[k] = test\n",
    "# test\n",
    "# test.to_csv('/Users/user/Desktop/test.csv', encoding='utf-8', index=False)\n",
    "newDf = testPerClass['ano']\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    if k != 'ano':\n",
    "        print(k)\n",
    "        newDf= newDf.append(testPerClass[k]) \n",
    "\n",
    "df = newDf\n",
    "df = df[pd.notnull(df['left MeanFreq of EMG1'])]\n",
    "df = df[pd.notnull(df['right MeanFreq of EMG1'])]\n",
    "df = df[pd.notnull(df['left MeanFreq of EMG5'])]\n",
    "\n",
    "classNames = df[\"Class\"].tolist()\n",
    "\n",
    "\n",
    "df = df.drop(\"Class\", axis=1)\n",
    "\n",
    "x = df.values.astype(float)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "df = pd.DataFrame(x_scaled,columns=df.columns)\n",
    "\n",
    "df[\"Class\"] = classNames\n",
    "\n",
    "df.to_csv('ConsolidatedData-Normalized(Trimmed).csv', encoding='utf-8', index=False)\n",
    "newDf.to_csv('ConsolidatedData-Original(Trimmed).csv', encoding='utf-8', index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classNames = newDf[\"Class\"].tolist()\n",
    "\n",
    "# df = newDf.drop(\"Class\", axis=1)\n",
    "# df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "# df[\"Class\"] = classNames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('ConsolidatedData.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDf.to_csv('ConsolidatedData-Original.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.isnull().T.any().T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df[df.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDf[225:] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDf.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# rightMeanFreq1 = df[\"right MeanFreq of EMG1\"].tolist()\n",
    "# rightMeanFreq2 = df[\"right MeanFreq of EMG2\"].tolist()\n",
    "# rightMeanFreq3 = df[\"right MeanFreq of EMG3\"].tolist()\n",
    "# rightMeanFreq4 = df[\"right MeanFreq of EMG4\"].tolist()\n",
    "# rightMeanFreq5 = df[\"right MeanFreq of EMG5\"].tolist()\n",
    "# rightMeanFreq6 = df[\"right MeanFreq of EMG6\"].tolist()\n",
    "# rightMeanFreq7 = df[\"right MeanFreq of EMG7\"].tolist()\n",
    "# rightMeanFreq8 = df[\"right MeanFreq of EMG8\"].tolist()\n",
    "\n",
    "# leftMeanFreq1 = df[\"left MeanFreq of EMG1\"].tolist()\n",
    "# leftMeanFreq2 = df[\"left MeanFreq of EMG2\"].tolist()\n",
    "# leftMeanFreq3 = df[\"left MeanFreq of EMG3\"].tolist()\n",
    "# leftMeanFreq4 = df[\"left MeanFreq of EMG4\"].tolist()\n",
    "# leftMeanFreq5 = df[\"left MeanFreq of EMG5\"].tolist()\n",
    "# leftMeanFreq6 = df[\"left MeanFreq of EMG6\"].tolist()\n",
    "# leftMeanFreq7 = df[\"left MeanFreq of EMG7\"].tolist()\n",
    "# leftMeanFreq8 = df[\"left MeanFreq of EMG8\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "# df = df.drop(\"right MeanFreq of EMG1\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG2\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG3\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG4\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG5\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG6\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG7\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG8\", axis=1)\n",
    "\n",
    "# df = df.drop(\"left MeanFreq of EMG1\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG2\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG3\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG4\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG5\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG6\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG7\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG8\", axis=1)\n",
    "\n",
    "# df[\"right MeanFreq of EMG1\"] = rightMeanFreq1\n",
    "# df[\"right MeanFreq of EMG2\"] = rightMeanFreq2\n",
    "# df[\"right MeanFreq of EMG3\"] = rightMeanFreq3\n",
    "# df[\"right MeanFreq of EMG4\"] = rightMeanFreq4\n",
    "# df[\"right MeanFreq of EMG5\"] = rightMeanFreq5\n",
    "# df[\"right MeanFreq of EMG6\"] = rightMeanFreq6\n",
    "# df[\"right MeanFreq of EMG7\"] = rightMeanFreq7\n",
    "# df[\"right MeanFreq of EMG8\"] = rightMeanFreq8\n",
    "\n",
    "# df[\"left MeanFreq of EMG1\"] = leftMeanFreq1\n",
    "# df[\"left MeanFreq of EMG2\"] = leftMeanFreq2\n",
    "# df[\"left MeanFreq of EMG3\"] = leftMeanFreq3\n",
    "# df[\"left MeanFreq of EMG4\"] = leftMeanFreq4\n",
    "# df[\"left MeanFreq of EMG5\"] = leftMeanFreq5\n",
    "# df[\"left MeanFreq of EMG6\"] = leftMeanFreq6\n",
    "# df[\"left MeanFreq of EMG7\"] = leftMeanFreq7\n",
    "# df[\"left MeanFreq of EMG8\"] = leftMeanFreq8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "    \n",
    "\n",
    "\n",
    "# for k2 in GyroDataFramesPerFeature.keys():\n",
    "#     for i in GyroDataFramesPerFeature[k2].columns:\n",
    "#         dataFramesPerFeature['variance'][i] = GyroDataFramesPerFeature[k2][i]\n",
    "            \n",
    "# for k2 in accDataFramesPerFeature.keys():\n",
    "#     for i in accDataFramesPerFeature[k2].columns:\n",
    "#         dataFramesPerFeature['variance'][i] = accDataFramesPerFeature[k2][i]\n",
    "\n",
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "#     newDf = listOfLabeledAccDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledAccDataPerClass[a][k])\n",
    "# dataFramesPerFeature.to_csv('/Users/user/Desktop/test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Consolidation (save to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "#     newDf = listOfLabeledAccDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledAccDataPerClass[a][k])\n",
    "    \n",
    "    \n",
    "#     newDf.to_csv('/Users/user/Desktop/'+ a +'ArmConsolidatedAcc.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "#     newDf = listOfLabeledGyroDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedGyroDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledGyroDataPerClass[a][k])\n",
    "    \n",
    "    \n",
    "#     newDf.to_csv('/Users/user/Desktop/'+ a +'ArmConsolidatedGyro.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
