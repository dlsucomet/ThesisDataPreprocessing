{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done listing the class and file names\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "listOfFileNames = []\n",
    "listOfClassNames = []\n",
    "listOfDataPerClass = []\n",
    "\n",
    "files = []\n",
    "classNames = []\n",
    "#path = \"/Users/user/Desktop/asd/thesis/placeholder/\"\n",
    "#path = \"/Users/user/Desktop/pinakalatest/thesis/placeholder/\"\n",
    "path = \"trimmed_data_updated/\"\n",
    "classNames = glob.glob(path + \"*\")\n",
    "onewords = [\"ano\",\"asul\",\"ate\",\"baboy\",\"dalawa\",\"dito\",\"hello\",\"isa\",\"isda\",\"itim\",\"ito\",\"kanin\",\"kayo\",\"ko\",\"kulay\",\"kuya\",\"large (shirt)\",\"magkano\",\"manok\",\"mantika\",\"medium (shirt)\",\"nito\",\"niyo\",\"pagkain\",\"pula\",\"salamat\",\"small (shirt)\",\"softdrinks\",\"sorry\",\"tatlo\",\"tubig\"]\n",
    "\n",
    "for c in classNames:\n",
    "    className = c.split(\"\\\\\")[1]\n",
    "    listOfClassNames.append(c.split(\"\\\\\")[1])\n",
    "    files = glob.glob(path + className+\"/*\") \n",
    "    listOfFileNames = []\n",
    "    if className in onewords:\n",
    "        \n",
    "        for f in files:\n",
    "            checker = False\n",
    "\n",
    "            fileLocation = f.split(\"\\\\\")[1]\n",
    "\n",
    "\n",
    "            if checker is False:\n",
    "                listOfFileNames.append(fileLocation)\n",
    "\n",
    "        listOfDataPerClass.append(listOfFileNames)\n",
    "\n",
    "    \n",
    "#listOfClassNames\n",
    "#listOfDataPerClass[0]\n",
    "\n",
    "print(\"Done listing the class and file names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word ano-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word asul-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word ate-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word baboy-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word binebenta-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word dalawa-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word dito-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word extra-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word gulay-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word gusto-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word hello-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word isa-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word isda-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word itim-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word itlog-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word ito-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word juice-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kanin-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kape-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kayo-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kilo-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word ko-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kulay-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kuya-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word large (shirt)-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word magkano-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word mahal-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word malaki-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word maliit-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word manok-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word mantika-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "Done converting to dataframes!\n"
     ]
    }
   ],
   "source": [
    "#len(listOfDataPerClass)\n",
    "#listOfDataPerClass[3]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "listOfDataFramesPerClass = {}\n",
    "dataFrameDictionary = {}\n",
    "dataFrames = []\n",
    "\n",
    "\n",
    "for c, d in zip(listOfClassNames, listOfDataPerClass):\n",
    "    \n",
    "    print(\"----------------- Word \" + c + \"-----------------\")\n",
    "    emgDataFrames = {}\n",
    "    emgDataFrames['right'] = []\n",
    "    emgDataFrames['left'] = []\n",
    "\n",
    "    accDataFrames = {}\n",
    "    accDataFrames['right'] = []\n",
    "    accDataFrames['left'] = []\n",
    "\n",
    "    gyroDataFrames = {}\n",
    "    gyroDataFrames['right'] = []\n",
    "    gyroDataFrames['left'] = []\n",
    "\n",
    "    dataFrameDictionary = {}\n",
    "    className = c\n",
    "    emgleftctr = 0\n",
    "    emgrightctr = 0\n",
    "    accleftctr = 0\n",
    "    accrightctr = 0\n",
    "    gyroleftctr = 0\n",
    "    gyrorightctr = 0\n",
    "\n",
    "    for fileName in d:\n",
    "        checker = False\n",
    "        fileLocation = path + className + \"/\" + fileName + \"\"\n",
    "        #print(fileLocation)\n",
    "        df = pd.read_csv(fileLocation)\n",
    "\n",
    "\n",
    "        if \"emg\" in fileName:   \n",
    "            if \"-Right\" in fileName:\n",
    "                emgDataFrames['right'].append(df)\n",
    "                emgrightctr+=1\n",
    "            else:\n",
    "                emgDataFrames['left'].append(df)\n",
    "                emgleftctr+=1\n",
    "        elif (\"acc\") in fileName:\n",
    "            if \"-Right\" in fileName:\n",
    "                accDataFrames['right'].append(df)\n",
    "                accrightctr+=1\n",
    "            else:\n",
    "                accDataFrames['left'].append(df)\n",
    "                accleftctr+=1\n",
    "        elif (\"gyro\") in fileName:\n",
    "            if \"-Right\" in fileName:\n",
    "                gyroDataFrames['right'].append(df)\n",
    "                gyrorightctr+=1\n",
    "            else:\n",
    "                gyroDataFrames['left'].append(df)\n",
    "                gyroleftctr+=1\n",
    "\n",
    "    dataFrameDictionary[\"emg\"] = emgDataFrames\n",
    "    dataFrameDictionary[\"acc\"] = accDataFrames\n",
    "    dataFrameDictionary[\"gyro\"] = gyroDataFrames\n",
    "\n",
    "    listOfDataFramesPerClass[className] = dataFrameDictionary\n",
    "    print(\"Total of \" + str(emgleftctr) + \" left arm emg files and \" + str(emgrightctr) + \" right arm emg files.\")\n",
    "    print(\"Total of \" + str(accleftctr) + \" left arm acc files and \" + str(accrightctr) + \" right arm acc files.\")\n",
    "    print(\"Total of \" + str(gyroleftctr) + \" left arm gyro files and \" + str(gyrorightctr) + \" right arm gyro files.\")\n",
    "\n",
    "\n",
    "print(\"Done converting to dataframes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# emgDataFrames = {}\n",
    "# emgDataFrames['right'] = []\n",
    "# emgDataFrames['left'] = []\n",
    "    \n",
    "# accDataFrames = {}\n",
    "# accDataFrames['right'] = []\n",
    "# accDataFrames['left'] = []\n",
    "\n",
    "# gyroDataFrames = {}\n",
    "# gyroDataFrames['right'] = []\n",
    "# gyroDataFrames['left'] = []\n",
    "\n",
    "# dataFrameDictionary = {}\n",
    "# className = c\n",
    "# emgleftctr = 0\n",
    "# emgrightctr = 0\n",
    "# accleftctr = 0\n",
    "# accrightctr = 0\n",
    "# gyroleftctr = 0\n",
    "# gyrorightctr = 0\n",
    "    \n",
    "# className = \"binebenta\"\n",
    "# d = listOfDataPerClass[43]\n",
    "# for fileName in d:\n",
    "#     checker = False\n",
    "#     fileLocation = path + className + \"/\" + fileName + \"\"\n",
    "#     #print(fileLocation)\n",
    "#     df = pd.read_csv(fileLocation)\n",
    "        \n",
    "        \n",
    "#     if \"emg\" in fileName:   \n",
    "#         if \"-Right\" in fileName:\n",
    "#             emgDataFrames['right'].append(df)\n",
    "#             emgrightctr+=1\n",
    "#         else:\n",
    "#             emgDataFrames['left'].append(df)\n",
    "#             emgleftctr+=1\n",
    "#     elif (\"acc\") in fileName:\n",
    "#         if \"-Right\" in fileName:\n",
    "#             accDataFrames['right'].append(df)\n",
    "#             accrightctr+=1\n",
    "#         else:\n",
    "#             accDataFrames['left'].append(df)\n",
    "#             accleftctr+=1\n",
    "#     elif (\"gyro\") in fileName:\n",
    "#         if \"-Right\" in fileName:\n",
    "#             gyroDataFrames['right'].append(df)\n",
    "#             gyrorightctr+=1\n",
    "#         else:\n",
    "#             gyroDataFrames['left'].append(df)\n",
    "#             gyroleftctr+=1\n",
    "    \n",
    "# dataFrameDictionary[\"emg\"] = emgDataFrames\n",
    "# dataFrameDictionary[\"acc\"] = accDataFrames\n",
    "# dataFrameDictionary[\"gyro\"] = gyroDataFrames\n",
    "\n",
    "# listOfDataFramesPerClass[className] = dataFrameDictionary\n",
    "# print(\"Total of \" + str(emgleftctr) + \" left arm emg files and \" + str(emgrightctr) + \" right arm emg files.\")\n",
    "# print(\"Total of \" + str(accleftctr) + \" left arm acc files and \" + str(accrightctr) + \" right arm acc files.\")\n",
    "# print(\"Total of \" + str(gyroleftctr) + \" left arm gyro files and \" + str(gyrorightctr) + \" right arm gyro files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For EMG Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band Pass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ano\n",
      "100\n",
      "ano\n",
      "100\n",
      "asul\n",
      "100\n",
      "asul\n",
      "100\n",
      "ate\n",
      "100\n",
      "ate\n",
      "100\n",
      "baboy\n",
      "100\n",
      "baboy\n",
      "100\n",
      "binebenta\n",
      "100\n",
      "binebenta\n",
      "100\n",
      "dalawa\n",
      "100\n",
      "dalawa\n",
      "100\n",
      "dito\n",
      "100\n",
      "dito\n",
      "100\n",
      "extra\n",
      "100\n",
      "extra\n",
      "100\n",
      "gulay\n",
      "100\n",
      "gulay\n",
      "100\n",
      "gusto\n",
      "100\n",
      "gusto\n",
      "100\n",
      "hello\n",
      "100\n",
      "hello\n",
      "100\n",
      "isa\n",
      "100\n",
      "isa\n",
      "100\n",
      "isda\n",
      "100\n",
      "isda\n",
      "100\n",
      "itim\n",
      "100\n",
      "itim\n",
      "100\n",
      "itlog\n",
      "100\n",
      "itlog\n",
      "100\n",
      "ito\n",
      "100\n",
      "ito\n",
      "100\n",
      "juice\n",
      "100\n",
      "juice\n",
      "100\n",
      "kanin\n",
      "100\n",
      "kanin\n",
      "100\n",
      "kape\n",
      "100\n",
      "kape\n",
      "100\n",
      "kayo\n",
      "100\n",
      "kayo\n",
      "100\n",
      "kilo\n",
      "100\n",
      "kilo\n",
      "100\n",
      "ko\n",
      "100\n",
      "ko\n",
      "100\n",
      "kulay\n",
      "100\n",
      "kulay\n",
      "100\n",
      "kuya\n",
      "100\n",
      "kuya\n",
      "100\n",
      "large (shirt)\n",
      "100\n",
      "large (shirt)\n",
      "100\n",
      "magkano\n",
      "100\n",
      "magkano\n",
      "100\n",
      "mahal\n",
      "100\n",
      "mahal\n",
      "100\n",
      "malaki\n",
      "100\n",
      "malaki\n",
      "100\n",
      "maliit\n",
      "100\n",
      "maliit\n",
      "100\n",
      "manok\n",
      "100\n",
      "manok\n",
      "100\n",
      "mantika\n",
      "100\n",
      "mantika\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    for a in listOfDataFramesPerClass[k]['emg']:\n",
    "        print(k)\n",
    "        ctr = 0\n",
    "        for d in listOfDataFramesPerClass[k]['emg'][a]:\n",
    "            for r in d:\n",
    "                if \"time\" not in r:\n",
    "                    emg = np.array(d[r].values)\n",
    "\n",
    "                    emg_correctmean = emg - np.mean(emg)\n",
    "\n",
    "                    # create bandpass filter for EMG\n",
    "                    high = 2/(100/2)\n",
    "                    low = 45/(100/2)\n",
    "                    b, a = sp.signal.butter(4, [high,low], btype='bandpass')\n",
    "\n",
    "                    emg_filtered = sp.signal.filtfilt(b, a, emg_correctmean)\n",
    "\n",
    "                    emg_rectified = abs(emg_filtered)\n",
    "\n",
    "\n",
    "\n",
    "                    # create lowpass filter and apply to rectified signal to get EMG envelope\n",
    "                    sfreq = 100\n",
    "                    low_pass = 10/sfreq\n",
    "                    b2, a2 = sp.signal.butter(4, low_pass, btype='lowpass')\n",
    "                    emg_envelope = sp.signal.filtfilt(b2, a2, emg_rectified)\n",
    "\n",
    "                    d[r] = emg_envelope\n",
    "            ctr +=1\n",
    "        print(ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word ano-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word asul-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word ate-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word baboy-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word binebenta-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word dalawa-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word dito-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word extra-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word gulay-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word gusto-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word hello-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word isa-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word isda-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word itim-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word itlog-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word ito-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word juice-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word kanin-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word kape-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word kayo-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word kilo-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word ko-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word kulay-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word kuya-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word large (shirt)-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word magkano-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word mahal-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word malaki-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word maliit-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word manok-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word mantika-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "Data Normalization done!!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "listOfNormalizedDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    \n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        for d in listOfDataFramesPerClass[k]['emg'][a]:\n",
    "\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            \n",
    "          \n",
    "            ctr += 1\n",
    "\n",
    "        print(\"Done Normalizing \" + str(ctr) + a + \" arm files\")\n",
    "    dataFrameDictionary[\"emg\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099378</td>\n",
       "      <td>0.113893</td>\n",
       "      <td>0.050630</td>\n",
       "      <td>0.088453</td>\n",
       "      <td>0.076253</td>\n",
       "      <td>0.198765</td>\n",
       "      <td>0.211798</td>\n",
       "      <td>0.125419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.195561</td>\n",
       "      <td>0.195056</td>\n",
       "      <td>0.098869</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.147970</td>\n",
       "      <td>0.347219</td>\n",
       "      <td>0.411123</td>\n",
       "      <td>0.244359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.286409</td>\n",
       "      <td>0.267680</td>\n",
       "      <td>0.142850</td>\n",
       "      <td>0.248192</td>\n",
       "      <td>0.211255</td>\n",
       "      <td>0.477994</td>\n",
       "      <td>0.586655</td>\n",
       "      <td>0.351238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.370057</td>\n",
       "      <td>0.328549</td>\n",
       "      <td>0.181221</td>\n",
       "      <td>0.312786</td>\n",
       "      <td>0.263106</td>\n",
       "      <td>0.584923</td>\n",
       "      <td>0.729311</td>\n",
       "      <td>0.441683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.444920</td>\n",
       "      <td>0.375363</td>\n",
       "      <td>0.213269</td>\n",
       "      <td>0.364113</td>\n",
       "      <td>0.301732</td>\n",
       "      <td>0.664223</td>\n",
       "      <td>0.833046</td>\n",
       "      <td>0.512862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010427</td>\n",
       "      <td>0.509677</td>\n",
       "      <td>0.406833</td>\n",
       "      <td>0.238940</td>\n",
       "      <td>0.401108</td>\n",
       "      <td>0.326706</td>\n",
       "      <td>0.714668</td>\n",
       "      <td>0.895272</td>\n",
       "      <td>0.563576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010427</td>\n",
       "      <td>0.563250</td>\n",
       "      <td>0.422702</td>\n",
       "      <td>0.258770</td>\n",
       "      <td>0.423737</td>\n",
       "      <td>0.338933</td>\n",
       "      <td>0.737445</td>\n",
       "      <td>0.916856</td>\n",
       "      <td>0.594170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.015276</td>\n",
       "      <td>0.604823</td>\n",
       "      <td>0.423706</td>\n",
       "      <td>0.273755</td>\n",
       "      <td>0.432901</td>\n",
       "      <td>0.340476</td>\n",
       "      <td>0.735741</td>\n",
       "      <td>0.901793</td>\n",
       "      <td>0.606316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015276</td>\n",
       "      <td>0.633898</td>\n",
       "      <td>0.411484</td>\n",
       "      <td>0.285169</td>\n",
       "      <td>0.430282</td>\n",
       "      <td>0.334260</td>\n",
       "      <td>0.714178</td>\n",
       "      <td>0.856586</td>\n",
       "      <td>0.602730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018456</td>\n",
       "      <td>0.650371</td>\n",
       "      <td>0.388439</td>\n",
       "      <td>0.294391</td>\n",
       "      <td>0.418157</td>\n",
       "      <td>0.323711</td>\n",
       "      <td>0.678200</td>\n",
       "      <td>0.789445</td>\n",
       "      <td>0.586863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.018456</td>\n",
       "      <td>0.654624</td>\n",
       "      <td>0.357558</td>\n",
       "      <td>0.302730</td>\n",
       "      <td>0.399181</td>\n",
       "      <td>0.312362</td>\n",
       "      <td>0.633483</td>\n",
       "      <td>0.709405</td>\n",
       "      <td>0.562579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.020471</td>\n",
       "      <td>0.647588</td>\n",
       "      <td>0.322197</td>\n",
       "      <td>0.311290</td>\n",
       "      <td>0.376165</td>\n",
       "      <td>0.303483</td>\n",
       "      <td>0.585460</td>\n",
       "      <td>0.625435</td>\n",
       "      <td>0.533836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.020471</td>\n",
       "      <td>0.630745</td>\n",
       "      <td>0.285850</td>\n",
       "      <td>0.320859</td>\n",
       "      <td>0.351856</td>\n",
       "      <td>0.299753</td>\n",
       "      <td>0.538960</td>\n",
       "      <td>0.545666</td>\n",
       "      <td>0.504366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.026013</td>\n",
       "      <td>0.606074</td>\n",
       "      <td>0.251930</td>\n",
       "      <td>0.331857</td>\n",
       "      <td>0.328728</td>\n",
       "      <td>0.303035</td>\n",
       "      <td>0.497984</td>\n",
       "      <td>0.476773</td>\n",
       "      <td>0.477395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.026013</td>\n",
       "      <td>0.575908</td>\n",
       "      <td>0.223579</td>\n",
       "      <td>0.344313</td>\n",
       "      <td>0.308808</td>\n",
       "      <td>0.314247</td>\n",
       "      <td>0.465585</td>\n",
       "      <td>0.423580</td>\n",
       "      <td>0.455417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.028438</td>\n",
       "      <td>0.542730</td>\n",
       "      <td>0.203506</td>\n",
       "      <td>0.357901</td>\n",
       "      <td>0.293548</td>\n",
       "      <td>0.333355</td>\n",
       "      <td>0.443830</td>\n",
       "      <td>0.388867</td>\n",
       "      <td>0.440051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.028438</td>\n",
       "      <td>0.508946</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.371992</td>\n",
       "      <td>0.283761</td>\n",
       "      <td>0.359457</td>\n",
       "      <td>0.433819</td>\n",
       "      <td>0.373386</td>\n",
       "      <td>0.431993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.031208</td>\n",
       "      <td>0.476676</td>\n",
       "      <td>0.196239</td>\n",
       "      <td>0.385741</td>\n",
       "      <td>0.279626</td>\n",
       "      <td>0.390948</td>\n",
       "      <td>0.435735</td>\n",
       "      <td>0.376045</td>\n",
       "      <td>0.431055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.031208</td>\n",
       "      <td>0.447605</td>\n",
       "      <td>0.211487</td>\n",
       "      <td>0.398156</td>\n",
       "      <td>0.280731</td>\n",
       "      <td>0.425737</td>\n",
       "      <td>0.448911</td>\n",
       "      <td>0.394234</td>\n",
       "      <td>0.436284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.036442</td>\n",
       "      <td>0.422912</td>\n",
       "      <td>0.239857</td>\n",
       "      <td>0.408186</td>\n",
       "      <td>0.286183</td>\n",
       "      <td>0.461490</td>\n",
       "      <td>0.471924</td>\n",
       "      <td>0.424237</td>\n",
       "      <td>0.446138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.036442</td>\n",
       "      <td>0.403273</td>\n",
       "      <td>0.280946</td>\n",
       "      <td>0.414804</td>\n",
       "      <td>0.294727</td>\n",
       "      <td>0.495896</td>\n",
       "      <td>0.502688</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>0.458721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.039228</td>\n",
       "      <td>0.388904</td>\n",
       "      <td>0.333747</td>\n",
       "      <td>0.417109</td>\n",
       "      <td>0.304897</td>\n",
       "      <td>0.526901</td>\n",
       "      <td>0.538608</td>\n",
       "      <td>0.502096</td>\n",
       "      <td>0.472032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.039228</td>\n",
       "      <td>0.379636</td>\n",
       "      <td>0.396703</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.315173</td>\n",
       "      <td>0.552916</td>\n",
       "      <td>0.576755</td>\n",
       "      <td>0.541160</td>\n",
       "      <td>0.484218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.041438</td>\n",
       "      <td>0.374991</td>\n",
       "      <td>0.467765</td>\n",
       "      <td>0.406509</td>\n",
       "      <td>0.324126</td>\n",
       "      <td>0.572934</td>\n",
       "      <td>0.614099</td>\n",
       "      <td>0.575257</td>\n",
       "      <td>0.493795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.041438</td>\n",
       "      <td>0.374263</td>\n",
       "      <td>0.544465</td>\n",
       "      <td>0.393430</td>\n",
       "      <td>0.330545</td>\n",
       "      <td>0.586567</td>\n",
       "      <td>0.647761</td>\n",
       "      <td>0.601662</td>\n",
       "      <td>0.499796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.046979</td>\n",
       "      <td>0.376609</td>\n",
       "      <td>0.623988</td>\n",
       "      <td>0.375790</td>\n",
       "      <td>0.333528</td>\n",
       "      <td>0.593989</td>\n",
       "      <td>0.675263</td>\n",
       "      <td>0.618724</td>\n",
       "      <td>0.501837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.046979</td>\n",
       "      <td>0.381160</td>\n",
       "      <td>0.703265</td>\n",
       "      <td>0.354587</td>\n",
       "      <td>0.332533</td>\n",
       "      <td>0.595811</td>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.625925</td>\n",
       "      <td>0.500090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.049455</td>\n",
       "      <td>0.387133</td>\n",
       "      <td>0.779075</td>\n",
       "      <td>0.331143</td>\n",
       "      <td>0.327404</td>\n",
       "      <td>0.592910</td>\n",
       "      <td>0.705064</td>\n",
       "      <td>0.623828</td>\n",
       "      <td>0.495188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.049455</td>\n",
       "      <td>0.393937</td>\n",
       "      <td>0.848166</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.318357</td>\n",
       "      <td>0.586246</td>\n",
       "      <td>0.705921</td>\n",
       "      <td>0.613936</td>\n",
       "      <td>0.488086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.948082</td>\n",
       "      <td>0.433340</td>\n",
       "      <td>0.562803</td>\n",
       "      <td>0.496362</td>\n",
       "      <td>0.202414</td>\n",
       "      <td>0.634265</td>\n",
       "      <td>0.619354</td>\n",
       "      <td>0.611355</td>\n",
       "      <td>0.484284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.953404</td>\n",
       "      <td>0.413423</td>\n",
       "      <td>0.551052</td>\n",
       "      <td>0.479274</td>\n",
       "      <td>0.209160</td>\n",
       "      <td>0.617618</td>\n",
       "      <td>0.600093</td>\n",
       "      <td>0.642993</td>\n",
       "      <td>0.475096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.953404</td>\n",
       "      <td>0.394677</td>\n",
       "      <td>0.546132</td>\n",
       "      <td>0.458421</td>\n",
       "      <td>0.211728</td>\n",
       "      <td>0.598466</td>\n",
       "      <td>0.573462</td>\n",
       "      <td>0.673851</td>\n",
       "      <td>0.462667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0.953628</td>\n",
       "      <td>0.377144</td>\n",
       "      <td>0.547469</td>\n",
       "      <td>0.434291</td>\n",
       "      <td>0.208665</td>\n",
       "      <td>0.577343</td>\n",
       "      <td>0.540596</td>\n",
       "      <td>0.702674</td>\n",
       "      <td>0.447767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0.953628</td>\n",
       "      <td>0.360983</td>\n",
       "      <td>0.553918</td>\n",
       "      <td>0.407641</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.554763</td>\n",
       "      <td>0.503244</td>\n",
       "      <td>0.728184</td>\n",
       "      <td>0.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.958267</td>\n",
       "      <td>0.346545</td>\n",
       "      <td>0.563840</td>\n",
       "      <td>0.379606</td>\n",
       "      <td>0.182926</td>\n",
       "      <td>0.531292</td>\n",
       "      <td>0.463621</td>\n",
       "      <td>0.749053</td>\n",
       "      <td>0.415255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.958267</td>\n",
       "      <td>0.334403</td>\n",
       "      <td>0.575264</td>\n",
       "      <td>0.351775</td>\n",
       "      <td>0.160941</td>\n",
       "      <td>0.507635</td>\n",
       "      <td>0.424203</td>\n",
       "      <td>0.763933</td>\n",
       "      <td>0.400671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0.960958</td>\n",
       "      <td>0.325348</td>\n",
       "      <td>0.586110</td>\n",
       "      <td>0.326211</td>\n",
       "      <td>0.134928</td>\n",
       "      <td>0.484732</td>\n",
       "      <td>0.387510</td>\n",
       "      <td>0.771552</td>\n",
       "      <td>0.389595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.960958</td>\n",
       "      <td>0.320361</td>\n",
       "      <td>0.594449</td>\n",
       "      <td>0.305412</td>\n",
       "      <td>0.107647</td>\n",
       "      <td>0.463825</td>\n",
       "      <td>0.355898</td>\n",
       "      <td>0.770871</td>\n",
       "      <td>0.384018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0.966157</td>\n",
       "      <td>0.320546</td>\n",
       "      <td>0.598771</td>\n",
       "      <td>0.292166</td>\n",
       "      <td>0.082725</td>\n",
       "      <td>0.446472</td>\n",
       "      <td>0.331393</td>\n",
       "      <td>0.761270</td>\n",
       "      <td>0.385981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.966157</td>\n",
       "      <td>0.327033</td>\n",
       "      <td>0.598208</td>\n",
       "      <td>0.289349</td>\n",
       "      <td>0.064425</td>\n",
       "      <td>0.434482</td>\n",
       "      <td>0.315577</td>\n",
       "      <td>0.742711</td>\n",
       "      <td>0.397414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.968996</td>\n",
       "      <td>0.340850</td>\n",
       "      <td>0.592675</td>\n",
       "      <td>0.299631</td>\n",
       "      <td>0.057307</td>\n",
       "      <td>0.429772</td>\n",
       "      <td>0.309511</td>\n",
       "      <td>0.715810</td>\n",
       "      <td>0.419944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.968996</td>\n",
       "      <td>0.362767</td>\n",
       "      <td>0.582888</td>\n",
       "      <td>0.325142</td>\n",
       "      <td>0.065791</td>\n",
       "      <td>0.434130</td>\n",
       "      <td>0.313695</td>\n",
       "      <td>0.681816</td>\n",
       "      <td>0.454653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.974209</td>\n",
       "      <td>0.393125</td>\n",
       "      <td>0.570242</td>\n",
       "      <td>0.367115</td>\n",
       "      <td>0.093663</td>\n",
       "      <td>0.448934</td>\n",
       "      <td>0.328045</td>\n",
       "      <td>0.642483</td>\n",
       "      <td>0.501837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.974209</td>\n",
       "      <td>0.431669</td>\n",
       "      <td>0.556535</td>\n",
       "      <td>0.425547</td>\n",
       "      <td>0.143543</td>\n",
       "      <td>0.474831</td>\n",
       "      <td>0.351860</td>\n",
       "      <td>0.599875</td>\n",
       "      <td>0.560791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.974658</td>\n",
       "      <td>0.477389</td>\n",
       "      <td>0.543597</td>\n",
       "      <td>0.498938</td>\n",
       "      <td>0.216388</td>\n",
       "      <td>0.511462</td>\n",
       "      <td>0.383781</td>\n",
       "      <td>0.556143</td>\n",
       "      <td>0.629634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.974658</td>\n",
       "      <td>0.528410</td>\n",
       "      <td>0.532886</td>\n",
       "      <td>0.584140</td>\n",
       "      <td>0.311047</td>\n",
       "      <td>0.557251</td>\n",
       "      <td>0.421750</td>\n",
       "      <td>0.513288</td>\n",
       "      <td>0.705222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.981828</td>\n",
       "      <td>0.581959</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>0.676375</td>\n",
       "      <td>0.423946</td>\n",
       "      <td>0.609323</td>\n",
       "      <td>0.462996</td>\n",
       "      <td>0.472940</td>\n",
       "      <td>0.783168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.981828</td>\n",
       "      <td>0.634414</td>\n",
       "      <td>0.520043</td>\n",
       "      <td>0.769430</td>\n",
       "      <td>0.548945</td>\n",
       "      <td>0.663567</td>\n",
       "      <td>0.504074</td>\n",
       "      <td>0.436167</td>\n",
       "      <td>0.857996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.982174</td>\n",
       "      <td>0.681473</td>\n",
       "      <td>0.516278</td>\n",
       "      <td>0.856032</td>\n",
       "      <td>0.677449</td>\n",
       "      <td>0.714865</td>\n",
       "      <td>0.540980</td>\n",
       "      <td>0.403340</td>\n",
       "      <td>0.923445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.982174</td>\n",
       "      <td>0.718430</td>\n",
       "      <td>0.511459</td>\n",
       "      <td>0.928363</td>\n",
       "      <td>0.798805</td>\n",
       "      <td>0.757473</td>\n",
       "      <td>0.569359</td>\n",
       "      <td>0.374087</td>\n",
       "      <td>0.972913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.987088</td>\n",
       "      <td>0.740567</td>\n",
       "      <td>0.502456</td>\n",
       "      <td>0.978679</td>\n",
       "      <td>0.901032</td>\n",
       "      <td>0.785519</td>\n",
       "      <td>0.584794</td>\n",
       "      <td>0.347355</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.987088</td>\n",
       "      <td>0.743618</td>\n",
       "      <td>0.485784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971854</td>\n",
       "      <td>0.793566</td>\n",
       "      <td>0.583191</td>\n",
       "      <td>0.321572</td>\n",
       "      <td>0.999107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.989938</td>\n",
       "      <td>0.724253</td>\n",
       "      <td>0.458086</td>\n",
       "      <td>0.986802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777189</td>\n",
       "      <td>0.561206</td>\n",
       "      <td>0.294901</td>\n",
       "      <td>0.966024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>0.989938</td>\n",
       "      <td>0.680524</td>\n",
       "      <td>0.416643</td>\n",
       "      <td>0.935667</td>\n",
       "      <td>0.976645</td>\n",
       "      <td>0.733487</td>\n",
       "      <td>0.516695</td>\n",
       "      <td>0.265548</td>\n",
       "      <td>0.898444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.994802</td>\n",
       "      <td>0.612203</td>\n",
       "      <td>0.359840</td>\n",
       "      <td>0.845824</td>\n",
       "      <td>0.896815</td>\n",
       "      <td>0.661518</td>\n",
       "      <td>0.449092</td>\n",
       "      <td>0.232070</td>\n",
       "      <td>0.796365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.994802</td>\n",
       "      <td>0.520948</td>\n",
       "      <td>0.287524</td>\n",
       "      <td>0.719467</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>0.562579</td>\n",
       "      <td>0.359663</td>\n",
       "      <td>0.193657</td>\n",
       "      <td>0.662313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.997560</td>\n",
       "      <td>0.410272</td>\n",
       "      <td>0.201182</td>\n",
       "      <td>0.561798</td>\n",
       "      <td>0.573209</td>\n",
       "      <td>0.440273</td>\n",
       "      <td>0.251563</td>\n",
       "      <td>0.150311</td>\n",
       "      <td>0.501329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.997560</td>\n",
       "      <td>0.285279</td>\n",
       "      <td>0.103890</td>\n",
       "      <td>0.380687</td>\n",
       "      <td>0.345714</td>\n",
       "      <td>0.300298</td>\n",
       "      <td>0.129643</td>\n",
       "      <td>0.102896</td>\n",
       "      <td>0.320667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185945</td>\n",
       "      <td>0.092905</td>\n",
       "      <td>0.149932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053033</td>\n",
       "      <td>0.129181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.000000  0.000000  0.028118  0.000000  0.000000  0.000000  0.040662   \n",
       "1    0.000000  0.099378  0.113893  0.050630  0.088453  0.076253  0.198765   \n",
       "2    0.005207  0.195561  0.195056  0.098869  0.172414  0.147970  0.347219   \n",
       "3    0.005207  0.286409  0.267680  0.142850  0.248192  0.211255  0.477994   \n",
       "4    0.007721  0.370057  0.328549  0.181221  0.312786  0.263106  0.584923   \n",
       "5    0.007721  0.444920  0.375363  0.213269  0.364113  0.301732  0.664223   \n",
       "6    0.010427  0.509677  0.406833  0.238940  0.401108  0.326706  0.714668   \n",
       "7    0.010427  0.563250  0.422702  0.258770  0.423737  0.338933  0.737445   \n",
       "8    0.015276  0.604823  0.423706  0.273755  0.432901  0.340476  0.735741   \n",
       "9    0.015276  0.633898  0.411484  0.285169  0.430282  0.334260  0.714178   \n",
       "10   0.018456  0.650371  0.388439  0.294391  0.418157  0.323711  0.678200   \n",
       "11   0.018456  0.654624  0.357558  0.302730  0.399181  0.312362  0.633483   \n",
       "12   0.020471  0.647588  0.322197  0.311290  0.376165  0.303483  0.585460   \n",
       "13   0.020471  0.630745  0.285850  0.320859  0.351856  0.299753  0.538960   \n",
       "14   0.026013  0.606074  0.251930  0.331857  0.328728  0.303035  0.497984   \n",
       "15   0.026013  0.575908  0.223579  0.344313  0.308808  0.314247  0.465585   \n",
       "16   0.028438  0.542730  0.203506  0.357901  0.293548  0.333355  0.443830   \n",
       "17   0.028438  0.508946  0.193877  0.371992  0.283761  0.359457  0.433819   \n",
       "18   0.031208  0.476676  0.196239  0.385741  0.279626  0.390948  0.435735   \n",
       "19   0.031208  0.447605  0.211487  0.398156  0.280731  0.425737  0.448911   \n",
       "20   0.036442  0.422912  0.239857  0.408186  0.286183  0.461490  0.471924   \n",
       "21   0.036442  0.403273  0.280946  0.414804  0.294727  0.495896  0.502688   \n",
       "22   0.039228  0.388904  0.333747  0.417109  0.304897  0.526901  0.538608   \n",
       "23   0.039228  0.379636  0.396703  0.414444  0.315173  0.552916  0.576755   \n",
       "24   0.041438  0.374991  0.467765  0.406509  0.324126  0.572934  0.614099   \n",
       "25   0.041438  0.374263  0.544465  0.393430  0.330545  0.586567  0.647761   \n",
       "26   0.046979  0.376609  0.623988  0.375790  0.333528  0.593989  0.675263   \n",
       "27   0.046979  0.381160  0.703265  0.354587  0.332533  0.595811  0.694737   \n",
       "28   0.049455  0.387133  0.779075  0.331143  0.327404  0.592910  0.705064   \n",
       "29   0.049455  0.393937  0.848166  0.306967  0.318357  0.586246  0.705921   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "545  0.948082  0.433340  0.562803  0.496362  0.202414  0.634265  0.619354   \n",
       "546  0.953404  0.413423  0.551052  0.479274  0.209160  0.617618  0.600093   \n",
       "547  0.953404  0.394677  0.546132  0.458421  0.211728  0.598466  0.573462   \n",
       "548  0.953628  0.377144  0.547469  0.434291  0.208665  0.577343  0.540596   \n",
       "549  0.953628  0.360983  0.553918  0.407641  0.199100  0.554763  0.503244   \n",
       "550  0.958267  0.346545  0.563840  0.379606  0.182926  0.531292  0.463621   \n",
       "551  0.958267  0.334403  0.575264  0.351775  0.160941  0.507635  0.424203   \n",
       "552  0.960958  0.325348  0.586110  0.326211  0.134928  0.484732  0.387510   \n",
       "553  0.960958  0.320361  0.594449  0.305412  0.107647  0.463825  0.355898   \n",
       "554  0.966157  0.320546  0.598771  0.292166  0.082725  0.446472  0.331393   \n",
       "555  0.966157  0.327033  0.598208  0.289349  0.064425  0.434482  0.315577   \n",
       "556  0.968996  0.340850  0.592675  0.299631  0.057307  0.429772  0.309511   \n",
       "557  0.968996  0.362767  0.582888  0.325142  0.065791  0.434130  0.313695   \n",
       "558  0.974209  0.393125  0.570242  0.367115  0.093663  0.448934  0.328045   \n",
       "559  0.974209  0.431669  0.556535  0.425547  0.143543  0.474831  0.351860   \n",
       "560  0.974658  0.477389  0.543597  0.498938  0.216388  0.511462  0.383781   \n",
       "561  0.974658  0.528410  0.532886  0.584140  0.311047  0.557251  0.421750   \n",
       "562  0.981828  0.581959  0.525125  0.676375  0.423946  0.609323  0.462996   \n",
       "563  0.981828  0.634414  0.520043  0.769430  0.548945  0.663567  0.504074   \n",
       "564  0.982174  0.681473  0.516278  0.856032  0.677449  0.714865  0.540980   \n",
       "565  0.982174  0.718430  0.511459  0.928363  0.798805  0.757473  0.569359   \n",
       "566  0.987088  0.740567  0.502456  0.978679  0.901032  0.785519  0.584794   \n",
       "567  0.987088  0.743618  0.485784  1.000000  0.971854  0.793566  0.583191   \n",
       "568  0.989938  0.724253  0.458086  0.986802  1.000000  0.777189  0.561206   \n",
       "569  0.989938  0.680524  0.416643  0.935667  0.976645  0.733487  0.516695   \n",
       "570  0.994802  0.612203  0.359840  0.845824  0.896815  0.661518  0.449092   \n",
       "571  0.994802  0.520948  0.287524  0.719467  0.760500  0.562579  0.359663   \n",
       "572  0.997560  0.410272  0.201182  0.561798  0.573209  0.440273  0.251563   \n",
       "573  0.997560  0.285279  0.103890  0.380687  0.345714  0.300298  0.129643   \n",
       "574  1.000000  0.152203  0.000000  0.185945  0.092905  0.149932  0.000000   \n",
       "\n",
       "            7         8  \n",
       "0    0.000000  0.000000  \n",
       "1    0.211798  0.125419  \n",
       "2    0.411123  0.244359  \n",
       "3    0.586655  0.351238  \n",
       "4    0.729311  0.441683  \n",
       "5    0.833046  0.512862  \n",
       "6    0.895272  0.563576  \n",
       "7    0.916856  0.594170  \n",
       "8    0.901793  0.606316  \n",
       "9    0.856586  0.602730  \n",
       "10   0.789445  0.586863  \n",
       "11   0.709405  0.562579  \n",
       "12   0.625435  0.533836  \n",
       "13   0.545666  0.504366  \n",
       "14   0.476773  0.477395  \n",
       "15   0.423580  0.455417  \n",
       "16   0.388867  0.440051  \n",
       "17   0.373386  0.431993  \n",
       "18   0.376045  0.431055  \n",
       "19   0.394234  0.436284  \n",
       "20   0.424237  0.446138  \n",
       "21   0.461700  0.458721  \n",
       "22   0.502096  0.472032  \n",
       "23   0.541160  0.484218  \n",
       "24   0.575257  0.493795  \n",
       "25   0.601662  0.499796  \n",
       "26   0.618724  0.501837  \n",
       "27   0.625925  0.500090  \n",
       "28   0.623828  0.495188  \n",
       "29   0.613936  0.488086  \n",
       "..        ...       ...  \n",
       "545  0.611355  0.484284  \n",
       "546  0.642993  0.475096  \n",
       "547  0.673851  0.462667  \n",
       "548  0.702674  0.447767  \n",
       "549  0.728184  0.431500  \n",
       "550  0.749053  0.415255  \n",
       "551  0.763933  0.400671  \n",
       "552  0.771552  0.389595  \n",
       "553  0.770871  0.384018  \n",
       "554  0.761270  0.385981  \n",
       "555  0.742711  0.397414  \n",
       "556  0.715810  0.419944  \n",
       "557  0.681816  0.454653  \n",
       "558  0.642483  0.501837  \n",
       "559  0.599875  0.560791  \n",
       "560  0.556143  0.629634  \n",
       "561  0.513288  0.705222  \n",
       "562  0.472940  0.783168  \n",
       "563  0.436167  0.857996  \n",
       "564  0.403340  0.923445  \n",
       "565  0.374087  0.972913  \n",
       "566  0.347355  1.000000  \n",
       "567  0.321572  0.999107  \n",
       "568  0.294901  0.966024  \n",
       "569  0.265548  0.898444  \n",
       "570  0.232070  0.796365  \n",
       "571  0.193657  0.662313  \n",
       "572  0.150311  0.501329  \n",
       "573  0.102896  0.320667  \n",
       "574  0.053033  0.129181  \n",
       "\n",
       "[575 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word ano-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word asul-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word ate-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word baboy-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word binebenta-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word dalawa-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word dito-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word extra-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word gulay-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word gusto-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word hello-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word isa-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word isda-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word itim-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word itlog-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word ito-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word juice-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word kanin-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word kape-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word kayo-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word kilo-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word ko-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word kulay-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word kuya-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word large (shirt)-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word magkano-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word mahal-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word malaki-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word maliit-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word manok-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word mantika-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "Done computing emg features!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "\n",
    "listOfVarianceDataFramePerClass = {}\n",
    "listOfVarianceDataFramePerClass['right'] = []\n",
    "listOfVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMavDataFramePerClass = {}\n",
    "listOfMavDataFramePerClass['right'] = []\n",
    "listOfMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMeanDataFramePerClass = {}\n",
    "listOfMeanDataFramePerClass['right'] = []\n",
    "listOfMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfSdDataFramePerClass = {}\n",
    "listOfSdDataFramePerClass['right'] = []\n",
    "listOfSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfRmsDataFramePerClass = {}\n",
    "listOfRmsDataFramePerClass['right'] = []\n",
    "listOfRmsDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "\n",
    "    for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm + 'variance of EMG1'), (arm + 'variance of EMG2'), (arm + 'variance of EMG3'), (arm + 'variance of EMG4'),\n",
    "                                 (arm + 'variance of EMG5'), (arm + 'variance of EMG6'), (arm + 'variance of EMG7'), (arm + 'variance of EMG8')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm + 'Mav of EMG1'), (arm + 'Mav of EMG2'), (arm + 'Mav of EMG3'), (arm + 'Mav of EMG4'),\n",
    "                                     (arm + 'Mav of EMG5'), (arm + 'Mav of EMG6'), (arm + 'Mav of EMG7'), (arm + 'Mav of EMG8')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm + 'Mean of EMG1'), (arm + 'Mean of EMG2'), (arm + 'Mean of EMG3'), (arm + 'Mean of EMG4'),\n",
    "                                     (arm + 'Mean of EMG5'), (arm + 'Mean of EMG6'), (arm + 'Mean of EMG7'), (arm + 'Mean of EMG8')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm + 'Sd of EMG1'), (arm + 'Sd of EMG2'), (arm + 'Sd of EMG3'), (arm + 'Sd of EMG4'),\n",
    "                                     (arm + 'Sd of EMG5'), (arm + 'Sd of EMG6'), (arm + 'Sd of EMG7'), (arm + 'Sd of EMG8')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm + 'Rms of EMG1'), (arm + 'Rms of EMG2'), (arm + 'Rms of EMG3'), (arm + 'Rms of EMG4'),\n",
    "                                     (arm + 'Rms of EMG5'), (arm + 'Rms of EMG6'), (arm + 'Rms of EMG7'), (arm + 'Rms of EMG8')])\n",
    "        for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg'][a]:\n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3], df_normalized.var()[4], df_normalized.var()[5], df_normalized.var()[6], df_normalized.var()[7], df_normalized.var()[8]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3], robust.mad(df_normalized)[4], robust.mad(df_normalized)[5], robust.mad(df_normalized)[6], robust.mad(df_normalized)[7], robust.mad(df_normalized)[8]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3], np.mean(df_normalized)[4], np.mean(df_normalized)[5], np.mean(df_normalized)[6], np.mean(df_normalized)[7], np.mean(df_normalized)[8]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3], np.std(df_normalized)[4], np.std(df_normalized)[5], np.std(df_normalized)[6], np.std(df_normalized)[7], np.std(df_normalized)[8]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2)), np.sqrt(np.mean(df_normalized[4].values**2)), np.sqrt(np.mean(df_normalized[5].values**2)), np.sqrt(np.mean(df_normalized[6].values**2)),  np.sqrt(np.mean(df_normalized[6].values**2)), np.sqrt(np.mean(df_normalized[8].values**2))]\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "    \n",
    "        print(\"Done computing the var, mav, mean , sd, and rms of \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing emg features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and Median Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word ano-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word asul-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word ate-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word baboy-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word binebenta-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word dalawa-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word dito-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word extra-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word gulay-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word gusto-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word hello-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word isa-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word isda-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word itim-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word itlog-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word ito-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word juice-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word kanin-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word kape-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word kayo-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word kilo-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word ko-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word kulay-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word kuya-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word large (shirt)-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word magkano-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word mahal-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word malaki-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word maliit-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word manok-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word mantika-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "Done computing emg features!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "listOfMeanFreqDataFramePerClass = {}\n",
    "listOfMeanFreqDataFramePerClass['right'] = []\n",
    "listOfMeanFreqDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMedFreqDataFramePerClass = {}\n",
    "listOfMedFreqDataFramePerClass['right'] = []\n",
    "listOfMedFreqDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    \n",
    "    for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        meanFreqDataFrame = pd.DataFrame(columns = [(arm + 'MeanFreq of EMG1'), (arm + 'MeanFreq of EMG2'), (arm + 'MeanFreq of EMG3'), (arm + 'MeanFreq of EMG4'),\n",
    "                                 (arm + 'MeanFreq of EMG5'), (arm + 'MeanFreq of EMG6'), (arm + 'MeanFreq of EMG7'), (arm + 'MeanFreq of EMG8')]) \n",
    "\n",
    "        medFreqDataFrame = pd.DataFrame(columns = [(arm + 'MedianFreq of EMG1'), (arm + 'MedianFreq of EMG2'), (arm + 'MedianFreq of EMG3'), (arm + 'MedianFreq of EMG4'),\n",
    "                                     (arm + 'MedianFreq of EMG5'), (arm + 'MedianFreq of EMG6'), (arm + 'MedianFreq of EMG7'), (arm + 'MedianFreq of EMG8')])\n",
    "\n",
    "        for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg'][a]:\n",
    "            meanFreq = []\n",
    "            medFreq = []\n",
    "\n",
    "            for i in range(1, 9):\n",
    "                data = df_normalized[i].values\n",
    "                ps = np.abs(np.fft.fft(data))**2\n",
    "\n",
    "                freqs = np.fft.fftfreq(data.size, 1/100)\n",
    "\n",
    "                sumProd = 0\n",
    "                sumPs = 0\n",
    "\n",
    "                for f, p in zip(freqs,ps):\n",
    "                    sumProd += f*p\n",
    "                    sumPs += p\n",
    "                \n",
    "                sumProd = sumProd * 100000000\n",
    "                meanFreq.append(100000000*sumProd/sumPs)\n",
    "                medFreq.append(sumPs/2)\n",
    "                \n",
    "            \n",
    "            meanFreqDataFrame.loc[ctr] = [meanFreq[0], meanFreq[1], meanFreq[2], meanFreq[3], meanFreq[4], meanFreq[5], meanFreq[6], meanFreq[7]]\n",
    "            medFreqDataFrame.loc[ctr] = [medFreq[0], medFreq[1], medFreq[2], medFreq[3], medFreq[4], medFreq[5], medFreq[6], medFreq[7]]\n",
    "\n",
    "            ctr+=1\n",
    "        listOfMeanFreqDataFramePerClass[a].append(meanFreqDataFrame)\n",
    "        listOfMedFreqDataFramePerClass[a].append(medFreqDataFrame)\n",
    "        print(\"Done computing Mean and Median Frequency of \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing emg features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAMP, WL, ZC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# listOfWAMPDataFramePerClass = {}\n",
    "# listOfWAMPDataFramePerClass['right'] = []\n",
    "# listOfWAMPDataFramePerClass['left'] = []\n",
    "\n",
    "# listOfWLDataFramePerClass = {}\n",
    "# listOfWLDataFramePerClass['right'] = []\n",
    "# listOfWLDataFramePerClass['left'] = []\n",
    "\n",
    "# listOfZCDataFramePerClass = {}\n",
    "# listOfZCDataFramePerClass['right'] = []\n",
    "# listOfZCDataFramePerClass['left'] = []\n",
    "\n",
    "# for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "#     print(\"----------------- Word \" + k + \"-----------------\")\n",
    "#     ctr = 0\n",
    "    \n",
    "    \n",
    "#     for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "#         ctr = 0\n",
    "#         arm = a + \" \"\n",
    "\n",
    "#         wampDataFrame = pd.DataFrame(columns = [(arm + 'WAMP of EMG1'), (arm + 'WAMP of EMG2'), (arm + 'WAMP of EMG3'), (arm + 'WAMP of EMG4'),\n",
    "#                                  (arm + 'WAMP of EMG5'), (arm + 'WAMP of EMG6'), (arm + 'WAMP of EMG7'), (arm + 'WAMP of EMG8')]) \n",
    "\n",
    "#         wlFreqDataFrame = pd.DataFrame(columns = [(arm + 'WL of EMG1'), (arm + 'WL of EMG2'), (arm + 'WL of EMG3'), (arm + 'WL of EMG4'),\n",
    "#                                      (arm + 'WL of EMG5'), (arm + 'WL of EMG6'), (arm + 'WL of EMG7'), (arm + 'WL of EMG8')])\n",
    "        \n",
    "#         zcFreqDataFrame = pd.DataFrame(columns = [(arm + 'ZC of EMG1'), (arm + 'ZC of EMG2'), (arm + 'ZC of EMG3'), (arm + 'ZC of EMG4'),\n",
    "#                                      (arm + 'ZC of EMG5'), (arm + 'ZC of EMG6'), (arm + 'ZC of EMG7'), (arm + 'ZC of EMG8')])\n",
    "\n",
    "       \n",
    "#             meanFreqDataFrame.loc[ctr] = [meanFreq[0], meanFreq[1], meanFreq[2], meanFreq[3], meanFreq[4], meanFreq[5], meanFreq[6], meanFreq[7]]\n",
    "#             medFreqDataFrame.loc[ctr] = [medFreq[0], medFreq[1], medFreq[2], medFreq[3], medFreq[4], medFreq[5], medFreq[6], medFreq[7]]\n",
    "\n",
    "#             ctr+=1\n",
    "#         listOfMeanFreqDataFramePerClass[a].append(meanFreqDataFrame)\n",
    "#         listOfMedFreqDataFramePerClass[a].append(medFreqDataFrame)\n",
    "#         print(\"Done computing Mean and Median Frequency of \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "# print(\"Done computing emg features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done labeling emg data of ano right arm files\n",
      "Done labeling emg data of asul right arm files\n",
      "Done labeling emg data of ate right arm files\n",
      "Done labeling emg data of baboy right arm files\n",
      "Done labeling emg data of binebenta right arm files\n",
      "Done labeling emg data of dalawa right arm files\n",
      "Done labeling emg data of dito right arm files\n",
      "Done labeling emg data of extra right arm files\n",
      "Done labeling emg data of gulay right arm files\n",
      "Done labeling emg data of gusto right arm files\n",
      "Done labeling emg data of hello right arm files\n",
      "Done labeling emg data of isa right arm files\n",
      "Done labeling emg data of isda right arm files\n",
      "Done labeling emg data of itim right arm files\n",
      "Done labeling emg data of itlog right arm files\n",
      "Done labeling emg data of ito right arm files\n",
      "Done labeling emg data of juice right arm files\n",
      "Done labeling emg data of kanin right arm files\n",
      "Done labeling emg data of kape right arm files\n",
      "Done labeling emg data of kayo right arm files\n",
      "Done labeling emg data of kilo right arm files\n",
      "Done labeling emg data of ko right arm files\n",
      "Done labeling emg data of kulay right arm files\n",
      "Done labeling emg data of kuya right arm files\n",
      "Done labeling emg data of large (shirt) right arm files\n",
      "Done labeling emg data of magkano right arm files\n",
      "Done labeling emg data of mahal right arm files\n",
      "Done labeling emg data of malaki right arm files\n",
      "Done labeling emg data of maliit right arm files\n",
      "Done labeling emg data of manok right arm files\n",
      "Done labeling emg data of mantika right arm files\n",
      "Done labeling emg data of ano left arm files\n",
      "Done labeling emg data of asul left arm files\n",
      "Done labeling emg data of ate left arm files\n",
      "Done labeling emg data of baboy left arm files\n",
      "Done labeling emg data of binebenta left arm files\n",
      "Done labeling emg data of dalawa left arm files\n",
      "Done labeling emg data of dito left arm files\n",
      "Done labeling emg data of extra left arm files\n",
      "Done labeling emg data of gulay left arm files\n",
      "Done labeling emg data of gusto left arm files\n",
      "Done labeling emg data of hello left arm files\n",
      "Done labeling emg data of isa left arm files\n",
      "Done labeling emg data of isda left arm files\n",
      "Done labeling emg data of itim left arm files\n",
      "Done labeling emg data of itlog left arm files\n",
      "Done labeling emg data of ito left arm files\n",
      "Done labeling emg data of juice left arm files\n",
      "Done labeling emg data of kanin left arm files\n",
      "Done labeling emg data of kape left arm files\n",
      "Done labeling emg data of kayo left arm files\n",
      "Done labeling emg data of kilo left arm files\n",
      "Done labeling emg data of ko left arm files\n",
      "Done labeling emg data of kulay left arm files\n",
      "Done labeling emg data of kuya left arm files\n",
      "Done labeling emg data of large (shirt) left arm files\n",
      "Done labeling emg data of magkano left arm files\n",
      "Done labeling emg data of mahal left arm files\n",
      "Done labeling emg data of malaki left arm files\n",
      "Done labeling emg data of maliit left arm files\n",
      "Done labeling emg data of manok left arm files\n",
      "Done labeling emg data of mantika left arm files\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "\n",
    "listOfLabeledDataPerClass = {}\n",
    "listOfLabeledDataPerClass['right'] = {}\n",
    "listOfLabeledDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "\n",
    "    dataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        dataFramesPerFeature['variance'] = listOfVarianceDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['mav'] = listOfMavDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['rms'] = listOfRmsDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['sd'] = listOfSdDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['mean'] = listOfMeanDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['medFreq'] = listOfMedFreqDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['meanFreq'] = listOfMeanFreqDataFramePerClass[a][ctr]\n",
    "    \n",
    "\n",
    "        for k2 in dataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in dataFramesPerFeature[k2].columns:\n",
    "                    dataFramesPerFeature['variance'][i] = dataFramesPerFeature[k2][i]\n",
    "        \n",
    "        dataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledDataPerClass[a][k] = dataFramesPerFeature['variance']\n",
    "        print(\"Done labeling emg data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For IMU values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization (For Acceleration and Gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word ano-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word asul-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word ate-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word baboy-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word binebenta-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word dalawa-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word dito-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word extra-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word gulay-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word gusto-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word hello-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word isa-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word isda-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word itim-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word itlog-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word ito-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word juice-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kanin-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kape-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kayo-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kilo-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word ko-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kulay-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kuya-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word large (shirt)-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word magkano-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word mahal-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word malaki-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word maliit-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word manok-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word mantika-----------------\n",
      "Done Normalizing 200 files\n",
      "Acc Data Normalization done!!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedAccDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['acc']:\n",
    "        for d in listOfDataFramesPerClass[k]['acc'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"acc\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedAccDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Acc Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word ano-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word asul-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word ate-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word baboy-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word binebenta-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word dalawa-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word dito-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word extra-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word gulay-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word gusto-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word hello-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word isa-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word isda-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word itim-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word itlog-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word ito-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word juice-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kanin-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kape-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kayo-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kilo-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word ko-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kulay-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kuya-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word large (shirt)-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word magkano-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word mahal-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word malaki-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word maliit-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word manok-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word mantika-----------------\n",
      "Done Normalizing 200 files\n",
      "Gyro Data Normalization done!!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedGyroDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['gyro']:\n",
    "        for d in listOfDataFramesPerClass[k]['gyro'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "           \n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"gyro\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedGyroDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Gyro Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word ano-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darre\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2505: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word asul-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word ate-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word baboy-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word binebenta-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word dalawa-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word dito-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word extra-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word gulay-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word gusto-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word hello-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word isa-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word isda-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word itim-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word itlog-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word ito-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word juice-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word kanin-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word kape-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word kayo-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word kilo-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word ko-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word kulay-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word kuya-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word large (shirt)-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word magkano-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word mahal-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word malaki-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word maliit-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word manok-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word mantika-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "Done computing acc features!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "#kurtosis\n",
    "#standarddev\n",
    "#mean\n",
    "#variance\n",
    "#entropy\n",
    "#meanabsval\n",
    "#rootmeansquare\n",
    "#Signal Magnitude Area\n",
    "#Integration\n",
    "\n",
    "listOfAccVarianceDataFramePerClass = {}\n",
    "listOfAccVarianceDataFramePerClass['right'] = []\n",
    "listOfAccVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccMavDataFramePerClass = {}\n",
    "listOfAccMavDataFramePerClass['right'] = []\n",
    "listOfAccMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccMeanDataFramePerClass = {}\n",
    "listOfAccMeanDataFramePerClass['right'] = []\n",
    "listOfAccMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccSdDataFramePerClass = {}\n",
    "listOfAccSdDataFramePerClass['right'] = []\n",
    "listOfAccSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccRmsDataFramePerClass = {}\n",
    "listOfAccRmsDataFramePerClass['right'] = []\n",
    "listOfAccRmsDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccEntropyDataFramePerClass = {}\n",
    "listOfAccEntropyDataFramePerClass['right'] = []\n",
    "listOfAccEntropyDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccKurtosisDataFramePerClass = {}\n",
    "listOfAccKurtosisDataFramePerClass['right'] = []\n",
    "listOfAccKurtosisDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccSkewnessDataFramePerClass = {}\n",
    "listOfAccSkewnessDataFramePerClass['right'] = []\n",
    "listOfAccSkewnessDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccSmaDataFramePerClass = {}\n",
    "listOfAccSmaDataFramePerClass['right'] = []\n",
    "listOfAccSmaDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccIntegrationDataFramePerClass = {}\n",
    "listOfAccIntegrationDataFramePerClass['right'] = []\n",
    "listOfAccIntegrationDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedAccDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm+ 'Variance of ACC x'), (arm+ 'Variance of ACC y'), (arm+ 'Variance of ACC z')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm + 'Mav of ACC x'), (arm + 'Mav of ACC y'), (arm + 'Mav of ACC z')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm + 'Mean of ACC x'), (arm + 'Mean of ACC y'), (arm + 'Mean of ACC z')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm + 'Sd of ACC x'), (arm + 'Sd of ACC y'), (arm + 'Sd of ACC z')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm + 'Rms of ACC x'), (arm + 'Rms of ACC y'), (arm + 'Rms of ACC z')])\n",
    "        entropyDataFrame = pd.DataFrame(columns = [(arm + 'Entropy of ACC x'), (arm + 'Entropy of ACC y'), (arm + 'Entropy of ACC z')])\n",
    "        kurtosisDataFrame = pd.DataFrame(columns = [(arm + 'Kurtosis of ACC x'), (arm + 'Kurtosis of ACC y'), (arm + 'Kurtosis of ACC z')])\n",
    "        skewnessDataFrame = pd.DataFrame(columns = [(arm + 'Skewness of ACC x'), (arm + 'Skewness of ACC y'), (arm + 'Skewness of ACC z')])\n",
    "        smaDataFrame = pd.DataFrame(columns = [(arm + 'SMA of ACC')])\n",
    "        integrationDataFrame = pd.DataFrame(columns = [(arm + 'Integration of ACC x'), (arm + 'Integration of ACC y'), (arm + 'Integration of ACC z')])\n",
    "\n",
    "        \n",
    "        for df_normalized in listOfNormalizedAccDataFramesPerClass[k]['acc'][a]:\n",
    "            \n",
    "#             print(\"df_normalized\")\n",
    "#             time.sleep(5.5) \n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2))]\n",
    "            entropyDataFrame.loc[ctr] = [sp.stats.entropy(df_normalized)[1], sp.stats.entropy(df_normalized)[2], sp.stats.entropy(df_normalized)[3]]\n",
    "            kurtosisDataFrame.loc[ctr] = [df_normalized.kurtosis()[1], df_normalized.kurtosis()[2], df_normalized.kurtosis()[3]]\n",
    "            skewnessDataFrame.loc[ctr] = [df_normalized.skew(axis=0)[1], df_normalized.skew(axis=0)[2], df_normalized.skew(axis=0)[3]]\n",
    "            length = df_normalized.shape[1]\n",
    "            sma = 0\n",
    "            for x in range(0, length):\n",
    "                # .iloc[x,0] is accessing row, column\n",
    "                sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "            sma = sma / length\n",
    "            smaDataFrame.loc[ctr] = [sma]\n",
    "            integrationDataFrame.loc[ctr] = [sp.integrate.simps(df_normalized, axis=0)[1],sp.integrate.simps(df_normalized, axis=0)[2], sp.integrate.simps(df_normalized, axis=0)[3]]\n",
    "\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfAccVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfAccMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfAccMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfAccSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfAccRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "        listOfAccEntropyDataFramePerClass[a].append(entropyDataFrame) \n",
    "        listOfAccKurtosisDataFramePerClass[a].append(kurtosisDataFrame) \n",
    "        listOfAccSkewnessDataFramePerClass[a].append(skewnessDataFrame) \n",
    "        listOfAccSmaDataFramePerClass[a].append(smaDataFrame) \n",
    "        listOfAccIntegrationDataFramePerClass[a].append(integrationDataFrame) \n",
    "        \n",
    "        print(\"Done computing acc features \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing acc features!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word ano-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word asul-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word ate-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word baboy-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word binebenta-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word dalawa-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word dito-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word extra-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word gulay-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word gusto-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word hello-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word isa-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word isda-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word itim-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word itlog-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word ito-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word juice-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word kanin-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word kape-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word kayo-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word kilo-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word ko-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word kulay-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word kuya-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word large (shirt)-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word magkano-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word mahal-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word malaki-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word maliit-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word manok-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word mantika-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "Done computing gyro features!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "#kurtosis\n",
    "#standarddev\n",
    "#mean\n",
    "#variance\n",
    "#entropy\n",
    "#meanabsval\n",
    "#rootmeansquare\n",
    "#Signal Magnitude Area\n",
    "#Integration\n",
    "\n",
    "listOfGyroVarianceDataFramePerClass = {}\n",
    "listOfGyroVarianceDataFramePerClass['right'] = []\n",
    "listOfGyroVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroMavDataFramePerClass = {}\n",
    "listOfGyroMavDataFramePerClass['right'] = []\n",
    "listOfGyroMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroMeanDataFramePerClass = {}\n",
    "listOfGyroMeanDataFramePerClass['right'] = []\n",
    "listOfGyroMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSdDataFramePerClass = {}\n",
    "listOfGyroSdDataFramePerClass['right'] = []\n",
    "listOfGyroSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroRmsDataFramePerClass = {}\n",
    "listOfGyroRmsDataFramePerClass['right'] = []\n",
    "listOfGyroRmsDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroEntropyDataFramePerClass = {}\n",
    "listOfGyroEntropyDataFramePerClass['right'] = []\n",
    "listOfGyroEntropyDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroKurtosisDataFramePerClass = {}\n",
    "listOfGyroKurtosisDataFramePerClass['right'] = []\n",
    "listOfGyroKurtosisDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSkewnessDataFramePerClass = {}\n",
    "listOfGyroSkewnessDataFramePerClass['right'] = []\n",
    "listOfGyroSkewnessDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSmaDataFramePerClass = {}\n",
    "listOfGyroSmaDataFramePerClass['right'] = []\n",
    "listOfGyroSmaDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroIntegrationDataFramePerClass = {}\n",
    "listOfGyroIntegrationDataFramePerClass['right'] = []\n",
    "listOfGyroIntegrationDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedGyroDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm + 'Variance of Gyro x'), (arm+ 'Variance of Gyro y'), (arm+ 'Variance of Gyro z')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm+ 'Mav of Gyro x'), (arm+ 'Mav of Gyro y'), (arm+ 'Mav of Gyro z')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm+ 'Mean of Gyro x'), (arm+ 'Mean of Gyro y'), (arm+ 'Mean of Gyro z')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm+ 'Sd of Gyro x'), (arm+ 'Sd of Gyro y'), (arm+ 'Sd of Gyro z')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm+ 'Rms of Gyro x'), (arm+ 'Rms of Gyro y'), (arm+ 'Rms of Gyro z')])\n",
    "        entropyDataFrame = pd.DataFrame(columns = [(arm+ 'Entropy of Gyro x'), (arm+ 'Entropy of Gyro y'), (arm+ 'Entropy of Gyro z')])\n",
    "        kurtosisDataFrame = pd.DataFrame(columns = [(arm+ 'Kurtosis of Gyro x'), (arm+ 'Kurtosis of Gyro y'), (arm+ 'Kurtosis of Gyro z')])\n",
    "        skewnessDataFrame = pd.DataFrame(columns = [(arm+ 'Skewness of Gyro x'), (arm+ 'Skewness of Gyro y'), (arm+ 'Skewness of Gyro z')])\n",
    "        smaDataFrame = pd.DataFrame(columns = [(arm+ 'SMA of Gyro')])\n",
    "        integrationDataFrame = pd.DataFrame(columns = [(arm+ 'Integration of Gyro x'), (arm+ 'Integration of Gyro y'), (arm+ 'Integration of Gyro z')])\n",
    "\n",
    "        \n",
    "        for df_normalized in listOfNormalizedGyroDataFramesPerClass[k]['gyro'][a]:\n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2))]\n",
    "            entropyDataFrame.loc[ctr] = [sp.stats.entropy(df_normalized)[1], sp.stats.entropy(df_normalized)[2], sp.stats.entropy(df_normalized)[3],]\n",
    "            kurtosisDataFrame.loc[ctr] = [df_normalized.kurtosis()[1], df_normalized.kurtosis()[2], df_normalized.kurtosis()[3]]\n",
    "            skewnessDataFrame.loc[ctr] = [df_normalized.skew(axis=0)[1], df_normalized.skew(axis=0)[2], df_normalized.skew(axis=0)[3]]\n",
    "            length = df_normalized.shape[1]\n",
    "            sma = 0\n",
    "            for x in range(0, length):\n",
    "                # .iloc[x,0] is Gyroessing row, column\n",
    "                sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "            sma = sma / length\n",
    "            smaDataFrame.loc[ctr] = [sma]\n",
    "            integrationDataFrame.loc[ctr] = [sp.integrate.simps(df_normalized, axis=0)[1],sp.integrate.simps(df_normalized, axis=0)[2], sp.integrate.simps(df_normalized, axis=0)[3]]\n",
    "\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfGyroVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfGyroMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfGyroMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfGyroSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfGyroRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "        listOfGyroEntropyDataFramePerClass[a].append(entropyDataFrame) \n",
    "        listOfGyroKurtosisDataFramePerClass[a].append(kurtosisDataFrame) \n",
    "        listOfGyroSkewnessDataFramePerClass[a].append(skewnessDataFrame) \n",
    "        listOfGyroSmaDataFramePerClass[a].append(smaDataFrame) \n",
    "        listOfGyroIntegrationDataFramePerClass[a].append(integrationDataFrame) \n",
    "        \n",
    "        print(\"Done computing Gyro features \" + str(ctr) + a + \" arm files\")\n",
    "        \n",
    "print(\"Done computing gyro features!!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done labeling acc data of ano right arm files\n",
      "Done labeling acc data of asul right arm files\n",
      "Done labeling acc data of ate right arm files\n",
      "Done labeling acc data of baboy right arm files\n",
      "Done labeling acc data of binebenta right arm files\n",
      "Done labeling acc data of dalawa right arm files\n",
      "Done labeling acc data of dito right arm files\n",
      "Done labeling acc data of extra right arm files\n",
      "Done labeling acc data of gulay right arm files\n",
      "Done labeling acc data of gusto right arm files\n",
      "Done labeling acc data of hello right arm files\n",
      "Done labeling acc data of isa right arm files\n",
      "Done labeling acc data of isda right arm files\n",
      "Done labeling acc data of itim right arm files\n",
      "Done labeling acc data of itlog right arm files\n",
      "Done labeling acc data of ito right arm files\n",
      "Done labeling acc data of juice right arm files\n",
      "Done labeling acc data of kanin right arm files\n",
      "Done labeling acc data of kape right arm files\n",
      "Done labeling acc data of kayo right arm files\n",
      "Done labeling acc data of kilo right arm files\n",
      "Done labeling acc data of ko right arm files\n",
      "Done labeling acc data of kulay right arm files\n",
      "Done labeling acc data of kuya right arm files\n",
      "Done labeling acc data of large (shirt) right arm files\n",
      "Done labeling acc data of magkano right arm files\n",
      "Done labeling acc data of mahal right arm files\n",
      "Done labeling acc data of malaki right arm files\n",
      "Done labeling acc data of maliit right arm files\n",
      "Done labeling acc data of manok right arm files\n",
      "Done labeling acc data of mantika right arm files\n",
      "Done labeling acc data of ano left arm files\n",
      "Done labeling acc data of asul left arm files\n",
      "Done labeling acc data of ate left arm files\n",
      "Done labeling acc data of baboy left arm files\n",
      "Done labeling acc data of binebenta left arm files\n",
      "Done labeling acc data of dalawa left arm files\n",
      "Done labeling acc data of dito left arm files\n",
      "Done labeling acc data of extra left arm files\n",
      "Done labeling acc data of gulay left arm files\n",
      "Done labeling acc data of gusto left arm files\n",
      "Done labeling acc data of hello left arm files\n",
      "Done labeling acc data of isa left arm files\n",
      "Done labeling acc data of isda left arm files\n",
      "Done labeling acc data of itim left arm files\n",
      "Done labeling acc data of itlog left arm files\n",
      "Done labeling acc data of ito left arm files\n",
      "Done labeling acc data of juice left arm files\n",
      "Done labeling acc data of kanin left arm files\n",
      "Done labeling acc data of kape left arm files\n",
      "Done labeling acc data of kayo left arm files\n",
      "Done labeling acc data of kilo left arm files\n",
      "Done labeling acc data of ko left arm files\n",
      "Done labeling acc data of kulay left arm files\n",
      "Done labeling acc data of kuya left arm files\n",
      "Done labeling acc data of large (shirt) left arm files\n",
      "Done labeling acc data of magkano left arm files\n",
      "Done labeling acc data of mahal left arm files\n",
      "Done labeling acc data of malaki left arm files\n",
      "Done labeling acc data of maliit left arm files\n",
      "Done labeling acc data of manok left arm files\n",
      "Done labeling acc data of mantika left arm files\n"
     ]
    }
   ],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "ctr = 0\n",
    "\n",
    "listOfLabeledAccDataPerClass = {}\n",
    "listOfLabeledAccDataPerClass['right'] = {}\n",
    "listOfLabeledAccDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfDataFramesPerClass[k]['acc']:\n",
    "\n",
    "    accDataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        accDataFramesPerFeature['variance'] = listOfAccVarianceDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['mav'] = listOfAccMavDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['rms'] = listOfAccRmsDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['sd'] = listOfAccSdDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['mean'] = listOfAccMeanDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['entropy'] = listOfAccEntropyDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['kurtosis'] = listOfAccKurtosisDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['skewness'] = listOfAccSkewnessDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['sma'] = listOfAccSmaDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['integration'] = listOfAccIntegrationDataFramePerClass[a][ctr]\n",
    "\n",
    "        for k2 in accDataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in accDataFramesPerFeature[k2].columns:\n",
    "                    accDataFramesPerFeature['variance'][i] = accDataFramesPerFeature[k2][i]\n",
    "        \n",
    "        accDataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledAccDataPerClass[a][k] = accDataFramesPerFeature['variance']\n",
    "        print(\"Done labeling acc data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done labeling Gyro data of ano left arm files\n",
      "Done labeling Gyro data of asul left arm files\n",
      "Done labeling Gyro data of ate left arm files\n",
      "Done labeling Gyro data of baboy left arm files\n",
      "Done labeling Gyro data of binebenta left arm files\n",
      "Done labeling Gyro data of dalawa left arm files\n",
      "Done labeling Gyro data of dito left arm files\n",
      "Done labeling Gyro data of extra left arm files\n",
      "Done labeling Gyro data of gulay left arm files\n",
      "Done labeling Gyro data of gusto left arm files\n",
      "Done labeling Gyro data of hello left arm files\n",
      "Done labeling Gyro data of isa left arm files\n",
      "Done labeling Gyro data of isda left arm files\n",
      "Done labeling Gyro data of itim left arm files\n",
      "Done labeling Gyro data of itlog left arm files\n",
      "Done labeling Gyro data of ito left arm files\n",
      "Done labeling Gyro data of juice left arm files\n",
      "Done labeling Gyro data of kanin left arm files\n",
      "Done labeling Gyro data of kape left arm files\n",
      "Done labeling Gyro data of kayo left arm files\n",
      "Done labeling Gyro data of kilo left arm files\n",
      "Done labeling Gyro data of ko left arm files\n",
      "Done labeling Gyro data of kulay left arm files\n",
      "Done labeling Gyro data of kuya left arm files\n",
      "Done labeling Gyro data of large (shirt) left arm files\n",
      "Done labeling Gyro data of magkano left arm files\n",
      "Done labeling Gyro data of mahal left arm files\n",
      "Done labeling Gyro data of malaki left arm files\n",
      "Done labeling Gyro data of maliit left arm files\n",
      "Done labeling Gyro data of manok left arm files\n",
      "Done labeling Gyro data of mantika left arm files\n",
      "Done labeling Gyro data of ano right arm files\n",
      "Done labeling Gyro data of asul right arm files\n",
      "Done labeling Gyro data of ate right arm files\n",
      "Done labeling Gyro data of baboy right arm files\n",
      "Done labeling Gyro data of binebenta right arm files\n",
      "Done labeling Gyro data of dalawa right arm files\n",
      "Done labeling Gyro data of dito right arm files\n",
      "Done labeling Gyro data of extra right arm files\n",
      "Done labeling Gyro data of gulay right arm files\n",
      "Done labeling Gyro data of gusto right arm files\n",
      "Done labeling Gyro data of hello right arm files\n",
      "Done labeling Gyro data of isa right arm files\n",
      "Done labeling Gyro data of isda right arm files\n",
      "Done labeling Gyro data of itim right arm files\n",
      "Done labeling Gyro data of itlog right arm files\n",
      "Done labeling Gyro data of ito right arm files\n",
      "Done labeling Gyro data of juice right arm files\n",
      "Done labeling Gyro data of kanin right arm files\n",
      "Done labeling Gyro data of kape right arm files\n",
      "Done labeling Gyro data of kayo right arm files\n",
      "Done labeling Gyro data of kilo right arm files\n",
      "Done labeling Gyro data of ko right arm files\n",
      "Done labeling Gyro data of kulay right arm files\n",
      "Done labeling Gyro data of kuya right arm files\n",
      "Done labeling Gyro data of large (shirt) right arm files\n",
      "Done labeling Gyro data of magkano right arm files\n",
      "Done labeling Gyro data of mahal right arm files\n",
      "Done labeling Gyro data of malaki right arm files\n",
      "Done labeling Gyro data of maliit right arm files\n",
      "Done labeling Gyro data of manok right arm files\n",
      "Done labeling Gyro data of mantika right arm files\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "\n",
    "listOfLabeledGyroDataPerClass = {}\n",
    "listOfLabeledGyroDataPerClass['right'] = {}\n",
    "listOfLabeledGyroDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "\n",
    "    GyroDataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        GyroDataFramesPerFeature['variance'] = listOfGyroVarianceDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['mav'] = listOfGyroMavDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['rms'] = listOfGyroRmsDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['sd'] = listOfGyroSdDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['mean'] = listOfGyroMeanDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['entropy'] = listOfGyroEntropyDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['kurtosis'] = listOfGyroKurtosisDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['skewness'] = listOfGyroSkewnessDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['sma'] = listOfGyroSmaDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['integration'] = listOfGyroIntegrationDataFramePerClass[a][ctr]\n",
    "\n",
    "        for k2 in GyroDataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in GyroDataFramesPerFeature[k2].columns:\n",
    "                    GyroDataFramesPerFeature['variance'][i] = GyroDataFramesPerFeature[k2][i]\n",
    "        \n",
    "        GyroDataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledGyroDataPerClass[a][k] = GyroDataFramesPerFeature['variance']\n",
    "        print(\"Done labeling Gyro data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asul\n",
      "ate\n",
      "baboy\n",
      "binebenta\n",
      "dalawa\n",
      "dito\n",
      "extra\n",
      "gulay\n",
      "gusto\n",
      "hello\n",
      "isa\n",
      "isda\n",
      "itim\n",
      "itlog\n",
      "ito\n",
      "juice\n",
      "kanin\n",
      "kape\n",
      "kayo\n",
      "kilo\n",
      "ko\n",
      "kulay\n",
      "kuya\n",
      "large (shirt)\n",
      "magkano\n",
      "mahal\n",
      "malaki\n",
      "maliit\n",
      "manok\n",
      "mantika\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test = listOfLabeledGyroDataPerClass['left']['ano']\n",
    "testPerClass = {}\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    #print(('%s %s') % (a, k))\n",
    "    testPerClass[k] = []\n",
    "    test = listOfLabeledGyroDataPerClass['left'][k]\n",
    "    for i in listOfLabeledGyroDataPerClass['right'][k]:\n",
    "        test[i] = listOfLabeledGyroDataPerClass['right'][k][i]\n",
    "    for i in listOfLabeledAccDataPerClass['left'][k].columns:\n",
    "        test[i] = listOfLabeledAccDataPerClass['left'][k][i]\n",
    "    for i in listOfLabeledAccDataPerClass['right'][k].columns:\n",
    "        test[i] = listOfLabeledAccDataPerClass['right'][k][i]\n",
    "    for i in listOfLabeledDataPerClass['left'][k].columns:\n",
    "        test[i] = listOfLabeledDataPerClass['left'][k][i]\n",
    "    for i in listOfLabeledDataPerClass['right'][k].columns:\n",
    "        test[i] = listOfLabeledDataPerClass['right'][k][i]                        #emg data\n",
    "    testPerClass[k] = test\n",
    "# test\n",
    "# test.to_csv('/Users/user/Desktop/test.csv', encoding='utf-8', index=False)\n",
    "newDf = testPerClass['ano']\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    if k != 'ano':\n",
    "        print(k)\n",
    "        newDf= newDf.append(testPerClass[k]) \n",
    "\n",
    "df = newDf\n",
    "df = df[pd.notnull(df['left MeanFreq of EMG1'])]\n",
    "df = df[pd.notnull(df['right MeanFreq of EMG1'])]\n",
    "df = df[pd.notnull(df['left MeanFreq of EMG5'])]\n",
    "\n",
    "classNames = df[\"Class\"].tolist()\n",
    "\n",
    "\n",
    "df = df.drop(\"Class\", axis=1)\n",
    "\n",
    "x = df.values.astype(np.float64)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "df = pd.DataFrame(x_scaled,columns=df.columns)\n",
    "\n",
    "df[\"Class\"] = classNames\n",
    "\n",
    "df.to_csv('WithEmgFilter-Onearm.csv', encoding='utf-8', index=False)\n",
    "newDf.to_csv('WithEmgFilter-NoNormalization.csv', encoding='utf-8', index=False)\n",
    "#df.to_csv('ConsolidatedData-Normalized(Trimmed).csv', encoding='utf-8', index=False)\n",
    "#newDf.to_csv('ConsolidatedData-Original(Trimmed).csv', encoding='utf-8', index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ((-7.493890 - np.mean(newDf[\"left MeanFreq of EMG1\"]))/np.max(newDf[\"left MeanFreq of EMG1\"])-np.min(newDf[\"left MeanFreq of EMG1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mFreq = newDf[\"left MeanFreq of EMG1\"]\n",
    "# for i in mFreq:\n",
    "#     maxFreq = np.max(mFreq)\n",
    "#     minFreq = np.min(mFreq)\n",
    "#     meanFreq = np.mean(mFreq)\n",
    "    \n",
    "#     print(\"(%f - %f) / (%f - %f) = %f\" % (i, meanFreq, maxFreq, minFreq, (i-meanFreq)/(maxFreq-minFreq)))\n",
    "#     print((i - np.mean(mFreq))/(np.max(mFreq)-np.min(mFreq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classNames = newDf[\"Class\"].tolist()\n",
    "\n",
    "# df = newDf.drop(\"Class\", axis=1)\n",
    "# df = df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "# df[\"Class\"] = classNames\n",
    "\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('ConsolidatedData.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDf.to_csv('ConsolidatedData-Original.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.isnull().T.any().T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df[df.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDf[225:] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDf.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(newDf[\"left MeanFreq of EMG1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# rightMeanFreq1 = df[\"right MeanFreq of EMG1\"].tolist()\n",
    "# rightMeanFreq2 = df[\"right MeanFreq of EMG2\"].tolist()\n",
    "# rightMeanFreq3 = df[\"right MeanFreq of EMG3\"].tolist()\n",
    "# rightMeanFreq4 = df[\"right MeanFreq of EMG4\"].tolist()\n",
    "# rightMeanFreq5 = df[\"right MeanFreq of EMG5\"].tolist()\n",
    "# rightMeanFreq6 = df[\"right MeanFreq of EMG6\"].tolist()\n",
    "# rightMeanFreq7 = df[\"right MeanFreq of EMG7\"].tolist()\n",
    "# rightMeanFreq8 = df[\"right MeanFreq of EMG8\"].tolist()\n",
    "\n",
    "# leftMeanFreq1 = df[\"left MeanFreq of EMG1\"].tolist()\n",
    "# leftMeanFreq2 = df[\"left MeanFreq of EMG2\"].tolist()\n",
    "# leftMeanFreq3 = df[\"left MeanFreq of EMG3\"].tolist()\n",
    "# leftMeanFreq4 = df[\"left MeanFreq of EMG4\"].tolist()\n",
    "# leftMeanFreq5 = df[\"left MeanFreq of EMG5\"].tolist()\n",
    "# leftMeanFreq6 = df[\"left MeanFreq of EMG6\"].tolist()\n",
    "# leftMeanFreq7 = df[\"left MeanFreq of EMG7\"].tolist()\n",
    "# leftMeanFreq8 = df[\"left MeanFreq of EMG8\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "# df = df.drop(\"right MeanFreq of EMG1\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG2\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG3\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG4\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG5\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG6\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG7\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG8\", axis=1)\n",
    "\n",
    "# df = df.drop(\"left MeanFreq of EMG1\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG2\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG3\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG4\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG5\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG6\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG7\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG8\", axis=1)\n",
    "\n",
    "# df[\"right MeanFreq of EMG1\"] = rightMeanFreq1\n",
    "# df[\"right MeanFreq of EMG2\"] = rightMeanFreq2\n",
    "# df[\"right MeanFreq of EMG3\"] = rightMeanFreq3\n",
    "# df[\"right MeanFreq of EMG4\"] = rightMeanFreq4\n",
    "# df[\"right MeanFreq of EMG5\"] = rightMeanFreq5\n",
    "# df[\"right MeanFreq of EMG6\"] = rightMeanFreq6\n",
    "# df[\"right MeanFreq of EMG7\"] = rightMeanFreq7\n",
    "# df[\"right MeanFreq of EMG8\"] = rightMeanFreq8\n",
    "\n",
    "# df[\"left MeanFreq of EMG1\"] = leftMeanFreq1\n",
    "# df[\"left MeanFreq of EMG2\"] = leftMeanFreq2\n",
    "# df[\"left MeanFreq of EMG3\"] = leftMeanFreq3\n",
    "# df[\"left MeanFreq of EMG4\"] = leftMeanFreq4\n",
    "# df[\"left MeanFreq of EMG5\"] = leftMeanFreq5\n",
    "# df[\"left MeanFreq of EMG6\"] = leftMeanFreq6\n",
    "# df[\"left MeanFreq of EMG7\"] = leftMeanFreq7\n",
    "# df[\"left MeanFreq of EMG8\"] = leftMeanFreq8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "    \n",
    "\n",
    "\n",
    "# for k2 in GyroDataFramesPerFeature.keys():\n",
    "#     for i in GyroDataFramesPerFeature[k2].columns:\n",
    "#         dataFramesPerFeature['variance'][i] = GyroDataFramesPerFeature[k2][i]\n",
    "            \n",
    "# for k2 in accDataFramesPerFeature.keys():\n",
    "#     for i in accDataFramesPerFeature[k2].columns:\n",
    "#         dataFramesPerFeature['variance'][i] = accDataFramesPerFeature[k2][i]\n",
    "\n",
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "#     newDf = listOfLabeledAccDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledAccDataPerClass[a][k])\n",
    "# dataFramesPerFeature.to_csv('/Users/user/Desktop/test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Consolidation (save to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "#     newDf = listOfLabeledAccDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledAccDataPerClass[a][k])\n",
    "    \n",
    "    \n",
    "#     newDf.to_csv('/Users/user/Desktop/'+ a +'ArmConsolidatedAcc.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "#     newDf = listOfLabeledGyroDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedGyroDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledGyroDataPerClass[a][k])\n",
    "    \n",
    "    \n",
    "#     newDf.to_csv('/Users/user/Desktop/'+ a +'ArmConsolidatedGyro.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
