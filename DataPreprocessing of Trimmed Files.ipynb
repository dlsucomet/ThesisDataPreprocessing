{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done listing the class and file names\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "listOfFileNames = []\n",
    "listOfClassNames = []\n",
    "listOfDataPerClass = []\n",
    "files = []\n",
    "classNames = []\n",
    "#path = \"/Users/user/Desktop/asd/thesis/placeholder/\"\n",
    "#path = \"/Users/user/Desktop/pinakalatest/thesis/placeholder/\"\n",
    "path = \"trimmed_data(2arms)/\"\n",
    "classNames = glob.glob(path + \"*\")\n",
    "\n",
    "for c in classNames:\n",
    "    className = c.split(\"\\\\\")[1]\n",
    "    listOfClassNames.append(c.split(\"\\\\\")[1])\n",
    "    files = glob.glob(path + className+\"/*\") \n",
    "    listOfFileNames = []\n",
    "    for f in files:\n",
    "        listOfFileNames.append(f.split(\"\\\\\")[1])\n",
    "        \n",
    "    listOfDataPerClass.append(listOfFileNames)\n",
    "\n",
    "    \n",
    "#listOfClassNames\n",
    "#listOfDataPerClass[0]\n",
    "print(\"Done listing the class and file names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word binebenta-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word extra-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word gulay-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word gusto-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word itlog-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word juice-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kape-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kilo-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word mahal-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word malaki-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word maliit-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word mayroon-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word nagbubukas-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word nagsasara-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word oras-----------------\n",
      "Total of 99 left arm emg files and 99 right arm emg files.\n",
      "Total of 99 left arm acc files and 99 right arm acc files.\n",
      "Total of 99 left arm gyro files and 99 right arm gyro files.\n",
      "----------------- Word pabili-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word poloshirt-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word puwede-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word saging-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word sari-sari store-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word shorts-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word size-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word spaghetti-----------------\n",
      "Total of 99 left arm emg files and 99 right arm emg files.\n",
      "Total of 99 left arm acc files and 99 right arm acc files.\n",
      "Total of 99 left arm gyro files and 99 right arm gyro files.\n",
      "----------------- Word supot-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word t-shirt-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word tawad-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word tinapay-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word utang-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word wala-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "Done converting to dataframes!\n"
     ]
    }
   ],
   "source": [
    "#len(listOfDataPerClass)\n",
    "#listOfDataPerClass[3]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "listOfDataFramesPerClass = {}\n",
    "dataFrameDictionary = {}\n",
    "dataFrames = []\n",
    "\n",
    "firstDay = ['mayroon', 'kayo', 'black', 'ano', 'niyo', 'kape', 'magkano', 'bibili', 'oras', 'tubig', 'maliit(thing)', \n",
    "            'kulay', 'isa', 'dito', 'pagkain']\n",
    "secondDay = ['nagbubukas', 'ate', 'isda', 'itlog', 'kuya', 'baboy', 't-shirt', 'blue', 'wala', 'dalawa', 'tatlo', 'nagsasara', 'shorts', 'red', 'mahal', \n",
    "              'tawad', 'small(shirt)', 'medium(shirt)', 'large(shirt)', 'sari-sari-store', 'mantika', 'juice', 'size']\n",
    "thirdDay = ['saging', 'nito', 'kanin', 'ito', 'spaghetti', 'gusto', 'tinapay', 'manok', 'poloshirt', 'extra', 'kilo', 'salamat', 'binebenta', 'puwede', 'welcome', 'utang', 'gulay',\n",
    "           'softdrinks', 'sorry', 'hello', 'malaki', 'supot(plastik)']\n",
    "\n",
    "for c, d in zip(listOfClassNames, listOfDataPerClass):\n",
    "    print(\"----------------- Word \" + c + \"-----------------\")\n",
    "    emgDataFrames = {}\n",
    "    emgDataFrames['right'] = []\n",
    "    emgDataFrames['left'] = []\n",
    "    \n",
    "    accDataFrames = {}\n",
    "    accDataFrames['right'] = []\n",
    "    accDataFrames['left'] = []\n",
    "\n",
    "    gyroDataFrames = {}\n",
    "    gyroDataFrames['right'] = []\n",
    "    gyroDataFrames['left'] = []\n",
    "\n",
    "    dataFrameDictionary = {}\n",
    "    className = c\n",
    "    emgleftctr = 0\n",
    "    emgrightctr = 0\n",
    "    accleftctr = 0\n",
    "    accrightctr = 0\n",
    "    gyroleftctr = 0\n",
    "    gyrorightctr = 0\n",
    "    for fileName in d:\n",
    "        fileLocation = path + className + \"/\" + fileName + \"\"\n",
    "        #print(fileLocation)\n",
    "        df = pd.read_csv(fileLocation)\n",
    "\n",
    "        if \"emg\" in fileName:   \n",
    "            if \"-Right\" in fileName:\n",
    "                emgDataFrames['right'].append(df)\n",
    "                emgrightctr+=1\n",
    "            else:\n",
    "                emgDataFrames['left'].append(df)\n",
    "                emgleftctr+=1\n",
    "        elif (\"acc\") in fileName:\n",
    "            if \"-Right\" in fileName:\n",
    "                accDataFrames['right'].append(df)\n",
    "                accrightctr+=1\n",
    "            else:\n",
    "                accDataFrames['left'].append(df)\n",
    "                accleftctr+=1\n",
    "        elif (\"gyro\") in fileName:\n",
    "            if \"-Right\" in fileName:\n",
    "                gyroDataFrames['right'].append(df)\n",
    "                gyrorightctr+=1\n",
    "            else:\n",
    "                gyroDataFrames['left'].append(df)\n",
    "                gyroleftctr+=1\n",
    "    \n",
    "    dataFrameDictionary[\"emg\"] = emgDataFrames\n",
    "    dataFrameDictionary[\"acc\"] = accDataFrames\n",
    "    dataFrameDictionary[\"gyro\"] = gyroDataFrames\n",
    "\n",
    "    listOfDataFramesPerClass[className] = dataFrameDictionary\n",
    "    print(\"Total of \" + str(emgleftctr) + \" left arm emg files and \" + str(emgrightctr) + \" right arm emg files.\")\n",
    "    print(\"Total of \" + str(accleftctr) + \" left arm acc files and \" + str(accrightctr) + \" right arm acc files.\")\n",
    "    print(\"Total of \" + str(gyroleftctr) + \" left arm gyro files and \" + str(gyrorightctr) + \" right arm gyro files.\")\n",
    "\n",
    "\n",
    "print(\"Done converting to dataframes!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For EMG Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# listOfTrimmedDataFramesPerClass = {}\n",
    "\n",
    "# for k in listOfDataFramesPerClass.keys():\n",
    "#     print(\"----------------- Word \" + k + \"-----------------\")\n",
    "#     ctr = 0\n",
    "#     trimmedDataFramesPerClass = {}\n",
    "#     trimmedDataFramesPerClass['left'] = []\n",
    "#     trimmedDataFramesPerClass['right'] = []\n",
    "    \n",
    "#     dataFrameDictionary = {}\n",
    "\n",
    "#     for a in listOfDataFramesPerClass[k]['emg']:\n",
    "#         for d in listOfDataFramesPerClass[k]['emg'][a]:\n",
    "# #             keep_col = ['emg1','emg2','emg3','emg4','emg5','emg6','emg7','emg8']\n",
    "# #             new_df = d[keep_col]\n",
    "#             new_df = d\n",
    "#             new_df = new_df[:-49]\n",
    "#             trimmed_df = new_df.iloc[49:]\n",
    "#             if len(trimmed_df) < 100:\n",
    "#                 print(str(ctr) + \" \" + k)\n",
    "#             trimmedDataFramesPerClass[a].append(trimmed_df)\n",
    "#             ctr += 1\n",
    "        \n",
    "#     print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "#     dataFrameDictionary[\"emg\"] = trimmedDataFramesPerClass\n",
    "#     listOfTrimmedDataFramesPerClass[k] = dataFrameDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word binebenta-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word extra-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word gulay-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word gusto-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word itlog-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word juice-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word kape-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word kilo-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word mahal-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word malaki-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word maliit-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word mayroon-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word nagbubukas-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word nagsasara-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word oras-----------------\n",
      "Done Normalizing 99right arm files\n",
      "Done Normalizing 99left arm files\n",
      "----------------- Word pabili-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word poloshirt-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word puwede-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word saging-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word sari-sari store-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word shorts-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word size-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word spaghetti-----------------\n",
      "Done Normalizing 99right arm files\n",
      "Done Normalizing 99left arm files\n",
      "----------------- Word supot-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word t-shirt-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word tawad-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word tinapay-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word utang-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "----------------- Word wala-----------------\n",
      "Done Normalizing 100right arm files\n",
      "Done Normalizing 100left arm files\n",
      "Data Normalization done!!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    \n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        for d in listOfDataFramesPerClass[k]['emg'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "\n",
    "        print(\"Done Normalizing \" + str(ctr) + a + \" arm files\")\n",
    "    dataFrameDictionary[\"emg\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'left emg'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"left\" + \" emg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word binebenta-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word extra-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word gulay-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word gusto-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word itlog-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word juice-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word kape-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word kilo-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word mahal-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word malaki-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word maliit-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word mayroon-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word nagbubukas-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word nagsasara-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word oras-----------------\n",
      "99\n",
      "Done computing the var, mav, mean , sd, and rms of 99right arm files\n",
      "99\n",
      "Done computing the var, mav, mean , sd, and rms of 99left arm files\n",
      "----------------- Word pabili-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word poloshirt-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word puwede-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word saging-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word sari-sari store-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word shorts-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word size-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word spaghetti-----------------\n",
      "99\n",
      "Done computing the var, mav, mean , sd, and rms of 99right arm files\n",
      "99\n",
      "Done computing the var, mav, mean , sd, and rms of 99left arm files\n",
      "----------------- Word supot-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word t-shirt-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word tawad-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word tinapay-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word utang-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "----------------- Word wala-----------------\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100right arm files\n",
      "100\n",
      "Done computing the var, mav, mean , sd, and rms of 100left arm files\n",
      "Done computing emg features!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "\n",
    "listOfVarianceDataFramePerClass = {}\n",
    "listOfVarianceDataFramePerClass['right'] = []\n",
    "listOfVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMavDataFramePerClass = {}\n",
    "listOfMavDataFramePerClass['right'] = []\n",
    "listOfMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMeanDataFramePerClass = {}\n",
    "listOfMeanDataFramePerClass['right'] = []\n",
    "listOfMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfSdDataFramePerClass = {}\n",
    "listOfSdDataFramePerClass['right'] = []\n",
    "listOfSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfRmsDataFramePerClass = {}\n",
    "listOfRmsDataFramePerClass['right'] = []\n",
    "listOfRmsDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "\n",
    "    for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm + 'variance of EMG1'), (arm + 'variance of EMG2'), (arm + 'variance of EMG3'), (arm + 'variance of EMG4'),\n",
    "                                 (arm + 'variance of EMG5'), (arm + 'variance of EMG6'), (arm + 'variance of EMG7'), (arm + 'variance of EMG8')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm + 'Mav of EMG1'), (arm + 'Mav of EMG2'), (arm + 'Mav of EMG3'), (arm + 'Mav of EMG4'),\n",
    "                                     (arm + 'Mav of EMG5'), (arm + 'Mav of EMG6'), (arm + 'Mav of EMG7'), (arm + 'Mav of EMG8')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm + 'Mean of EMG1'), (arm + 'Mean of EMG2'), (arm + 'Mean of EMG3'), (arm + 'Mean of EMG4'),\n",
    "                                     (arm + 'Mean of EMG5'), (arm + 'Mean of EMG6'), (arm + 'Mean of EMG7'), (arm + 'Mean of EMG8')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm + 'Sd of EMG1'), (arm + 'Sd of EMG2'), (arm + 'Sd of EMG3'), (arm + 'Sd of EMG4'),\n",
    "                                     (arm + 'Sd of EMG5'), (arm + 'Sd of EMG6'), (arm + 'Sd of EMG7'), (arm + 'Sd of EMG8')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm + 'Rms of EMG1'), (arm + 'Rms of EMG2'), (arm + 'Rms of EMG3'), (arm + 'Rms of EMG4'),\n",
    "                                     (arm + 'Rms of EMG5'), (arm + 'Rms of EMG6'), (arm + 'Rms of EMG7'), (arm + 'Rms of EMG8')])\n",
    "        for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg'][a]:\n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3], df_normalized.var()[4], df_normalized.var()[5], df_normalized.var()[6], df_normalized.var()[7], df_normalized.var()[8]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3], robust.mad(df_normalized)[4], robust.mad(df_normalized)[5], robust.mad(df_normalized)[6], robust.mad(df_normalized)[7], robust.mad(df_normalized)[8]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3], np.mean(df_normalized)[4], np.mean(df_normalized)[5], np.mean(df_normalized)[6], np.mean(df_normalized)[7], np.mean(df_normalized)[8]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3], np.std(df_normalized)[4], np.std(df_normalized)[5], np.std(df_normalized)[6], np.std(df_normalized)[7], np.std(df_normalized)[8]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2)), np.sqrt(np.mean(df_normalized[4].values**2)), np.sqrt(np.mean(df_normalized[5].values**2)), np.sqrt(np.mean(df_normalized[6].values**2)), robust.mad(df_normalized)[7], np.sqrt(np.mean(df_normalized[8].values**2))]\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "    \n",
    "        print(\"Done computing the var, mav, mean , sd, and rms of \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing emg features!\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mean and Median Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word binebenta-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word extra-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word gulay-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word gusto-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word itlog-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word juice-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word kape-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word kilo-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word mahal-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word malaki-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word maliit-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word mayroon-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word nagbubukas-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word nagsasara-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word oras-----------------\n",
      "Done computing Mean and Median Frequency of 99right arm files\n",
      "Done computing Mean and Median Frequency of 99left arm files\n",
      "----------------- Word pabili-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word poloshirt-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word puwede-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word saging-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word sari-sari store-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word shorts-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word size-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word spaghetti-----------------\n",
      "Done computing Mean and Median Frequency of 99right arm files\n",
      "Done computing Mean and Median Frequency of 99left arm files\n",
      "----------------- Word supot-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word t-shirt-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word tawad-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word tinapay-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word utang-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "----------------- Word wala-----------------\n",
      "Done computing Mean and Median Frequency of 100right arm files\n",
      "Done computing Mean and Median Frequency of 100left arm files\n",
      "Done computing emg features!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "listOfMeanFreqDataFramePerClass = {}\n",
    "listOfMeanFreqDataFramePerClass['right'] = []\n",
    "listOfMeanFreqDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMedFreqDataFramePerClass = {}\n",
    "listOfMedFreqDataFramePerClass['right'] = []\n",
    "listOfMedFreqDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    \n",
    "    for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        meanFreqDataFrame = pd.DataFrame(columns = [(arm + 'MeanFreq of EMG1'), (arm + 'MeanFreq of EMG2'), (arm + 'MeanFreq of EMG3'), (arm + 'MeanFreq of EMG4'),\n",
    "                                 (arm + 'MeanFreq of EMG5'), (arm + 'MeanFreq of EMG6'), (arm + 'MeanFreq of EMG7'), (arm + 'MeanFreq of EMG8')]) \n",
    "\n",
    "        medFreqDataFrame = pd.DataFrame(columns = [(arm + 'MedianFreq of EMG1'), (arm + 'MedianFreq of EMG2'), (arm + 'MedianFreq of EMG3'), (arm + 'MedianFreq of EMG4'),\n",
    "                                     (arm + 'MedianFreq of EMG5'), (arm + 'MedianFreq of EMG6'), (arm + 'MedianFreq of EMG7'), (arm + 'MedianFreq of EMG8')])\n",
    "\n",
    "        for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg'][a]:\n",
    "            meanFreq = []\n",
    "            medFreq = []\n",
    "\n",
    "            for i in range(0, 8):\n",
    "                data = df_normalized[i].values\n",
    "                ps = np.abs(np.fft.fft(data))**2\n",
    "\n",
    "                freqs = np.fft.fftfreq(data.size, 1/100)\n",
    "\n",
    "                sumProd = 0\n",
    "                sumPs = 0\n",
    "\n",
    "                for f, p in zip(freqs,ps):\n",
    "                    sumProd += f*p\n",
    "                    sumPs += p\n",
    "\n",
    "                meanFreq.append(sumProd/sumPs * 1000)\n",
    "                medFreq.append(sumPs/2)\n",
    "                \n",
    "            if k == \"tatlo\":\n",
    "                print(ctr)\n",
    "            \n",
    "            meanFreqDataFrame.loc[ctr] = [meanFreq[0], meanFreq[1], meanFreq[2], meanFreq[3], meanFreq[4], meanFreq[5], meanFreq[6], meanFreq[7]]\n",
    "            medFreqDataFrame.loc[ctr] = [medFreq[0], medFreq[1], medFreq[2], medFreq[3], medFreq[4], medFreq[5], medFreq[6], medFreq[7]]\n",
    "\n",
    "            ctr+=1\n",
    "        listOfMeanFreqDataFramePerClass[a].append(meanFreqDataFrame)\n",
    "        listOfMedFreqDataFramePerClass[a].append(medFreqDataFrame)\n",
    "        print(\"Done computing Mean and Median Frequency of \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing emg features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done labeling emg data of binebenta right arm files\n",
      "Done labeling emg data of extra right arm files\n",
      "Done labeling emg data of gulay right arm files\n",
      "Done labeling emg data of gusto right arm files\n",
      "Done labeling emg data of itlog right arm files\n",
      "Done labeling emg data of juice right arm files\n",
      "Done labeling emg data of kape right arm files\n",
      "Done labeling emg data of kilo right arm files\n",
      "Done labeling emg data of mahal right arm files\n",
      "Done labeling emg data of malaki right arm files\n",
      "Done labeling emg data of maliit right arm files\n",
      "Done labeling emg data of mayroon right arm files\n",
      "Done labeling emg data of nagbubukas right arm files\n",
      "Done labeling emg data of nagsasara right arm files\n",
      "Done labeling emg data of oras right arm files\n",
      "Done labeling emg data of pabili right arm files\n",
      "Done labeling emg data of poloshirt right arm files\n",
      "Done labeling emg data of puwede right arm files\n",
      "Done labeling emg data of saging right arm files\n",
      "Done labeling emg data of sari-sari store right arm files\n",
      "Done labeling emg data of shorts right arm files\n",
      "Done labeling emg data of size right arm files\n",
      "Done labeling emg data of spaghetti right arm files\n",
      "Done labeling emg data of supot right arm files\n",
      "Done labeling emg data of t-shirt right arm files\n",
      "Done labeling emg data of tawad right arm files\n",
      "Done labeling emg data of tinapay right arm files\n",
      "Done labeling emg data of utang right arm files\n",
      "Done labeling emg data of wala right arm files\n",
      "Done labeling emg data of binebenta left arm files\n",
      "Done labeling emg data of extra left arm files\n",
      "Done labeling emg data of gulay left arm files\n",
      "Done labeling emg data of gusto left arm files\n",
      "Done labeling emg data of itlog left arm files\n",
      "Done labeling emg data of juice left arm files\n",
      "Done labeling emg data of kape left arm files\n",
      "Done labeling emg data of kilo left arm files\n",
      "Done labeling emg data of mahal left arm files\n",
      "Done labeling emg data of malaki left arm files\n",
      "Done labeling emg data of maliit left arm files\n",
      "Done labeling emg data of mayroon left arm files\n",
      "Done labeling emg data of nagbubukas left arm files\n",
      "Done labeling emg data of nagsasara left arm files\n",
      "Done labeling emg data of oras left arm files\n",
      "Done labeling emg data of pabili left arm files\n",
      "Done labeling emg data of poloshirt left arm files\n",
      "Done labeling emg data of puwede left arm files\n",
      "Done labeling emg data of saging left arm files\n",
      "Done labeling emg data of sari-sari store left arm files\n",
      "Done labeling emg data of shorts left arm files\n",
      "Done labeling emg data of size left arm files\n",
      "Done labeling emg data of spaghetti left arm files\n",
      "Done labeling emg data of supot left arm files\n",
      "Done labeling emg data of t-shirt left arm files\n",
      "Done labeling emg data of tawad left arm files\n",
      "Done labeling emg data of tinapay left arm files\n",
      "Done labeling emg data of utang left arm files\n",
      "Done labeling emg data of wala left arm files\n"
     ]
    }
   ],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "ctr = 0\n",
    "\n",
    "listOfLabeledDataPerClass = {}\n",
    "listOfLabeledDataPerClass['right'] = {}\n",
    "listOfLabeledDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "\n",
    "    dataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        dataFramesPerFeature['variance'] = listOfVarianceDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['mav'] = listOfMavDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['rms'] = listOfRmsDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['sd'] = listOfSdDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['mean'] = listOfMeanDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['medFreq'] = listOfMedFreqDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['meanFreq'] = listOfMeanFreqDataFramePerClass[a][ctr]\n",
    "    \n",
    "\n",
    "        for k2 in dataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in dataFramesPerFeature[k2].columns:\n",
    "                    dataFramesPerFeature['variance'][i] = dataFramesPerFeature[k2][i]\n",
    "        \n",
    "        dataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledDataPerClass[a][k] = dataFramesPerFeature['variance']\n",
    "        print(\"Done labeling emg data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Consolidation (save to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For IMU values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming (For Acceleration and Gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# listOfTrimmedAccDataFramesPerClass = {}\n",
    "\n",
    "# for k in listOfDataFramesPerClass.keys():\n",
    "#     print(\"----------------- Word \" + k + \"-----------------\")\n",
    "#     ctr = 0\n",
    "#     trimmedDataFramesPerClass = {}\n",
    "#     trimmedDataFramesPerClass['left'] = []\n",
    "#     trimmedDataFramesPerClass['right'] = []\n",
    "#     dataFrameDictionary = {}\n",
    "    \n",
    "#     for a in listOfDataFramesPerClass[k]['emg']:\n",
    "#         for d in listOfDataFramesPerClass[k]['acc'][a]:\n",
    "# #             keep_col = ['x','y','z']\n",
    "# #             new_df = d[keep_col]\n",
    "#             new_df = d\n",
    "#             new_df = new_df[:-24]\n",
    "#             trimmed_df = new_df.iloc[24:]\n",
    "#             if len(trimmed_df) < 50:\n",
    "#                 print(str(ctr) + \" \" + str(len(trimmed_df)))\n",
    "#             trimmedDataFramesPerClass[a].append(trimmed_df)\n",
    "#             ctr += 1\n",
    "        \n",
    "#     print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "#     dataFrameDictionary[\"acc\"] = trimmedDataFramesPerClass\n",
    "#     listOfTrimmedAccDataFramesPerClass[k] = dataFrameDictionary\n",
    "    \n",
    "# print(\"Done Trimming Acc data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# listOfTrimmedGyroDataFramesPerClass = {}\n",
    "# #\n",
    "# for k in listOfDataFramesPerClass.keys():\n",
    "#     print(\"----------------- Word \" + k + \"-----------------\")\n",
    "#     ctr = 0\n",
    "#     trimmedDataFramesPerClass = {}\n",
    "#     trimmedDataFramesPerClass['left'] = []\n",
    "#     trimmedDataFramesPerClass['right'] = []\n",
    "#     dataFrameDictionary = {}\n",
    "    \n",
    "#     for a in listOfDataFramesPerClass[k]['gyro']:\n",
    "#         for d in listOfDataFramesPerClass[k]['gyro'][a]:\n",
    "# #             keep_col = ['x','y','z']\n",
    "# #             new_df = d[keep_col]\n",
    "#             new_df = d\n",
    "#             new_df = new_df[:-24]\n",
    "#             trimmed_df = new_df.iloc[24:]\n",
    "#             if len(trimmed_df) < 50:\n",
    "#                 print(str(ctr) + \" \" + str(len(trimmed_df)))\n",
    "#             trimmedDataFramesPerClass[a].append(trimmed_df)\n",
    "#             ctr += 1\n",
    "        \n",
    "#     print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "#     dataFrameDictionary[\"gyro\"] = trimmedDataFramesPerClass\n",
    "#     listOfTrimmedGyroDataFramesPerClass[k] = dataFrameDictionary\n",
    "    \n",
    "# print(\"Done Trimming Gyro data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization (For Acceleration and Gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word binebenta-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word extra-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word gulay-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word gusto-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word itlog-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word juice-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kape-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kilo-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word mahal-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word malaki-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word maliit-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word mayroon-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word nagbubukas-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word nagsasara-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word oras-----------------\n",
      "Done Normalizing 198 files\n",
      "----------------- Word pabili-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word poloshirt-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word puwede-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word saging-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word sari-sari store-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word shorts-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word size-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word spaghetti-----------------\n",
      "Done Normalizing 198 files\n",
      "----------------- Word supot-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word t-shirt-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word tawad-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word tinapay-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word utang-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word wala-----------------\n",
      "Done Normalizing 200 files\n",
      "Acc Data Normalization done!!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedAccDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['acc']:\n",
    "        for d in listOfDataFramesPerClass[k]['acc'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"acc\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedAccDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Acc Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#listOfDataFramesPerClass['ate']['acc']['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word binebenta-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word extra-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word gulay-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word gusto-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word itlog-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word juice-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kape-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word kilo-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word mahal-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word malaki-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word maliit-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word mayroon-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word nagbubukas-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word nagsasara-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word oras-----------------\n",
      "Done Normalizing 198 files\n",
      "----------------- Word pabili-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word poloshirt-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word puwede-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word saging-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word sari-sari store-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word shorts-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word size-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word spaghetti-----------------\n",
      "Done Normalizing 198 files\n",
      "----------------- Word supot-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word t-shirt-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word tawad-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word tinapay-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word utang-----------------\n",
      "Done Normalizing 200 files\n",
      "----------------- Word wala-----------------\n",
      "Done Normalizing 200 files\n",
      "Gyro Data Normalization done!!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedGyroDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['gyro']:\n",
    "        for d in listOfDataFramesPerClass[k]['gyro'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"gyro\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedGyroDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Gyro Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word binebenta-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word extra-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word gulay-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word gusto-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word itlog-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word juice-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word kape-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word kilo-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word mahal-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word malaki-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word maliit-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word mayroon-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word nagbubukas-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word nagsasara-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word oras-----------------\n",
      "99\n",
      "Done computing acc features 99left arm files\n",
      "99\n",
      "Done computing acc features 99right arm files\n",
      "----------------- Word pabili-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word poloshirt-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word puwede-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word saging-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word sari-sari store-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word shorts-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word size-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word spaghetti-----------------\n",
      "99\n",
      "Done computing acc features 99left arm files\n",
      "99\n",
      "Done computing acc features 99right arm files\n",
      "----------------- Word supot-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word t-shirt-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word tawad-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word tinapay-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word utang-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "----------------- Word wala-----------------\n",
      "100\n",
      "Done computing acc features 100left arm files\n",
      "100\n",
      "Done computing acc features 100right arm files\n",
      "Done computing acc features!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "#kurtosis\n",
    "#standarddev\n",
    "#mean\n",
    "#variance\n",
    "#entropy\n",
    "#meanabsval\n",
    "#rootmeansquare\n",
    "#Signal Magnitude Area\n",
    "#Integration\n",
    "\n",
    "listOfAccVarianceDataFramePerClass = {}\n",
    "listOfAccVarianceDataFramePerClass['right'] = []\n",
    "listOfAccVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccMavDataFramePerClass = {}\n",
    "listOfAccMavDataFramePerClass['right'] = []\n",
    "listOfAccMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccMeanDataFramePerClass = {}\n",
    "listOfAccMeanDataFramePerClass['right'] = []\n",
    "listOfAccMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccSdDataFramePerClass = {}\n",
    "listOfAccSdDataFramePerClass['right'] = []\n",
    "listOfAccSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccRmsDataFramePerClass = {}\n",
    "listOfAccRmsDataFramePerClass['right'] = []\n",
    "listOfAccRmsDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccEntropyDataFramePerClass = {}\n",
    "listOfAccEntropyDataFramePerClass['right'] = []\n",
    "listOfAccEntropyDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccKurtosisDataFramePerClass = {}\n",
    "listOfAccKurtosisDataFramePerClass['right'] = []\n",
    "listOfAccKurtosisDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccSkewnessDataFramePerClass = {}\n",
    "listOfAccSkewnessDataFramePerClass['right'] = []\n",
    "listOfAccSkewnessDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccSmaDataFramePerClass = {}\n",
    "listOfAccSmaDataFramePerClass['right'] = []\n",
    "listOfAccSmaDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccIntegrationDataFramePerClass = {}\n",
    "listOfAccIntegrationDataFramePerClass['right'] = []\n",
    "listOfAccIntegrationDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedAccDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm+ 'Variance of ACC x'), (arm+ 'Variance of ACC y'), (arm+ 'Variance of ACC z')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm + 'Mav of ACC x'), (arm + 'Mav of ACC y'), (arm + 'Mav of ACC z')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm + 'Mean of ACC x'), (arm + 'Mean of ACC y'), (arm + 'Mean of ACC z')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm + 'Sd of ACC x'), (arm + 'Sd of ACC y'), (arm + 'Sd of ACC z')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm + 'Rms of ACC x'), (arm + 'Rms of ACC y'), (arm + 'Rms of ACC z')])\n",
    "        entropyDataFrame = pd.DataFrame(columns = [(arm + 'Entropy of ACC x'), (arm + 'Entropy of ACC y'), (arm + 'Entropy of ACC z')])\n",
    "        kurtosisDataFrame = pd.DataFrame(columns = [(arm + 'Kurtosis of ACC x'), (arm + 'Kurtosis of ACC y'), (arm + 'Kurtosis of ACC z')])\n",
    "        skewnessDataFrame = pd.DataFrame(columns = [(arm + 'Skewness of ACC x'), (arm + 'Skewness of ACC y'), (arm + 'Skewness of ACC z')])\n",
    "        smaDataFrame = pd.DataFrame(columns = [(arm + 'SMA of ACC')])\n",
    "        integrationDataFrame = pd.DataFrame(columns = [(arm + 'Integration of ACC x'), (arm + 'Integration of ACC y'), (arm + 'Integration of ACC z')])\n",
    "\n",
    "        \n",
    "        for df_normalized in listOfNormalizedAccDataFramesPerClass[k]['acc'][a]:\n",
    "            \n",
    "#             print(\"df_normalized\")\n",
    "#             time.sleep(5.5) \n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2))]\n",
    "            entropyDataFrame.loc[ctr] = [sp.stats.entropy(df_normalized)[1], sp.stats.entropy(df_normalized)[2], sp.stats.entropy(df_normalized)[3]]\n",
    "            kurtosisDataFrame.loc[ctr] = [df_normalized.kurtosis()[1], df_normalized.kurtosis()[2], df_normalized.kurtosis()[3]]\n",
    "            skewnessDataFrame.loc[ctr] = [df_normalized.skew(axis=0)[1], df_normalized.skew(axis=0)[2], df_normalized.skew(axis=0)[3]]\n",
    "            length = df_normalized.shape[1]\n",
    "            sma = 0\n",
    "            for x in range(0, length):\n",
    "                # .iloc[x,0] is accessing row, column\n",
    "                sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "            sma = sma / length\n",
    "            smaDataFrame.loc[ctr] = [sma]\n",
    "            integrationDataFrame.loc[ctr] = [sp.integrate.simps(df_normalized, axis=0)[1],sp.integrate.simps(df_normalized, axis=0)[2], sp.integrate.simps(df_normalized, axis=0)[3]]\n",
    "\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfAccVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfAccMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfAccMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfAccSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfAccRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "        listOfAccEntropyDataFramePerClass[a].append(entropyDataFrame) \n",
    "        listOfAccKurtosisDataFramePerClass[a].append(kurtosisDataFrame) \n",
    "        listOfAccSkewnessDataFramePerClass[a].append(skewnessDataFrame) \n",
    "        listOfAccSmaDataFramePerClass[a].append(smaDataFrame) \n",
    "        listOfAccIntegrationDataFramePerClass[a].append(integrationDataFrame) \n",
    "        \n",
    "        print(\"Done computing acc features \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing acc features!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word binebenta-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word extra-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word gulay-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word gusto-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word itlog-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word juice-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word kape-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word kilo-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word mahal-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word malaki-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word maliit-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word mayroon-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word nagbubukas-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word nagsasara-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word oras-----------------\n",
      "99\n",
      "Done computing Gyro features 99left arm files\n",
      "99\n",
      "Done computing Gyro features 99right arm files\n",
      "----------------- Word pabili-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word poloshirt-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word puwede-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word saging-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word sari-sari store-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word shorts-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word size-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word spaghetti-----------------\n",
      "99\n",
      "Done computing Gyro features 99left arm files\n",
      "99\n",
      "Done computing Gyro features 99right arm files\n",
      "----------------- Word supot-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word t-shirt-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word tawad-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word tinapay-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word utang-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "----------------- Word wala-----------------\n",
      "100\n",
      "Done computing Gyro features 100left arm files\n",
      "100\n",
      "Done computing Gyro features 100right arm files\n",
      "Done computing gyro features!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "#kurtosis\n",
    "#standarddev\n",
    "#mean\n",
    "#variance\n",
    "#entropy\n",
    "#meanabsval\n",
    "#rootmeansquare\n",
    "#Signal Magnitude Area\n",
    "#Integration\n",
    "\n",
    "listOfGyroVarianceDataFramePerClass = {}\n",
    "listOfGyroVarianceDataFramePerClass['right'] = []\n",
    "listOfGyroVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroMavDataFramePerClass = {}\n",
    "listOfGyroMavDataFramePerClass['right'] = []\n",
    "listOfGyroMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroMeanDataFramePerClass = {}\n",
    "listOfGyroMeanDataFramePerClass['right'] = []\n",
    "listOfGyroMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSdDataFramePerClass = {}\n",
    "listOfGyroSdDataFramePerClass['right'] = []\n",
    "listOfGyroSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroRmsDataFramePerClass = {}\n",
    "listOfGyroRmsDataFramePerClass['right'] = []\n",
    "listOfGyroRmsDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroEntropyDataFramePerClass = {}\n",
    "listOfGyroEntropyDataFramePerClass['right'] = []\n",
    "listOfGyroEntropyDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroKurtosisDataFramePerClass = {}\n",
    "listOfGyroKurtosisDataFramePerClass['right'] = []\n",
    "listOfGyroKurtosisDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSkewnessDataFramePerClass = {}\n",
    "listOfGyroSkewnessDataFramePerClass['right'] = []\n",
    "listOfGyroSkewnessDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSmaDataFramePerClass = {}\n",
    "listOfGyroSmaDataFramePerClass['right'] = []\n",
    "listOfGyroSmaDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroIntegrationDataFramePerClass = {}\n",
    "listOfGyroIntegrationDataFramePerClass['right'] = []\n",
    "listOfGyroIntegrationDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedGyroDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm + 'Variance of Gyro x'), (arm+ 'Variance of Gyro y'), (arm+ 'Variance of Gyro z')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm+ 'Mav of Gyro x'), (arm+ 'Mav of Gyro y'), (arm+ 'Mav of Gyro z')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm+ 'Mean of Gyro x'), (arm+ 'Mean of Gyro y'), (arm+ 'Mean of Gyro z')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm+ 'Sd of Gyro x'), (arm+ 'Sd of Gyro y'), (arm+ 'Sd of Gyro z')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm+ 'Rms of Gyro x'), (arm+ 'Rms of Gyro y'), (arm+ 'Rms of Gyro z')])\n",
    "        entropyDataFrame = pd.DataFrame(columns = [(arm+ 'Entropy of Gyro x'), (arm+ 'Entropy of Gyro y'), (arm+ 'Entropy of Gyro z')])\n",
    "        kurtosisDataFrame = pd.DataFrame(columns = [(arm+ 'Kurtosis of Gyro x'), (arm+ 'Kurtosis of Gyro y'), (arm+ 'Kurtosis of Gyro z')])\n",
    "        skewnessDataFrame = pd.DataFrame(columns = [(arm+ 'Skewness of Gyro x'), (arm+ 'Skewness of Gyro y'), (arm+ 'Skewness of Gyro z')])\n",
    "        smaDataFrame = pd.DataFrame(columns = [(arm+ 'SMA of Gyro')])\n",
    "        integrationDataFrame = pd.DataFrame(columns = [(arm+ 'Integration of Gyro x'), (arm+ 'Integration of Gyro y'), (arm+ 'Integration of Gyro z')])\n",
    "\n",
    "        \n",
    "        for df_normalized in listOfNormalizedGyroDataFramesPerClass[k]['gyro'][a]:\n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2))]\n",
    "            entropyDataFrame.loc[ctr] = [sp.stats.entropy(df_normalized)[1], sp.stats.entropy(df_normalized)[2], sp.stats.entropy(df_normalized)[3],]\n",
    "            kurtosisDataFrame.loc[ctr] = [df_normalized.kurtosis()[1], df_normalized.kurtosis()[2], df_normalized.kurtosis()[3]]\n",
    "            skewnessDataFrame.loc[ctr] = [df_normalized.skew(axis=0)[1], df_normalized.skew(axis=0)[2], df_normalized.skew(axis=0)[3]]\n",
    "            length = df_normalized.shape[1]\n",
    "            sma = 0\n",
    "            for x in range(0, length):\n",
    "                # .iloc[x,0] is Gyroessing row, column\n",
    "                sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "            sma = sma / length\n",
    "            smaDataFrame.loc[ctr] = [sma]\n",
    "            integrationDataFrame.loc[ctr] = [sp.integrate.simps(df_normalized, axis=0)[1],sp.integrate.simps(df_normalized, axis=0)[2], sp.integrate.simps(df_normalized, axis=0)[3]]\n",
    "\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfGyroVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfGyroMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfGyroMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfGyroSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfGyroRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "        listOfGyroEntropyDataFramePerClass[a].append(entropyDataFrame) \n",
    "        listOfGyroKurtosisDataFramePerClass[a].append(kurtosisDataFrame) \n",
    "        listOfGyroSkewnessDataFramePerClass[a].append(skewnessDataFrame) \n",
    "        listOfGyroSmaDataFramePerClass[a].append(smaDataFrame) \n",
    "        listOfGyroIntegrationDataFramePerClass[a].append(integrationDataFrame) \n",
    "        \n",
    "        print(\"Done computing Gyro features \" + str(ctr) + a + \" arm files\")\n",
    "        \n",
    "print(\"Done computing gyro features!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#listOfGyroVarianceDataFramePerClass['left']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done labeling acc data of binebenta right arm files\n",
      "Done labeling acc data of extra right arm files\n",
      "Done labeling acc data of gulay right arm files\n",
      "Done labeling acc data of gusto right arm files\n",
      "Done labeling acc data of itlog right arm files\n",
      "Done labeling acc data of juice right arm files\n",
      "Done labeling acc data of kape right arm files\n",
      "Done labeling acc data of kilo right arm files\n",
      "Done labeling acc data of mahal right arm files\n",
      "Done labeling acc data of malaki right arm files\n",
      "Done labeling acc data of maliit right arm files\n",
      "Done labeling acc data of mayroon right arm files\n",
      "Done labeling acc data of nagbubukas right arm files\n",
      "Done labeling acc data of nagsasara right arm files\n",
      "Done labeling acc data of oras right arm files\n",
      "Done labeling acc data of pabili right arm files\n",
      "Done labeling acc data of poloshirt right arm files\n",
      "Done labeling acc data of puwede right arm files\n",
      "Done labeling acc data of saging right arm files\n",
      "Done labeling acc data of sari-sari store right arm files\n",
      "Done labeling acc data of shorts right arm files\n",
      "Done labeling acc data of size right arm files\n",
      "Done labeling acc data of spaghetti right arm files\n",
      "Done labeling acc data of supot right arm files\n",
      "Done labeling acc data of t-shirt right arm files\n",
      "Done labeling acc data of tawad right arm files\n",
      "Done labeling acc data of tinapay right arm files\n",
      "Done labeling acc data of utang right arm files\n",
      "Done labeling acc data of wala right arm files\n",
      "Done labeling acc data of binebenta left arm files\n",
      "Done labeling acc data of extra left arm files\n",
      "Done labeling acc data of gulay left arm files\n",
      "Done labeling acc data of gusto left arm files\n",
      "Done labeling acc data of itlog left arm files\n",
      "Done labeling acc data of juice left arm files\n",
      "Done labeling acc data of kape left arm files\n",
      "Done labeling acc data of kilo left arm files\n",
      "Done labeling acc data of mahal left arm files\n",
      "Done labeling acc data of malaki left arm files\n",
      "Done labeling acc data of maliit left arm files\n",
      "Done labeling acc data of mayroon left arm files\n",
      "Done labeling acc data of nagbubukas left arm files\n",
      "Done labeling acc data of nagsasara left arm files\n",
      "Done labeling acc data of oras left arm files\n",
      "Done labeling acc data of pabili left arm files\n",
      "Done labeling acc data of poloshirt left arm files\n",
      "Done labeling acc data of puwede left arm files\n",
      "Done labeling acc data of saging left arm files\n",
      "Done labeling acc data of sari-sari store left arm files\n",
      "Done labeling acc data of shorts left arm files\n",
      "Done labeling acc data of size left arm files\n",
      "Done labeling acc data of spaghetti left arm files\n",
      "Done labeling acc data of supot left arm files\n",
      "Done labeling acc data of t-shirt left arm files\n",
      "Done labeling acc data of tawad left arm files\n",
      "Done labeling acc data of tinapay left arm files\n",
      "Done labeling acc data of utang left arm files\n",
      "Done labeling acc data of wala left arm files\n"
     ]
    }
   ],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "ctr = 0\n",
    "\n",
    "listOfLabeledAccDataPerClass = {}\n",
    "listOfLabeledAccDataPerClass['right'] = {}\n",
    "listOfLabeledAccDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfDataFramesPerClass[k]['acc']:\n",
    "\n",
    "    accDataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        accDataFramesPerFeature['variance'] = listOfAccVarianceDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['mav'] = listOfAccMavDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['rms'] = listOfAccRmsDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['sd'] = listOfAccSdDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['mean'] = listOfAccMeanDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['entropy'] = listOfAccEntropyDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['kurtosis'] = listOfAccKurtosisDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['skewness'] = listOfAccSkewnessDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['sma'] = listOfAccSmaDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['integration'] = listOfAccIntegrationDataFramePerClass[a][ctr]\n",
    "\n",
    "        for k2 in accDataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in accDataFramesPerFeature[k2].columns:\n",
    "                    accDataFramesPerFeature['variance'][i] = accDataFramesPerFeature[k2][i]\n",
    "        \n",
    "        accDataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledAccDataPerClass[a][k] = accDataFramesPerFeature['variance']\n",
    "        print(\"Done labeling acc data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done labeling Gyro data of binebenta left arm files\n",
      "Done labeling Gyro data of extra left arm files\n",
      "Done labeling Gyro data of gulay left arm files\n",
      "Done labeling Gyro data of gusto left arm files\n",
      "Done labeling Gyro data of itlog left arm files\n",
      "Done labeling Gyro data of juice left arm files\n",
      "Done labeling Gyro data of kape left arm files\n",
      "Done labeling Gyro data of kilo left arm files\n",
      "Done labeling Gyro data of mahal left arm files\n",
      "Done labeling Gyro data of malaki left arm files\n",
      "Done labeling Gyro data of maliit left arm files\n",
      "Done labeling Gyro data of mayroon left arm files\n",
      "Done labeling Gyro data of nagbubukas left arm files\n",
      "Done labeling Gyro data of nagsasara left arm files\n",
      "Done labeling Gyro data of oras left arm files\n",
      "Done labeling Gyro data of pabili left arm files\n",
      "Done labeling Gyro data of poloshirt left arm files\n",
      "Done labeling Gyro data of puwede left arm files\n",
      "Done labeling Gyro data of saging left arm files\n",
      "Done labeling Gyro data of sari-sari store left arm files\n",
      "Done labeling Gyro data of shorts left arm files\n",
      "Done labeling Gyro data of size left arm files\n",
      "Done labeling Gyro data of spaghetti left arm files\n",
      "Done labeling Gyro data of supot left arm files\n",
      "Done labeling Gyro data of t-shirt left arm files\n",
      "Done labeling Gyro data of tawad left arm files\n",
      "Done labeling Gyro data of tinapay left arm files\n",
      "Done labeling Gyro data of utang left arm files\n",
      "Done labeling Gyro data of wala left arm files\n",
      "Done labeling Gyro data of binebenta right arm files\n",
      "Done labeling Gyro data of extra right arm files\n",
      "Done labeling Gyro data of gulay right arm files\n",
      "Done labeling Gyro data of gusto right arm files\n",
      "Done labeling Gyro data of itlog right arm files\n",
      "Done labeling Gyro data of juice right arm files\n",
      "Done labeling Gyro data of kape right arm files\n",
      "Done labeling Gyro data of kilo right arm files\n",
      "Done labeling Gyro data of mahal right arm files\n",
      "Done labeling Gyro data of malaki right arm files\n",
      "Done labeling Gyro data of maliit right arm files\n",
      "Done labeling Gyro data of mayroon right arm files\n",
      "Done labeling Gyro data of nagbubukas right arm files\n",
      "Done labeling Gyro data of nagsasara right arm files\n",
      "Done labeling Gyro data of oras right arm files\n",
      "Done labeling Gyro data of pabili right arm files\n",
      "Done labeling Gyro data of poloshirt right arm files\n",
      "Done labeling Gyro data of puwede right arm files\n",
      "Done labeling Gyro data of saging right arm files\n",
      "Done labeling Gyro data of sari-sari store right arm files\n",
      "Done labeling Gyro data of shorts right arm files\n",
      "Done labeling Gyro data of size right arm files\n",
      "Done labeling Gyro data of spaghetti right arm files\n",
      "Done labeling Gyro data of supot right arm files\n",
      "Done labeling Gyro data of t-shirt right arm files\n",
      "Done labeling Gyro data of tawad right arm files\n",
      "Done labeling Gyro data of tinapay right arm files\n",
      "Done labeling Gyro data of utang right arm files\n",
      "Done labeling Gyro data of wala right arm files\n"
     ]
    }
   ],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "ctr = 0\n",
    "\n",
    "listOfLabeledGyroDataPerClass = {}\n",
    "listOfLabeledGyroDataPerClass['right'] = {}\n",
    "listOfLabeledGyroDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "\n",
    "    GyroDataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        GyroDataFramesPerFeature['variance'] = listOfGyroVarianceDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['mav'] = listOfGyroMavDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['rms'] = listOfGyroRmsDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['sd'] = listOfGyroSdDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['mean'] = listOfGyroMeanDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['entropy'] = listOfGyroEntropyDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['kurtosis'] = listOfGyroKurtosisDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['skewness'] = listOfGyroSkewnessDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['sma'] = listOfGyroSmaDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['integration'] = listOfGyroIntegrationDataFramePerClass[a][ctr]\n",
    "\n",
    "        for k2 in GyroDataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in GyroDataFramesPerFeature[k2].columns:\n",
    "                    GyroDataFramesPerFeature['variance'][i] = GyroDataFramesPerFeature[k2][i]\n",
    "        \n",
    "        GyroDataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledGyroDataPerClass[a][k] = GyroDataFramesPerFeature['variance']\n",
    "        print(\"Done labeling Gyro data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra\n",
      "gulay\n",
      "gusto\n",
      "itlog\n",
      "juice\n",
      "kape\n",
      "kilo\n",
      "mahal\n",
      "malaki\n",
      "maliit\n",
      "mayroon\n",
      "nagbubukas\n",
      "nagsasara\n",
      "oras\n",
      "pabili\n",
      "poloshirt\n",
      "puwede\n",
      "saging\n",
      "sari-sari store\n",
      "shorts\n",
      "size\n",
      "spaghetti\n",
      "supot\n",
      "t-shirt\n",
      "tawad\n",
      "tinapay\n",
      "utang\n",
      "wala\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test = listOfLabeledGyroDataPerClass['left']['binebenta']\n",
    "testPerClass = {}\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    #print(('%s %s') % (a, k))\n",
    "    testPerClass[k] = []\n",
    "    test = listOfLabeledGyroDataPerClass['left'][k]\n",
    "    for i in listOfLabeledGyroDataPerClass['right'][k]:\n",
    "        test[i] = listOfLabeledGyroDataPerClass['right'][k][i]\n",
    "    for i in listOfLabeledAccDataPerClass['left'][k].columns:\n",
    "        test[i] = listOfLabeledAccDataPerClass['left'][k][i]\n",
    "    for i in listOfLabeledAccDataPerClass['right'][k].columns:\n",
    "        test[i] = listOfLabeledAccDataPerClass['right'][k][i]\n",
    "    for i in listOfLabeledDataPerClass['left'][k].columns:\n",
    "        test[i] = listOfLabeledDataPerClass['left'][k][i]\n",
    "    for i in listOfLabeledDataPerClass['right'][k].columns:\n",
    "        test[i] = listOfLabeledDataPerClass['right'][k][i]                        #emg data\n",
    "    testPerClass[k] = test\n",
    "# test\n",
    "# test.to_csv('/Users/user/Desktop/test.csv', encoding='utf-8', index=False)\n",
    "newDf = testPerClass['binebenta']\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    if k != 'binebenta':\n",
    "        print(k)\n",
    "        newDf= newDf.append(testPerClass[k]) \n",
    "\n",
    "df = newDf\n",
    "df = df[pd.notnull(df['left MeanFreq of EMG1'])]\n",
    "df = df[pd.notnull(df['right MeanFreq of EMG1'])]\n",
    "classNames = df[\"Class\"].tolist()\n",
    "df = df.drop(\"Class\", axis=1)\n",
    "\n",
    "x = df.values.astype(float)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "df = pd.DataFrame(x_scaled,columns=df.columns)\n",
    "df[\"Class\"] = classNames\n",
    "\n",
    "df.to_csv('ConsolidatedData-Normalized-2arms(Trimmed).csv', encoding='utf-8', index=False)\n",
    "newDf.to_csv('ConsolidatedData-Original-2arms(Trimmed).csv', encoding='utf-8', index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "df[57:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "5       1.0\n",
       "6       1.0\n",
       "7       1.0\n",
       "8       1.0\n",
       "9       1.0\n",
       "10      1.0\n",
       "11      1.0\n",
       "12      1.0\n",
       "13      1.0\n",
       "14      1.0\n",
       "15      1.0\n",
       "16      1.0\n",
       "17      1.0\n",
       "18      1.0\n",
       "19      1.0\n",
       "20      1.0\n",
       "21      1.0\n",
       "22      1.0\n",
       "23      1.0\n",
       "24      1.0\n",
       "25      1.0\n",
       "26      1.0\n",
       "27      1.0\n",
       "28      1.0\n",
       "29      1.0\n",
       "       ... \n",
       "2867    1.0\n",
       "2868    1.0\n",
       "2869    1.0\n",
       "2870    1.0\n",
       "2871    1.0\n",
       "2872    1.0\n",
       "2873    1.0\n",
       "2874    1.0\n",
       "2875    1.0\n",
       "2876    1.0\n",
       "2877    1.0\n",
       "2878    1.0\n",
       "2879    1.0\n",
       "2880    1.0\n",
       "2881    1.0\n",
       "2882    1.0\n",
       "2883    1.0\n",
       "2884    1.0\n",
       "2885    1.0\n",
       "2886    1.0\n",
       "2887    1.0\n",
       "2888    1.0\n",
       "2889    1.0\n",
       "2890    1.0\n",
       "2891    1.0\n",
       "2892    1.0\n",
       "2893    1.0\n",
       "2894    1.0\n",
       "2895    1.0\n",
       "2896    1.0\n",
       "Name: right MeanFreq of EMG2, Length: 2897, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['right MeanFreq of EMG2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf[225:] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDf.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "    \n",
    "\n",
    "\n",
    "# for k2 in GyroDataFramesPerFeature.keys():\n",
    "#     for i in GyroDataFramesPerFeature[k2].columns:\n",
    "#         dataFramesPerFeature['variance'][i] = GyroDataFramesPerFeature[k2][i]\n",
    "            \n",
    "# for k2 in accDataFramesPerFeature.keys():\n",
    "#     for i in accDataFramesPerFeature[k2].columns:\n",
    "#         dataFramesPerFeature['variance'][i] = accDataFramesPerFeature[k2][i]\n",
    "\n",
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "#     newDf = listOfLabeledAccDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledAccDataPerClass[a][k])\n",
    "# dataFramesPerFeature.to_csv('/Users/user/Desktop/test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Consolidation (save to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "#     newDf = listOfLabeledAccDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledAccDataPerClass[a][k])\n",
    "    \n",
    "    \n",
    "#     newDf.to_csv('/Users/user/Desktop/'+ a +'ArmConsolidatedAcc.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "#     newDf = listOfLabeledGyroDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedGyroDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledGyroDataPerClass[a][k])\n",
    "    \n",
    "    \n",
    "#     newDf.to_csv('/Users/user/Desktop/'+ a +'ArmConsolidatedGyro.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
