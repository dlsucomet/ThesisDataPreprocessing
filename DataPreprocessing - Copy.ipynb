{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "listOfFileNames = []\n",
    "listOfClassNames = []\n",
    "listOfDataPerClass = []\n",
    "files = []\n",
    "classNames = []\n",
    "\n",
    "classNames = glob.glob(\"/Users/user/Desktop/Thesis/placeholder/*\")\n",
    "\n",
    "for c in classNames:\n",
    "    className = c.split(\"\\\\\")[1]\n",
    "    listOfClassNames.append(c.split(\"\\\\\")[1])\n",
    "    files = glob.glob(\"/Users/user/Desktop/Thesis/placeholder/\"+className+\"/*.csv\")\n",
    "    listOfFileNames = []\n",
    "    for f in files:\n",
    "        listOfFileNames.append(f.split(\"\\\\\")[1])\n",
    "    listOfDataPerClass.append(listOfFileNames)\n",
    "\n",
    "    \n",
    "#listOfClassNames\n",
    "#listOfDataPerClass[0]\n",
    "print(\"Done listing the class and file names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(listOfDataPerClass)\n",
    "#listOfDataPerClass[3]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "listOfDataFramesPerClass = {}\n",
    "dataFrameDictionary = {}\n",
    "dataFrames = []\n",
    "\n",
    "for c, d in zip(listOfClassNames, listOfDataPerClass):\n",
    "    print(\"----------------- Word \" + c + \"-----------------\")\n",
    "    emgDataFrames = []\n",
    "    accDataFrames = []\n",
    "    gyroDataFrames = []\n",
    "\n",
    "    dataFrameDictionary = {}\n",
    "    className = c\n",
    "    ctr = 0\n",
    "    for fileName in d:\n",
    "        fileLocation = \"/Users/user/Desktop/Thesis/placeholder/\"+className+\"/\"+fileName + \"\"\n",
    "        df = pd.read_csv(fileLocation)\n",
    "        \n",
    "        if \"emg\" in fileName:            \n",
    "            emgDataFrames.append(df)\n",
    "            ctr+=1\n",
    "        elif (\"accelerometer\") in fileName:\n",
    "            accDataFrames.append(df)\n",
    "            ctr+=1\n",
    "        elif (\"gyro\") in fileName:\n",
    "            gyroDataFrames.append(df)\n",
    "            ctr+=1\n",
    "    \n",
    "    dataFrameDictionary[\"emg\"] = emgDataFrames\n",
    "    dataFrameDictionary[\"acc\"] = accDataFrames\n",
    "    dataFrameDictionary[\"gyro\"] = gyroDataFrames\n",
    "\n",
    "    listOfDataFramesPerClass[className] = dataFrameDictionary\n",
    "    print(\"Total of \" + str(ctr) + \" files\")\n",
    "\n",
    "\n",
    "print(\"Done converting to dataframes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(imuDataFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For EMG Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "listOfTrimmedDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    trimmedDataFramesPerClass = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for d in listOfDataFramesPerClass[k]['emg']:\n",
    "        keep_col = ['emg1','emg2','emg3','emg4','emg5','emg6','emg7','emg8']\n",
    "        new_df = d[keep_col]\n",
    "        new_df = new_df[:-49]\n",
    "        trimmed_df = new_df.iloc[49:]\n",
    "        if len(trimmed_df) < 100:\n",
    "            print(str(ctr) + \" \" + k)\n",
    "        trimmedDataFramesPerClass.append(trimmed_df)\n",
    "        ctr += 1\n",
    "        \n",
    "    print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"emg\"] = trimmedDataFramesPerClass\n",
    "    listOfTrimmedDataFramesPerClass[k] = dataFrameDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfTrimmedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for d in listOfTrimmedDataFramesPerClass[k]['emg']:\n",
    "        #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "        # Create x, where x the 'scores' column's values as floats\n",
    "        x = d.values.astype(float)\n",
    "\n",
    "        # Create a minimum and maximum processor object\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "        # Create an object to transform the data to fit minmax processor\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "        # Run the normalizer on the dataframe\n",
    "        df_normalized = pd.DataFrame(x_scaled)\n",
    "        #df_normalized\n",
    "        NormalizedDataFramesPerClass.append(df_normalized)\n",
    "        ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"emg\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "\n",
    "listOfVarianceDataFramePerClass = []\n",
    "listOfMavDataFramePerClass = []\n",
    "listOfMeanDataFramePerClass = []\n",
    "listOfSdDataFramePerClass = []\n",
    "listOfRmsDataFramePerClass = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "\n",
    "    varianceDataFramePerClass = []\n",
    "    varianceDataFrame = pd.DataFrame(columns = ['Variance of EMG1', 'Variance of EMG2', 'Variance of EMG3', 'Variance of EMG4',\n",
    "                                 'Variance of EMG5', 'Variance of EMG6', 'Variance of EMG7', 'Variance of EMG8'])\n",
    "    mavDataFramePerClass = []\n",
    "    mavDataFrame = pd.DataFrame(columns = ['Mav of EMG1', 'Mav of EMG2', 'Mav of EMG3', 'Mav of EMG4',\n",
    "                                 'Mav of EMG5', 'Mav of EMG6', 'Mav of EMG7', 'Mav of EMG8'])\n",
    "    meanDataFramePerClass = []\n",
    "    meanDataFrame = pd.DataFrame(columns = ['Mean of EMG1', 'Mean of EMG2', 'Mean of EMG3', 'Mean of EMG4',\n",
    "                                 'Mean of EMG5', 'Mean of EMG6', 'Mean of EMG7', 'Mean of EMG8'])\n",
    "    sdDataFramePerClass = []\n",
    "    sdDataFrame = pd.DataFrame(columns = ['Sd of EMG1', 'Sd of EMG2', 'Sd of EMG3', 'Sd of EMG4',\n",
    "                                 'Sd of EMG5', 'Sd of EMG6', 'Sd of EMG7', 'Sd of EMG8'])\n",
    "    rmsDataFramePerClass = []\n",
    "    rmsDataFrame = pd.DataFrame(columns = ['Rms of EMG1', 'Rms of EMG2', 'Rms of EMG3', 'Rms of EMG4',\n",
    "                                 'Rms of EMG5', 'Rms of EMG6', 'Rms of EMG7', 'Rms of EMG8'])\n",
    "    \n",
    "    for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        varianceDataFrame.loc[ctr] = [df_normalized.var()[0], df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3], df_normalized.var()[4], df_normalized.var()[5], df_normalized.var()[6], df_normalized.var()[7]]\n",
    "        mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[0], robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3], robust.mad(df_normalized)[4], robust.mad(df_normalized)[5], robust.mad(df_normalized)[6], robust.mad(df_normalized)[7]]\n",
    "        meanDataFrame.loc[ctr] = [np.mean(df_normalized)[0], np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3], np.mean(df_normalized)[4], np.mean(df_normalized)[5], np.mean(df_normalized)[6], np.mean(df_normalized)[7]]\n",
    "        sdDataFrame.loc[ctr] = [np.std(df_normalized)[0], np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3], np.std(df_normalized)[4], np.std(df_normalized)[5], np.std(df_normalized)[6], np.std(df_normalized)[7]]\n",
    "        rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[0].values**2)), np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2)), np.sqrt(np.mean(df_normalized[4].values**2)), np.sqrt(np.mean(df_normalized[5].values**2)), robust.mad(df_normalized)[6], np.sqrt(np.mean(df_normalized[7].values**2))]\n",
    "\n",
    "        ctr +=1 \n",
    "        \n",
    "    print(\"Done computing the var, mav, mean , sd, and rms of \" + str(ctr) + \" files\")\n",
    "    listOfVarianceDataFramePerClass.append(varianceDataFrame)\n",
    "    listOfMavDataFramePerClass.append(mavDataFrame)\n",
    "    listOfMeanDataFramePerClass.append(meanDataFrame)\n",
    "    listOfSdDataFramePerClass.append(sdDataFrame)\n",
    "    listOfRmsDataFramePerClass.append(rmsDataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and Median Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "listOfMeanFreqDataFramePerClass = []\n",
    "listOfMedFreqDataFramePerClass = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    meanFreqDataFramePerClass = []\n",
    "    meanFreqDataFrame = pd.DataFrame(columns = ['MeanFreq of EMG1', 'MeanFreq of EMG2', 'MeanFreq of EMG3', 'MeanFreq of EMG4',\n",
    "                                 'MeanFreq of EMG5', 'MeanFreq of EMG6', 'MeanFreq of EMG7', 'MeanFreq of EMG8'])\n",
    "    \n",
    "    medFreqDataFramePerClass = []\n",
    "    medFreqDataFrame = pd.DataFrame(columns = ['MedianFreq of EMG1', 'MedianFreq of EMG2', 'MedianFreq of EMG3', 'MedianFreq of EMG4',\n",
    "                                 'MedianFreq of EMG5', 'MedianFreq of EMG6', 'MedianFreq of EMG7', 'MedianFreq of EMG8'])\n",
    "    \n",
    "    for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        meanFreq = []\n",
    "        medFreq = []\n",
    "\n",
    "        for i in range(0, 8):\n",
    "            data = df_normalized[i].values\n",
    "            ps = np.abs(np.fft.fft(data))**2\n",
    "\n",
    "            freqs = np.fft.fftfreq(data.size, 1/100)\n",
    "\n",
    "            sumProd = 0\n",
    "            sumPs = 0\n",
    "\n",
    "            for f, p in zip(freqs,ps):\n",
    "                sumProd += f*p\n",
    "                sumPs += p\n",
    "\n",
    "            meanFreq.append(sumProd/sumPs)\n",
    "            medFreq.append(sumPs/2)\n",
    "            \n",
    "        meanFreqDataFrame.loc[ctr] = [meanFreq[0], meanFreq[1], meanFreq[2], meanFreq[3], meanFreq[4], meanFreq[5], meanFreq[6], meanFreq[7]]\n",
    "        medFreqDataFrame.loc[ctr] = [medFreq[0], medFreq[1], medFreq[2], medFreq[3], medFreq[4], medFreq[5], medFreq[6], medFreq[7]]\n",
    "\n",
    "        ctr+=1\n",
    "        \n",
    "    print(\"Done getting the Mean and Median Frequency of \" + str(ctr) + \" files\")\n",
    "    listOfMeanFreqDataFramePerClass.append(meanFreqDataFrame)\n",
    "    listOfMedFreqDataFramePerClass.append(medFreqDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance\n",
      "mav\n",
      "rms\n"
     ]
    }
   ],
   "source": [
    "dataFramesPerFeature = {}\n",
    "\n",
    "dataFramesPerFeature['variance'] = listOfVarianceDataFramePerClass[ctr]\n",
    "dataFramesPerFeature['mav'] = listOfMavDataFramePerClass[ctr]\n",
    "dataFramesPerFeature['rms'] = listOfRmsDataFramePerClass[ctr]\n",
    "\n",
    "for k in dataFramesPerFeature.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done labeling emg data of ano\n",
      "Done labeling emg data of bibili\n",
      "Done labeling emg data of black\n",
      "Done labeling emg data of dito\n",
      "Done labeling emg data of isa\n",
      "Done labeling emg data of kape\n",
      "Done labeling emg data of kayo\n",
      "Done labeling emg data of kulay\n",
      "Done labeling emg data of magkano\n",
      "Done labeling emg data of mayroon\n",
      "Done labeling emg data of niyo\n",
      "Done labeling emg data of oras\n",
      "Done labeling emg data of pagkain\n",
      "Done labeling emg data of small\n",
      "Done labeling emg data of tubig\n"
     ]
    }
   ],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "ctr = 0\n",
    "\n",
    "listOfLabeledDataPerClass = {}\n",
    "for k in listOfTrimmedDataFramesPerClass.keys():\n",
    "    dataFramesPerFeature = {}\n",
    "\n",
    "    dataFramesPerFeature['variance'] = listOfVarianceDataFramePerClass[ctr]\n",
    "    dataFramesPerFeature['mav'] = listOfMavDataFramePerClass[ctr]\n",
    "    dataFramesPerFeature['rms'] = listOfRmsDataFramePerClass[ctr]\n",
    "    dataFramesPerFeature['sd'] = listOfSdDataFramePerClass[ctr]\n",
    "    dataFramesPerFeature['mean'] = listOfMeanDataFramePerClass[ctr]\n",
    "    dataFramesPerFeature['meanFreq'] = listOfMedFreqDataFramePerClass[ctr]\n",
    "    dataFramesPerFeature['meanFreq'] = listOfMeanFreqDataFramePerClass[ctr]\n",
    "    \n",
    "    \n",
    "    for k2 in dataFramesPerFeature.keys():\n",
    "        if k2 != 'variance':\n",
    "            for i in dataFramesPerFeature[k2].columns:\n",
    "                dataFramesPerFeature['variance'][i] = dataFramesPerFeature[k2][i]\n",
    "\n",
    "    dataFramesPerFeature['variance']['Class'] = k\n",
    "    listOfLabeledDataPerClass[k] = dataFramesPerFeature['variance']\n",
    "    ctr+=1\n",
    "    print(\"Done labeling emg data of \" + k)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Consolidation (save to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bibili\n",
      "black\n",
      "dito\n",
      "isa\n",
      "kape\n",
      "kayo\n",
      "kulay\n",
      "magkano\n",
      "mayroon\n",
      "niyo\n",
      "oras\n",
      "pagkain\n",
      "small\n",
      "tubig\n"
     ]
    }
   ],
   "source": [
    "newDf = listOfLabeledDataPerClass['ano']\n",
    "for k in listOfTrimmedDataFramesPerClass.keys():\n",
    "    if k != 'ano':\n",
    "        print(k)\n",
    "        newDf= newDf.append(listOfLabeledDataPerClass[k])\n",
    "newDf.to_csv('/Users/user/Desktop/consolidatedEMG.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For IMU values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming (For Acceleration and Gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "listOfTrimmedAccDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    trimmedDataFramesPerClass = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for d in listOfDataFramesPerClass[k]['acc']:\n",
    "        keep_col = ['x','y','z']\n",
    "        new_df = d[keep_col]\n",
    "        new_df = new_df[:-24]\n",
    "        trimmed_df = new_df.iloc[24:]\n",
    "        if len(trimmed_df) < 50:\n",
    "            print(str(ctr) + \" \" + str(len(trimmed_df)))\n",
    "        trimmedDataFramesPerClass.append(trimmed_df)\n",
    "        ctr += 1\n",
    "        \n",
    "    print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"acc\"] = trimmedDataFramesPerClass\n",
    "    listOfTrimmedAccDataFramesPerClass[k] = dataFrameDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "listOfTrimmedGyroDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    trimmedDataFramesPerClass = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for d in listOfDataFramesPerClass[k]['gyro']:\n",
    "        keep_col = ['x','y','z']\n",
    "        new_df = d[keep_col]\n",
    "        new_df = new_df[:-24]\n",
    "        trimmed_df = new_df.iloc[24:]\n",
    "        if len(trimmed_df) < 50:\n",
    "            print(str(ctr) + \" \" + str(len(trimmed_df)))\n",
    "        trimmedDataFramesPerClass.append(trimmed_df)\n",
    "        ctr += 1\n",
    "        \n",
    "    print(\"Done Trimming \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"gyro\"] = trimmedDataFramesPerClass\n",
    "    listOfTrimmedGyroDataFramesPerClass[k] = dataFrameDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization (For Acceleration and Gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedAccDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for d in listOfTrimmedAccDataFramesPerClass[k]['acc']:\n",
    "        #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "        # Create x, where x the 'scores' column's values as floats\n",
    "        x = d.values.astype(float)\n",
    "\n",
    "        # Create a minimum and maximum processor object\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "        # Create an object to transform the data to fit minmax processor\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "        # Run the normalizer on the dataframe\n",
    "        df_normalized = pd.DataFrame(x_scaled)\n",
    "        #df_normalized\n",
    "        NormalizedDataFramesPerClass.append(df_normalized)\n",
    "        ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"acc\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedAccDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedGyroDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfTrimmedGyroDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for d in listOfTrimmedGyroDataFramesPerClass[k]['gyro']:\n",
    "        #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "        # Create x, where x the 'scores' column's values as floats\n",
    "        x = d.values.astype(float)\n",
    "\n",
    "        # Create a minimum and maximum processor object\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "        # Create an object to transform the data to fit minmax processor\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "        # Run the normalizer on the dataframe\n",
    "        df_normalized = pd.DataFrame(x_scaled)\n",
    "        #df_normalized\n",
    "        NormalizedDataFramesPerClass.append(df_normalized)\n",
    "        ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"gyro\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedGyroDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listOfNormalizedDataFramesPerClass['ano']['imu'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "\n",
    "listOfLabeledImuDataPerClass = []\n",
    "for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "    ctr = 0\n",
    "\n",
    "    labeledDataFramePerClass = []\n",
    "    labeledDataFrame = pd.DataFrame(columns = ['X of Accelerometer', 'Y of Accelerometer', 'Z of Accelerometer', \n",
    "                                               'X of Gyroscope', 'Y of Gyroscope', 'Z of Gyroscope', 'Class'])\n",
    "    for a, g in zip(listOfNormalizedAccDataFramesPerClass[k]['acc'],listOfNormalizedGyroDataFramesPerClass[k]['gyro'])\n",
    "        labeledDataFrame.loc[ctr] = [a[0], a[1], a[2], g[0], g[1], g[2], k]\n",
    "        ctr+=1\n",
    "\n",
    "    listOfLabeledImuDataPerClass.append(labeledDataFrame)\n",
    "    print(\"Done labeling imu data of \" + k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "listOfMavDataFramePerClass = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    mavDataFramePerClass = []\n",
    "    mavDataFrame = pd.DataFrame(columns = ['Mav of EMG1', 'Mav of EMG2', 'Mav of EMG3', 'Mav of EMG4',\n",
    "                                 'Mav of EMG5', 'Mav of EMG6', 'Mav of EMG7', 'Mav of EMG8'])\n",
    "   \n",
    "    for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[0], robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3], robust.mad(df_normalized)[4], robust.mad(df_normalized)[5], robust.mad(df_normalized)[6], robust.mad(df_normalized)[7]]\n",
    "        ctr +=1 \n",
    "        \n",
    "    print(\"Done getting the mav of \" + str(ctr) + \" files\")\n",
    "    listOfMavDataFramePerClass.append(mavDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Consolidation (save to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newDf = listOfLabeledDataPerClass['ano']\n",
    "for k in listOfTrimmedDataFramesPerClass.keys():\n",
    "    if k != 'ano':\n",
    "        print(k)\n",
    "        newDf= newDf.append(listOfLabeledDataPerClass[k])\n",
    "newDf.to_csv('/Users/user/Desktop/consolidatedEMG.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kurtosis (For Acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# per row returns nan, nan, nan...\n",
    "df_normalized.kurtosis().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Deviation (For Acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_normalized.std(axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean (For Acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_normalized.mean(axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance (For Acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_normalized.var(axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy (For Acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "# per row returns 0...\n",
    "sp.stats.entropy(df_normalized).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skewness (For Acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_normalized.skew(axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Value (For Acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels import robust\n",
    "\n",
    "rows = []\n",
    "mavValues = []\n",
    "length = df_normalized.shape[0]\n",
    "\n",
    "for x in range(0, length):\n",
    "    rows.append(df_normalized.iloc[x].tolist())\n",
    "\n",
    "for x in range(0, length):\n",
    "    mavValues.append(robust.mad(rows[x]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Square (For Acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.sqrt(df_normalized.mean(axis=1)**2).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "# fit a SVM model to the data\n",
    "model = SVC()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
