{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from statsmodels import robust\n",
    "import glob\n",
    "import io\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "path = \"trimmed_data_updated/ano/\"\n",
    "data = {}\n",
    "\n",
    "filenames = {\"gyro0-left2a\", \"gyro0-right2a\", \"acc0-left2a\", \"acc0-right2a\", \"emg0-left2a\", \"emg0-right2a\"};\n",
    "\n",
    "for f in filenames:\n",
    "    \n",
    "    data[f] = pd.read_csv(path+f+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataFrameDictionary = {}\n",
    "\n",
    "arms = [\"left\", \"right\"]\n",
    "\n",
    "emgDataFrames = {}\n",
    "emgDataFrames['right'] = data[\"emg0-right2a\"]\n",
    "emgDataFrames['left'] = data[\"emg0-left2a\"]\n",
    "\n",
    "accDataFrames = {}\n",
    "accDataFrames['right'] = data[\"acc0-right2a\"]\n",
    "accDataFrames['left'] = data[\"acc0-left2a\"]\n",
    "\n",
    "gyroDataFrames = {}\n",
    "gyroDataFrames['right'] = data[\"gyro0-right2a\"]\n",
    "gyroDataFrames['left'] = data[\"gyro0-left2a\"]\n",
    "\n",
    "dataFrameDictionary['emg'] = emgDataFrames\n",
    "dataFrameDictionary['acc'] = accDataFrames\n",
    "dataFrameDictionary['gyro'] = gyroDataFrames\n",
    "\n",
    "features ={}\n",
    "features['right'] = []\n",
    "features['left'] = []\n",
    "\n",
    "for a in arms:\n",
    "    \n",
    "    df = dataFrameDictionary['emg'][a]\n",
    "    \n",
    "    # bandpass filter\n",
    "    for column in df:\n",
    "        if \"time\" not in column:\n",
    "            emg = np.array(df[column].values)\n",
    "\n",
    "            emg_correctmean = emg - np.mean(emg)\n",
    "\n",
    "            # create bandpass filter for EMG\n",
    "            high = 2/(100/2)\n",
    "            low = 45/(100/2)\n",
    "            b, a1 = sp.signal.butter(4, [high,low], btype='bandpass')\n",
    "\n",
    "            emg_filtered = sp.signal.filtfilt(b, a1, emg_correctmean)\n",
    "\n",
    "            emg_rectified = abs(emg_filtered)\n",
    "\n",
    "                # create lowpass filter and apply to rectified signal to get EMG envelope\n",
    "            sfreq = 100\n",
    "            low_pass = 10/sfreq\n",
    "            b2, a2 = sp.signal.butter(4, low_pass, btype='lowpass')\n",
    "            emg_envelope = sp.signal.filtfilt(b2, a2, emg_rectified)\n",
    "\n",
    "            df[column] = emg_envelope\n",
    "    \n",
    "    filteredDf = df\n",
    "    \n",
    "    print(\"Filtering of \" + a + \" emg Done!!\")\n",
    "    \n",
    "    ctr = 0\n",
    "   \n",
    "    x = filteredDf.values.astype(float)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "    normalizedDf = df_normalized\n",
    "\n",
    "    print(a + \"EMG Data Normalization done!!\")\n",
    "\n",
    "    \n",
    "\n",
    "    ctr = 0\n",
    "    \n",
    "    df_normalized = normalizedDf\n",
    "    \n",
    "    arm = a + \" \"\n",
    "    \n",
    "    varianceDataFrame = pd.DataFrame(columns = [(arm + 'variance of EMG1'), (arm + 'variance of EMG2'), (arm + 'variance of EMG3'), (arm + 'variance of EMG4'),\n",
    "                                 (arm + 'variance of EMG5'), (arm + 'variance of EMG6'), (arm + 'variance of EMG7'), (arm + 'variance of EMG8')])\n",
    "    mavDataFrame = pd.DataFrame(columns = [(arm + 'Mav of EMG1'), (arm + 'Mav of EMG2'), (arm + 'Mav of EMG3'), (arm + 'Mav of EMG4'),\n",
    "                                     (arm + 'Mav of EMG5'), (arm + 'Mav of EMG6'), (arm + 'Mav of EMG7'), (arm + 'Mav of EMG8')])\n",
    "    meanDataFrame = pd.DataFrame(columns = [(arm + 'Mean of EMG1'), (arm + 'Mean of EMG2'), (arm + 'Mean of EMG3'), (arm + 'Mean of EMG4'),\n",
    "                                     (arm + 'Mean of EMG5'), (arm + 'Mean of EMG6'), (arm + 'Mean of EMG7'), (arm + 'Mean of EMG8')])\n",
    "    sdDataFrame = pd.DataFrame(columns = [(arm + 'Sd of EMG1'), (arm + 'Sd of EMG2'), (arm + 'Sd of EMG3'), (arm + 'Sd of EMG4'),\n",
    "                                     (arm + 'Sd of EMG5'), (arm + 'Sd of EMG6'), (arm + 'Sd of EMG7'), (arm + 'Sd of EMG8')])\n",
    "    rmsDataFrame = pd.DataFrame(columns = [(arm + 'Rms of EMG1'), (arm + 'Rms of EMG2'), (arm + 'Rms of EMG3'), (arm + 'Rms of EMG4'),\n",
    "                                     (arm + 'Rms of EMG5'), (arm + 'Rms of EMG6'), (arm + 'Rms of EMG7'), (arm + 'Rms of EMG8')])\n",
    "    meanFreqDataFrame = pd.DataFrame(columns = [(arm + 'MeanFreq of EMG1'), (arm + 'MeanFreq of EMG2'), (arm + 'MeanFreq of EMG3'), (arm + 'MeanFreq of EMG4'),\n",
    "                                 (arm + 'MeanFreq of EMG5'), (arm + 'MeanFreq of EMG6'), (arm + 'MeanFreq of EMG7'), (arm + 'MeanFreq of EMG8')]) \n",
    "    medFreqDataFrame = pd.DataFrame(columns = [(arm + 'MedianFreq of EMG1'), (arm + 'MedianFreq of EMG2'), (arm + 'MedianFreq of EMG3'), (arm + 'MedianFreq of EMG4'),\n",
    "                                     (arm + 'MedianFreq of EMG5'), (arm + 'MedianFreq of EMG6'), (arm + 'MedianFreq of EMG7'), (arm + 'MedianFreq of EMG8')])\n",
    "\n",
    "    varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3], df_normalized.var()[4], df_normalized.var()[5], df_normalized.var()[6], df_normalized.var()[7], df_normalized.var()[8]]\n",
    "    mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3], robust.mad(df_normalized)[4], robust.mad(df_normalized)[5], robust.mad(df_normalized)[6], robust.mad(df_normalized)[7], robust.mad(df_normalized)[8]]\n",
    "    meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3], np.mean(df_normalized)[4], np.mean(df_normalized)[5], np.mean(df_normalized)[6], np.mean(df_normalized)[7], np.mean(df_normalized)[8]]\n",
    "    sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3], np.std(df_normalized)[4], np.std(df_normalized)[5], np.std(df_normalized)[6], np.std(df_normalized)[7], np.std(df_normalized)[8]]\n",
    "    rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2)), np.sqrt(np.mean(df_normalized[4].values**2)), np.sqrt(np.mean(df_normalized[5].values**2)), np.sqrt(np.mean(df_normalized[6].values**2)),  np.sqrt(np.mean(df_normalized[7].values**2)), np.sqrt(np.mean(df_normalized[8].values**2))]\n",
    "    \n",
    "    meanFreq = []\n",
    "    medFreq = []\n",
    "\n",
    "    for i in range(1, 9):\n",
    "        data = df_normalized[i].values\n",
    "        ps = np.abs(np.fft.fft(data))**2\n",
    "\n",
    "        freqs = np.fft.fftfreq(data.size, 1/100)\n",
    "\n",
    "        sumProd = 0\n",
    "        sumPs = 0\n",
    "\n",
    "        for f, p in zip(freqs,ps):\n",
    "            sumProd += f*p\n",
    "            sumPs += p\n",
    "\n",
    "        sumProd = sumProd * 100000000\n",
    "        meanFreq.append(100000000*sumProd/sumPs)\n",
    "        medFreq.append(sumPs/2)\n",
    "\n",
    "\n",
    "    meanFreqDataFrame.loc[ctr] = [meanFreq[0], meanFreq[1], meanFreq[2], meanFreq[3], meanFreq[4], meanFreq[5], meanFreq[6], meanFreq[7]]\n",
    "    medFreqDataFrame.loc[ctr] = [medFreq[0], medFreq[1], medFreq[2], medFreq[3], medFreq[4], medFreq[5], medFreq[6], medFreq[7]]\n",
    "\n",
    "    ctr +=1 \n",
    "\n",
    "    features[a].append(varianceDataFrame)\n",
    "    features[a].append(mavDataFrame)\n",
    "    features[a].append(meanDataFrame)\n",
    "    features[a].append(sdDataFrame)\n",
    "    features[a].append(rmsDataFrame)\n",
    "    features[a].append(meanFreqDataFrame)\n",
    "    features[a].append(medFreqDataFrame)\n",
    "    print(\"Done computing emg features of \" + str(ctr) + a + \" arm files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for a in arms:\n",
    "    df = dataFrameDictionary['acc'][a]\n",
    "\n",
    "    x = df.values.astype(float)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "    normalizedAccDf = df_normalized\n",
    "\n",
    "    print(a + \"Acc Data Normalization done!!\")\n",
    "\n",
    "    ctr = 0    \n",
    "    arm = a + \" \"\n",
    "    \n",
    "    \n",
    "    #Acc features\n",
    "    df_normalized = normalizedAccDf\n",
    "    \n",
    "    varianceDataFrame = pd.DataFrame(columns = [(arm+ 'Variance of ACC x'), (arm+ 'Variance of ACC y'), (arm+ 'Variance of ACC z')])\n",
    "    mavDataFrame = pd.DataFrame(columns = [(arm + 'Mav of ACC x'), (arm + 'Mav of ACC y'), (arm + 'Mav of ACC z')])\n",
    "    meanDataFrame = pd.DataFrame(columns = [(arm + 'Mean of ACC x'), (arm + 'Mean of ACC y'), (arm + 'Mean of ACC z')])\n",
    "    sdDataFrame = pd.DataFrame(columns = [(arm + 'Sd of ACC x'), (arm + 'Sd of ACC y'), (arm + 'Sd of ACC z')])\n",
    "    rmsDataFrame = pd.DataFrame(columns = [(arm + 'Rms of ACC x'), (arm + 'Rms of ACC y'), (arm + 'Rms of ACC z')])\n",
    "    entropyDataFrame = pd.DataFrame(columns = [(arm + 'Entropy of ACC x'), (arm + 'Entropy of ACC y'), (arm + 'Entropy of ACC z')])\n",
    "    kurtosisDataFrame = pd.DataFrame(columns = [(arm + 'Kurtosis of ACC x'), (arm + 'Kurtosis of ACC y'), (arm + 'Kurtosis of ACC z')])\n",
    "    skewnessDataFrame = pd.DataFrame(columns = [(arm + 'Skewness of ACC x'), (arm + 'Skewness of ACC y'), (arm + 'Skewness of ACC z')])\n",
    "    smaDataFrame = pd.DataFrame(columns = [(arm + 'SMA of ACC')])\n",
    "    integrationDataFrame = pd.DataFrame(columns = [(arm + 'Integration of ACC x'), (arm + 'Integration of ACC y'), (arm + 'Integration of ACC z')])\n",
    "    \n",
    "    \n",
    "    \n",
    "    varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3]]\n",
    "    mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3]]\n",
    "    meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3]]\n",
    "    sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3]]\n",
    "    rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2))]\n",
    "    entropyDataFrame.loc[ctr] = [sp.stats.entropy(df_normalized)[1], sp.stats.entropy(df_normalized)[2], sp.stats.entropy(df_normalized)[3]]\n",
    "    kurtosisDataFrame.loc[ctr] = [df_normalized.kurtosis()[1], df_normalized.kurtosis()[2], df_normalized.kurtosis()[3]]\n",
    "    skewnessDataFrame.loc[ctr] = [df_normalized.skew(axis=0)[1], df_normalized.skew(axis=0)[2], df_normalized.skew(axis=0)[3]]\n",
    "    length = df_normalized.shape[1]\n",
    "    sma = 0\n",
    "    for x in range(0, length):\n",
    "        sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "    sma = sma / length\n",
    "    smaDataFrame.loc[ctr] = [sma]\n",
    "    integrationDataFrame.loc[ctr] = [sp.integrate.simps(df_normalized, axis=0)[1],sp.integrate.simps(df_normalized, axis=0)[2], sp.integrate.simps(df_normalized, axis=0)[3]]\n",
    "\n",
    "    features[a].append(varianceDataFrame)\n",
    "    features[a].append(mavDataFrame)\n",
    "    features[a].append(meanDataFrame)\n",
    "    features[a].append(sdDataFrame)\n",
    "    features[a].append(rmsDataFrame)\n",
    "    features[a].append(entropyDataFrame) \n",
    "    features[a].append(kurtosisDataFrame) \n",
    "    features[a].append(skewnessDataFrame) \n",
    "    features[a].append(smaDataFrame) \n",
    "    features[a].append(integrationDataFrame) \n",
    "    \n",
    "    print(a +\"Done computing acc features!!!!!!!\")\n",
    "    \n",
    "    df = dataFrameDictionary['gyro'][a]\n",
    "    x = df.values.astype(float)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "    normalizedGyroDf = df_normalized\n",
    "    print(a +\"Gyro Data Normalization done!!\")\n",
    "    \n",
    "    #Gyro features    \n",
    "    df_normalized = normalizedGyroDf\n",
    "    varianceDataFrame = pd.DataFrame(columns = [(arm + 'Variance of Gyro x'), (arm+ 'Variance of Gyro y'), (arm+ 'Variance of Gyro z')])\n",
    "    mavDataFrame = pd.DataFrame(columns = [(arm+ 'Mav of Gyro x'), (arm+ 'Mav of Gyro y'), (arm+ 'Mav of Gyro z')])\n",
    "    meanDataFrame = pd.DataFrame(columns = [(arm+ 'Mean of Gyro x'), (arm+ 'Mean of Gyro y'), (arm+ 'Mean of Gyro z')])\n",
    "    sdDataFrame = pd.DataFrame(columns = [(arm+ 'Sd of Gyro x'), (arm+ 'Sd of Gyro y'), (arm+ 'Sd of Gyro z')])\n",
    "    rmsDataFrame = pd.DataFrame(columns = [(arm+ 'Rms of Gyro x'), (arm+ 'Rms of Gyro y'), (arm+ 'Rms of Gyro z')])\n",
    "    entropyDataFrame = pd.DataFrame(columns = [(arm+ 'Entropy of Gyro x'), (arm+ 'Entropy of Gyro y'), (arm+ 'Entropy of Gyro z')])\n",
    "    kurtosisDataFrame = pd.DataFrame(columns = [(arm+ 'Kurtosis of Gyro x'), (arm+ 'Kurtosis of Gyro y'), (arm+ 'Kurtosis of Gyro z')])\n",
    "    skewnessDataFrame = pd.DataFrame(columns = [(arm+ 'Skewness of Gyro x'), (arm+ 'Skewness of Gyro y'), (arm+ 'Skewness of Gyro z')])\n",
    "    smaDataFrame = pd.DataFrame(columns = [(arm+ 'SMA of Gyro')])\n",
    "    integrationDataFrame = pd.DataFrame(columns = [(arm+ 'Integration of Gyro x'), (arm+ 'Integration of Gyro y'), (arm+ 'Integration of Gyro z')])\n",
    "\n",
    "        \n",
    "    varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3]]\n",
    "    mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3]]\n",
    "    meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3]]\n",
    "    sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3]]\n",
    "    rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2))]\n",
    "    entropyDataFrame.loc[ctr] = [sp.stats.entropy(df_normalized)[1], sp.stats.entropy(df_normalized)[2], sp.stats.entropy(df_normalized)[3],]\n",
    "    kurtosisDataFrame.loc[ctr] = [df_normalized.kurtosis()[1], df_normalized.kurtosis()[2], df_normalized.kurtosis()[3]]\n",
    "    skewnessDataFrame.loc[ctr] = [df_normalized.skew(axis=0)[1], df_normalized.skew(axis=0)[2], df_normalized.skew(axis=0)[3]]\n",
    "    length = df_normalized.shape[1]\n",
    "    sma = 0\n",
    "    for x in range(0, length):\n",
    "            # .iloc[x,0] is Gyroessing row, column\n",
    "        sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "    sma = sma / length\n",
    "    smaDataFrame.loc[ctr] = [sma]\n",
    "    integrationDataFrame.loc[ctr] = [sp.integrate.simps(df_normalized, axis=0)[1],sp.integrate.simps(df_normalized, axis=0)[2], sp.integrate.simps(df_normalized, axis=0)[3]]\n",
    "\n",
    "    features[a].append(varianceDataFrame)\n",
    "    features[a].append(mavDataFrame)\n",
    "    features[a].append(meanDataFrame)\n",
    "    features[a].append(sdDataFrame)\n",
    "    features[a].append(rmsDataFrame)\n",
    "    features[a].append(entropyDataFrame) \n",
    "    features[a].append(kurtosisDataFrame) \n",
    "    features[a].append(skewnessDataFrame) \n",
    "    features[a].append(smaDataFrame) \n",
    "    features[a].append(integrationDataFrame) \n",
    "    \n",
    "    print(a +\"Done computing gyro features!!!!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(features['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combine data\n",
    "firstFeature = features['left'][0]\n",
    "consolidatedFeatures = firstFeature\n",
    "\n",
    "for a in arms:\n",
    "    for feature in features[a]:\n",
    "        for column in feature:\n",
    "            if('left variance of E' not in column):\n",
    "                consolidatedFeatures[column] = feature[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(consolidatedFeatures.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consolidatedFeatures.to_csv('1data.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
