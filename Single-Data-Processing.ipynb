{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from statsmodels import robust\n",
    "import glob\n",
    "import io\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "gesture = [\"spaghetti\"]\n",
    "path = \"trimmed_data_updated/\"+gesture[0]+\"/\"\n",
    "data = {}\n",
    "w = \"20\"\n",
    "filenames = {\"gyro\"+ w +\"-left2a\", \"gyro\"+ w +\"-right2a\", \"acc\"+ w +\"-left2a\", \"acc\"+ w +\"-right2a\", \"emg\"+ w +\"-left2a\", \"emg\"+ w +\"-right2a\"};\n",
    "\n",
    "for f in filenames:\n",
    "    \n",
    "    data[f] = pd.read_csv(path+f+\".csv\")\n",
    "\n",
    "dataFrameDictionary = {}\n",
    "\n",
    "arms = [\"left\", \"right\"]\n",
    "\n",
    "emgDataFrames = {}\n",
    "emgDataFrames['right'] = data[\"emg\"+ w +\"-right2a\"]\n",
    "emgDataFrames['left'] = data[\"emg\"+ w +\"-left2a\"]\n",
    "\n",
    "accDataFrames = {}\n",
    "accDataFrames['right'] = data[\"acc\"+ w +\"-right2a\"]\n",
    "accDataFrames['left'] = data[\"acc\"+ w +\"-left2a\"]\n",
    "\n",
    "gyroDataFrames = {}\n",
    "gyroDataFrames['right'] = data[\"gyro\"+ w +\"-right2a\"]\n",
    "gyroDataFrames['left'] = data[\"gyro\"+ w +\"-left2a\"]\n",
    "\n",
    "dataFrameDictionary['emg'] = emgDataFrames\n",
    "dataFrameDictionary['acc'] = accDataFrames\n",
    "dataFrameDictionary['gyro'] = gyroDataFrames\n",
    "\n",
    "features ={}\n",
    "features['left'] = []\n",
    "features['right'] = []\n",
    "\n",
    "dfColumns = [\"left Variance of Gyro x\", \"left Variance of Gyro y\", \"left Variance of Gyro z\", \n",
    "         \"left Mav of Gyro x\", \"left Mav of Gyro y\", \"left Mav of Gyro z\", \"left Rms of Gyro x\", \"left Rms of Gyro y\", \n",
    "         \"left Rms of Gyro z\", \"left Sd of Gyro x\", \"left Sd of Gyro y\", \"left Sd of Gyro z\", \"left Mean of Gyro x\", \n",
    "         \"left Mean of Gyro y\", \"left Mean of Gyro z\", \"left Entropy of Gyro x\", \"left Entropy of Gyro y\", \n",
    "         \"left Entropy of Gyro z\", \"left Kurtosis of Gyro x\", \"left Kurtosis of Gyro y\", \"left Kurtosis of Gyro z\", \n",
    "         \"left Skewness of Gyro x\", \"left Skewness of Gyro y\", \"left Skewness of Gyro z\", \"left SMA of Gyro\", \n",
    "         \"left Integration of Gyro x\", \"left Integration of Gyro y\", \"left Integration of Gyro z\", \n",
    "         \"right Variance of Gyro x\", \"right Variance of Gyro y\", \"right Variance of Gyro z\", \"right Mav of Gyro x\", \n",
    "         \"right Mav of Gyro y\", \"right Mav of Gyro z\", \"right Rms of Gyro x\", \"right Rms of Gyro y\", \n",
    "         \"right Rms of Gyro z\", \"right Sd of Gyro x\", \"right Sd of Gyro y\", \"right Sd of Gyro z\", \"right Mean of Gyro x\", \n",
    "         \"right Mean of Gyro y\", \"right Mean of Gyro z\", \"right Entropy of Gyro x\", \"right Entropy of Gyro y\", \n",
    "         \"right Entropy of Gyro z\", \"right Kurtosis of Gyro x\", \"right Kurtosis of Gyro y\", \"right Kurtosis of Gyro z\", \n",
    "         \"right Skewness of Gyro x\", \"right Skewness of Gyro y\", \"right Skewness of Gyro z\", \"right SMA of Gyro\", \n",
    "         \"right Integration of Gyro x\", \"right Integration of Gyro y\", \"right Integration of Gyro z\", \"left Variance of ACC x\", \n",
    "         \"left Variance of ACC y\", \"left Variance of ACC z\", \"left Mav of ACC x\", \"left Mav of ACC y\", \"left Mav of ACC z\", \n",
    "         \"left Rms of ACC x\", \"left Rms of ACC y\", \"left Rms of ACC z\", \"left Sd of ACC x\", \"left Sd of ACC y\", \n",
    "         \"left Sd of ACC z\", \"left Mean of ACC x\", \"left Mean of ACC y\", \"left Mean of ACC z\", \"left Entropy of ACC x\", \n",
    "         \"left Entropy of ACC y\", \"left Entropy of ACC z\", \"left Kurtosis of ACC x\", \"left Kurtosis of ACC y\", \n",
    "         \"left Kurtosis of ACC z\", \"left Skewness of ACC x\", \"left Skewness of ACC y\", \"left Skewness of ACC z\", \n",
    "         \"left SMA of ACC\", \"left Integration of ACC x\", \"left Integration of ACC y\", \"left Integration of ACC z\", \n",
    "         \"right Variance of ACC x\", \"right Variance of ACC y\", \"right Variance of ACC z\", \"right Mav of ACC x\", \n",
    "         \"right Mav of ACC y\", \"right Mav of ACC z\", \"right Rms of ACC x\", \"right Rms of ACC y\", \"right Rms of ACC z\", \n",
    "         \"right Sd of ACC x\", \"right Sd of ACC y\", \"right Sd of ACC z\", \"right Mean of ACC x\", \"right Mean of ACC y\", \n",
    "         \"right Mean of ACC z\", \"right Entropy of ACC x\", \"right Entropy of ACC y\", \"right Entropy of ACC z\", \n",
    "         \"right Kurtosis of ACC x\", \"right Kurtosis of ACC y\", \"right Kurtosis of ACC z\", \"right Skewness of ACC x\", \n",
    "         \"right Skewness of ACC y\", \"right Skewness of ACC z\", \"right SMA of ACC\", \"right Integration of ACC x\", \n",
    "         \"right Integration of ACC y\", \"right Integration of ACC z\", \"left variance of EMG1\", \"left variance of EMG2\", \n",
    "         \"left variance of EMG3\", \"left variance of EMG4\", \"left variance of EMG5\", \"left variance of EMG6\", \n",
    "         \"left variance of EMG7\", \"left variance of EMG8\", \"left Mav of EMG1\", \"left Mav of EMG2\", \"left Mav of EMG3\", \n",
    "         \"left Mav of EMG4\", \"left Mav of EMG5\", \"left Mav of EMG6\", \"left Mav of EMG7\", \"left Mav of EMG8\", \"left Rms of EMG1\", \n",
    "         \"left Rms of EMG2\", \"left Rms of EMG3\", \"left Rms of EMG4\", \"left Rms of EMG5\", \"left Rms of EMG6\", \"left Rms of EMG7\", \n",
    "         \"left Rms of EMG8\", \"left Sd of EMG1\", \"left Sd of EMG2\", \"left Sd of EMG3\", \"left Sd of EMG4\", \"left Sd of EMG5\", \n",
    "         \"left Sd of EMG6\", \"left Sd of EMG7\", \"left Sd of EMG8\", \"left Mean of EMG1\", \"left Mean of EMG2\", \"left Mean of EMG3\", \n",
    "         \"left Mean of EMG4\", \"left Mean of EMG5\", \"left Mean of EMG6\", \"left Mean of EMG7\", \"left Mean of EMG8\", \n",
    "         \"left MedianFreq of EMG1\", \"left MedianFreq of EMG2\", \"left MedianFreq of EMG3\", \"left MedianFreq of EMG4\", \n",
    "         \"left MedianFreq of EMG5\", \"left MedianFreq of EMG6\", \"left MedianFreq of EMG7\", \"left MedianFreq of EMG8\", \n",
    "         \"left MeanFreq of EMG1\", \"left MeanFreq of EMG2\", \"left MeanFreq of EMG3\", \"left MeanFreq of EMG4\", \n",
    "         \"left MeanFreq of EMG5\", \"left MeanFreq of EMG6\", \"left MeanFreq of EMG7\", \"left MeanFreq of EMG8\", \n",
    "         \"right variance of EMG1\", \"right variance of EMG2\", \"right variance of EMG3\", \"right variance of EMG4\", \n",
    "         \"right variance of EMG5\", \"right variance of EMG6\", \"right variance of EMG7\", \"right variance of EMG8\", \n",
    "         \"right Mav of EMG1\", \"right Mav of EMG2\", \"right Mav of EMG3\", \"right Mav of EMG4\", \"right Mav of EMG5\", \n",
    "         \"right Mav of EMG6\", \"right Mav of EMG7\", \"right Mav of EMG8\", \"right Rms of EMG1\", \"right Rms of EMG2\", \n",
    "         \"right Rms of EMG3\", \"right Rms of EMG4\", \"right Rms of EMG5\", \"right Rms of EMG6\", \"right Rms of EMG7\", \n",
    "         \"right Rms of EMG8\", \"right Sd of EMG1\", \"right Sd of EMG2\", \"right Sd of EMG3\", \"right Sd of EMG4\", \"right Sd of EMG5\", \n",
    "         \"right Sd of EMG6\", \"right Sd of EMG7\", \"right Sd of EMG8\", \"right Mean of EMG1\", \"right Mean of EMG2\", \n",
    "         \"right Mean of EMG3\", \"right Mean of EMG4\", \"right Mean of EMG5\", \"right Mean of EMG6\", \"right Mean of EMG7\", \n",
    "         \"right Mean of EMG8\", \"right MedianFreq of EMG1\", \"right MedianFreq of EMG2\", \"right MedianFreq of EMG3\", \n",
    "         \"right MedianFreq of EMG4\", \"right MedianFreq of EMG5\", \"right MedianFreq of EMG6\", \"right MedianFreq of EMG7\", \n",
    "         \"right MedianFreq of EMG8\", \"right MeanFreq of EMG1\", \"right MeanFreq of EMG2\", \"right MeanFreq of EMG3\", \n",
    "         \"right MeanFreq of EMG4\", \"right MeanFreq of EMG5\", \"right MeanFreq of EMG6\", \"right MeanFreq of EMG7\", \n",
    "         \"right MeanFreq of EMG8\"]\n",
    "print(len(dfColumns))\n",
    "dfRow = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leftDone computing gyro features!!!!!!!\n",
      "rightDone computing gyro features!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "for a in arms:\n",
    "    \n",
    "    df = dataFrameDictionary['gyro'][a]\n",
    "    x = df.values.astype(float)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "     \n",
    "    \n",
    "    dfRow.append(df_normalized.var()[1])\n",
    "    dfRow.append(df_normalized.var()[2])\n",
    "    dfRow.append(df_normalized.var()[3])\n",
    "    dfRow.append(robust.mad(df_normalized)[1])\n",
    "    dfRow.append(robust.mad(df_normalized)[2])\n",
    "    dfRow.append(robust.mad(df_normalized)[3])\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[1].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[2].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[3].values**2)))\n",
    "    dfRow.append(np.std(df_normalized)[1])\n",
    "    dfRow.append(np.std(df_normalized)[2])\n",
    "    dfRow.append(np.std(df_normalized)[3])\n",
    "    dfRow.append(np.mean(df_normalized)[1])\n",
    "    dfRow.append(np.mean(df_normalized)[2])\n",
    "    dfRow.append(np.mean(df_normalized)[3])\n",
    "    dfRow.append(sp.stats.entropy(df_normalized)[1])\n",
    "    dfRow.append(sp.stats.entropy(df_normalized)[2])\n",
    "    dfRow.append(sp.stats.entropy(df_normalized)[3])\n",
    "    dfRow.append(df_normalized.kurtosis()[1])\n",
    "    dfRow.append(df_normalized.kurtosis()[2])\n",
    "    dfRow.append(df_normalized.kurtosis()[3])\n",
    "    dfRow.append(df_normalized.skew(axis=0)[1])\n",
    "    dfRow.append(df_normalized.skew(axis=0)[2])\n",
    "    dfRow.append(df_normalized.skew(axis=0)[3])\n",
    "    \n",
    "    length = df_normalized.shape[1]\n",
    "    sma = 0\n",
    "    for x in range(0, length):\n",
    "            # .iloc[x,0] is Gyroessing row, column\n",
    "        sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "    sma = sma / length\n",
    "    dfRow.append(sma)\n",
    "    dfRow.append(sp.integrate.simps(df_normalized, axis=0)[1])\n",
    "    dfRow.append(sp.integrate.simps(df_normalized, axis=0)[2])\n",
    "    dfRow.append(sp.integrate.simps(df_normalized, axis=0)[3])\n",
    "    \n",
    "    \n",
    "    print(a +\"Done computing gyro features!!!!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leftDone computing acc features!!!!!!!\n",
      "rightDone computing acc features!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "for a in arms:\n",
    "    df = dataFrameDictionary['acc'][a]\n",
    "\n",
    "    x = df.values.astype(float)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "    \n",
    "    \n",
    "    dfRow.append(df_normalized.var()[1])\n",
    "    dfRow.append(df_normalized.var()[2])\n",
    "    dfRow.append(df_normalized.var()[3])\n",
    "    dfRow.append(robust.mad(df_normalized)[1])\n",
    "    dfRow.append(robust.mad(df_normalized)[2])\n",
    "    dfRow.append(robust.mad(df_normalized)[3])\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[1].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[2].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[3].values**2)))\n",
    "    dfRow.append(np.std(df_normalized)[1])\n",
    "    dfRow.append(np.std(df_normalized)[2])\n",
    "    dfRow.append(np.std(df_normalized)[3])\n",
    "    dfRow.append(np.mean(df_normalized)[1])\n",
    "    dfRow.append(np.mean(df_normalized)[2])\n",
    "    dfRow.append(np.mean(df_normalized)[3])\n",
    "    dfRow.append(sp.stats.entropy(df_normalized)[1])\n",
    "    dfRow.append(sp.stats.entropy(df_normalized)[2])\n",
    "    dfRow.append(sp.stats.entropy(df_normalized)[3])\n",
    "    dfRow.append(df_normalized.kurtosis()[1])\n",
    "    dfRow.append(df_normalized.kurtosis()[2])\n",
    "    dfRow.append(df_normalized.kurtosis()[3])\n",
    "    dfRow.append(df_normalized.skew(axis=0)[1])\n",
    "    dfRow.append(df_normalized.skew(axis=0)[2])\n",
    "    dfRow.append(df_normalized.skew(axis=0)[3])\n",
    "    \n",
    "    length = df_normalized.shape[1]\n",
    "    sma = 0\n",
    "    for x in range(0, length):\n",
    "        sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "    sma = sma / length\n",
    "    dfRow.append(sma)\n",
    "    dfRow.append(sp.integrate.simps(df_normalized, axis=0)[1])\n",
    "    dfRow.append(sp.integrate.simps(df_normalized, axis=0)[2])\n",
    "    dfRow.append(sp.integrate.simps(df_normalized, axis=0)[3])\n",
    "    \n",
    "    print(a +\"Done computing acc features!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering of left emg Done!!\n",
      "Done computing emg features of left arm files\n",
      "Filtering of right emg Done!!\n",
      "Done computing emg features of right arm files\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "for a in arms:\n",
    "    \n",
    "    df = dataFrameDictionary['emg'][a]\n",
    "    \n",
    "    # bandpass filter\n",
    "    for column in df:\n",
    "        if \"time\" not in column:\n",
    "            emg = np.array(df[column].values)\n",
    "\n",
    "            emg_correctmean = emg - np.mean(emg)\n",
    "\n",
    "            # create bandpass filter for EMG\n",
    "            high = 2/(100/2)\n",
    "            low = 45/(100/2)\n",
    "            b, a1 = sp.signal.butter(4, [high,low], btype='bandpass')\n",
    "\n",
    "            emg_filtered = sp.signal.filtfilt(b, a1, emg_correctmean)\n",
    "\n",
    "            emg_rectified = abs(emg_filtered)\n",
    "\n",
    "                # create lowpass filter and apply to rectified signal to get EMG envelope\n",
    "            sfreq = 100\n",
    "            low_pass = 10/sfreq\n",
    "            b2, a2 = sp.signal.butter(4, low_pass, btype='lowpass')\n",
    "            emg_envelope = sp.signal.filtfilt(b2, a2, emg_rectified)\n",
    "\n",
    "            df[column] = emg_envelope\n",
    "    \n",
    "    filteredDf = df\n",
    "    \n",
    "    print(\"Filtering of \" + a + \" emg Done!!\")\n",
    "    \n",
    "   \n",
    "    x = filteredDf.values.astype(float)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "    \n",
    "    dfRow.append(df_normalized.var()[1])\n",
    "    dfRow.append(df_normalized.var()[2])\n",
    "    dfRow.append(df_normalized.var()[3])\n",
    "    dfRow.append(df_normalized.var()[4])\n",
    "    dfRow.append(df_normalized.var()[5])\n",
    "    dfRow.append(df_normalized.var()[6])\n",
    "    dfRow.append(df_normalized.var()[7])\n",
    "    dfRow.append(df_normalized.var()[8])\n",
    "\n",
    "    dfRow.append(robust.mad(df_normalized)[1])\n",
    "    dfRow.append(robust.mad(df_normalized)[2])\n",
    "    dfRow.append(robust.mad(df_normalized)[3])\n",
    "    dfRow.append(robust.mad(df_normalized)[4])\n",
    "    dfRow.append(robust.mad(df_normalized)[5])\n",
    "    dfRow.append(robust.mad(df_normalized)[6])\n",
    "    dfRow.append(robust.mad(df_normalized)[7])\n",
    "    dfRow.append(robust.mad(df_normalized)[8])\n",
    "    \n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[1].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[2].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[3].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[4].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[5].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[6].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[7].values**2)))\n",
    "    dfRow.append(np.sqrt(np.mean(df_normalized[8].values**2)))\n",
    "    \n",
    "    dfRow.append(np.std(df_normalized)[1])\n",
    "    dfRow.append(np.std(df_normalized)[2])\n",
    "    dfRow.append(np.std(df_normalized)[3])\n",
    "    dfRow.append(np.std(df_normalized)[4])\n",
    "    dfRow.append(np.std(df_normalized)[5])\n",
    "    dfRow.append(np.std(df_normalized)[6])\n",
    "    dfRow.append(np.std(df_normalized)[7])\n",
    "    dfRow.append(np.std(df_normalized)[8])\n",
    "    \n",
    "    dfRow.append(np.mean(df_normalized)[1])\n",
    "    dfRow.append(np.mean(df_normalized)[2])\n",
    "    dfRow.append(np.mean(df_normalized)[3])\n",
    "    dfRow.append(np.mean(df_normalized)[4])\n",
    "    dfRow.append(np.mean(df_normalized)[5])\n",
    "    dfRow.append(np.mean(df_normalized)[6])\n",
    "    dfRow.append(np.mean(df_normalized)[7])\n",
    "    dfRow.append(np.mean(df_normalized)[8])\n",
    "    \n",
    "    meanFreq = []\n",
    "    medFreq = []\n",
    "\n",
    "    for i in range(1, 9):\n",
    "        data = df_normalized[i].values\n",
    "        ps = np.abs(np.fft.fft(data))**2\n",
    "\n",
    "        freqs = np.fft.fftfreq(data.size, 1/100)\n",
    "\n",
    "        sumProd = 0\n",
    "        sumPs = 0\n",
    "\n",
    "        for f, p in zip(freqs,ps):\n",
    "            sumProd += f*p\n",
    "            sumPs += p\n",
    "\n",
    "        sumProd = sumProd * 100000000\n",
    "        meanFreq.append(100000000*sumProd/sumPs)\n",
    "        medFreq.append(sumPs/2)\n",
    "\n",
    "    dfRow.append(medFreq[0])\n",
    "    dfRow.append(medFreq[1])\n",
    "    dfRow.append(medFreq[2])\n",
    "    dfRow.append(medFreq[3])\n",
    "    dfRow.append(medFreq[4])\n",
    "    dfRow.append(medFreq[5])\n",
    "    dfRow.append(medFreq[6])\n",
    "    dfRow.append(medFreq[7])\n",
    "    \n",
    "    dfRow.append(meanFreq[0])\n",
    "    dfRow.append(meanFreq[1])\n",
    "    dfRow.append(meanFreq[2])\n",
    "    dfRow.append(meanFreq[3])\n",
    "    dfRow.append(meanFreq[4])\n",
    "    dfRow.append(meanFreq[5])\n",
    "    dfRow.append(meanFreq[6])\n",
    "    dfRow.append(meanFreq[7])\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"Done computing emg features of \" + a + \" arm files\")\n",
    "print(len(dfRow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "print(len(dfRow))\n",
    "\n",
    "consolidatedFeatures = pd.DataFrame(columns = dfColumns)\n",
    "\n",
    "consolidatedFeatures.loc[i] = dfRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   left Variance of Gyro x  left Variance of Gyro y  left Variance of Gyro z  \\\n",
      "8                  0.04246                  0.17587                  0.07046   \n",
      "\n",
      "   left Mav of Gyro x  left Mav of Gyro y  left Mav of Gyro z  \\\n",
      "8            0.164027            0.102912            0.124831   \n",
      "\n",
      "   left Rms of Gyro x  left Rms of Gyro y  left Rms of Gyro z  \\\n",
      "8            0.407341            0.565127            0.420781   \n",
      "\n",
      "   left Sd of Gyro x           ...            right MedianFreq of EMG7  \\\n",
      "8           0.205343           ...                        14175.320951   \n",
      "\n",
      "   right MedianFreq of EMG8  right MeanFreq of EMG1  right MeanFreq of EMG2  \\\n",
      "8               9780.331992               -0.512295               -1.952392   \n",
      "\n",
      "   right MeanFreq of EMG3  right MeanFreq of EMG4  right MeanFreq of EMG5  \\\n",
      "8               -0.564021               11.096948                5.409055   \n",
      "\n",
      "   right MeanFreq of EMG6  right MeanFreq of EMG7  right MeanFreq of EMG8  \n",
      "8                3.841973               -1.323309               -3.559858  \n",
      "\n",
      "[1 rows x 224 columns]\n"
     ]
    }
   ],
   "source": [
    "print(consolidatedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileLocation = \"WithEmgFilter-NoNormalization.csv\"\n",
    "df = pd.read_csv(fileLocation)\n",
    "\n",
    "for f in df:\n",
    "    if(f != \"Class\"):\n",
    "        mini = min(df[f])\n",
    "        maxi = max(df[f])\n",
    "        \n",
    "        norm = (consolidatedFeatures[f].iloc[0]-mini) / (maxi - mini) \n",
    "        consolidatedFeatures.set_value(8, f, norm)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   left Variance of Gyro x  left Variance of Gyro y  left Variance of Gyro z  \\\n",
      "8                 0.190514                 0.808835                 0.261105   \n",
      "\n",
      "   left Mav of Gyro x  left Mav of Gyro y  left Mav of Gyro z  \\\n",
      "8            0.242007            0.144369            0.169686   \n",
      "\n",
      "   left Rms of Gyro x  left Rms of Gyro y  left Rms of Gyro z  \\\n",
      "8            0.310967            0.452335            0.355651   \n",
      "\n",
      "   left Sd of Gyro x           ...            right MedianFreq of EMG7  \\\n",
      "8           0.346078           ...                            0.197753   \n",
      "\n",
      "   right MedianFreq of EMG8  right MeanFreq of EMG1  right MeanFreq of EMG2  \\\n",
      "8                  0.093531                     1.0                     1.0   \n",
      "\n",
      "   right MeanFreq of EMG3  right MeanFreq of EMG4  right MeanFreq of EMG5  \\\n",
      "8                     1.0                     1.0                     1.0   \n",
      "\n",
      "   right MeanFreq of EMG6  right MeanFreq of EMG7  right MeanFreq of EMG8  \n",
      "8                     1.0                     1.0                     1.0  \n",
      "\n",
      "[1 rows x 224 columns]\n"
     ]
    }
   ],
   "source": [
    "print(consolidatedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spaghetti']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "fileLocation = \"WithEmgFilter.csv\"\n",
    "df = pd.read_csv(fileLocation)\n",
    "\n",
    "data = df.drop('Class', axis=1)  \n",
    "classes = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, classes, test_size = 1)\n",
    "\n",
    "# print(X_test.columns)\n",
    "# print(consolidatedFeatures.columns)\n",
    "    \n",
    "# print(y_test)\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(data, classes)  \n",
    "\n",
    "y_pred = clf.predict(consolidatedFeatures)  \n",
    "\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
