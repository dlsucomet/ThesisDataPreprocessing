{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done listing the class and file names\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "listOfFileNames = []\n",
    "listOfClassNames = []\n",
    "listOfDataPerClass = []\n",
    "\n",
    "files = []\n",
    "classNames = []\n",
    "#path = \"/Users/user/Desktop/asd/thesis/placeholder/\"\n",
    "#path = \"/Users/user/Desktop/pinakalatest/thesis/placeholder/\"\n",
    "path = \"trimmed_data_updated/\"\n",
    "classNames = glob.glob(path + \"*\")\n",
    "#onewords = [\"ano\",\"asul\",\"ate\",\"baboy\",\"dalawa\",\"dito\",\"hello\",\"isa\",\"isda\",\"itim\",\"ito\",\"kanin\",\"kayo\",\"ko\",\"kulay\",\"kuya\",\"large (shirt)\",\"magkano\",\"manok\",\"mantika\",\"medium (shirt)\",\"nito\",\"niyo\",\"pagkain\",\"pula\",\"salamat\",\"small (shirt)\",\"softdrinks\",\"sorry\",\"tatlo\",\"tubig\"]\n",
    "\n",
    "for c in classNames:\n",
    "    className = c.split(\"\\\\\")[1]\n",
    "    listOfClassNames.append(c.split(\"\\\\\")[1])\n",
    "    files = glob.glob(path + className+\"/*\") \n",
    "    listOfFileNames = []\n",
    "    #if className in onewords:\n",
    "        \n",
    "    for f in files:\n",
    "        checker = False\n",
    "\n",
    "        fileLocation = f.split(\"\\\\\")[1]\n",
    "\n",
    "\n",
    "        if checker is False:\n",
    "            listOfFileNames.append(fileLocation)\n",
    "\n",
    "    listOfDataPerClass.append(listOfFileNames)\n",
    "\n",
    "    \n",
    "#listOfClassNames\n",
    "#listOfDataPerClass[0]\n",
    "\n",
    "print(\"Done listing the class and file names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word ano-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word asul-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word ate-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word baboy-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word binebenta-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word dalawa-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word dito-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word extra-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word gulay-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word gusto-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word hello-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word isa-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word isda-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word itim-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word itlog-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word ito-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word juice-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kanin-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kape-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kayo-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kilo-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word ko-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kulay-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word kuya-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word large (shirt)-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word magkano-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word mahal-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word malaki-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word maliit-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word manok-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word mantika-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word mayroon-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word medium (shirt)-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word nagbubukas-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word nagsasara-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word nito-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word niyo-----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word oras-----------------\n",
      "Total of 99 left arm emg files and 99 right arm emg files.\n",
      "Total of 99 left arm acc files and 99 right arm acc files.\n",
      "Total of 99 left arm gyro files and 99 right arm gyro files.\n",
      "----------------- Word pabili-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word pagkain-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word poloshirt-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word pula-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word puwede-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word saging-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word salamat-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word sari-sari store-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word shorts-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word size-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word small (shirt)-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word softdrinks-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word sorry-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word spaghetti-----------------\n",
      "Total of 99 left arm emg files and 99 right arm emg files.\n",
      "Total of 99 left arm acc files and 99 right arm acc files.\n",
      "Total of 99 left arm gyro files and 99 right arm gyro files.\n",
      "----------------- Word supot-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word t-shirt-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word tatlo-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word tawad-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word tinapay-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word tubig-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word utang-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "----------------- Word wala-----------------\n",
      "Total of 100 left arm emg files and 100 right arm emg files.\n",
      "Total of 100 left arm acc files and 100 right arm acc files.\n",
      "Total of 100 left arm gyro files and 100 right arm gyro files.\n",
      "Done converting to dataframes!\n"
     ]
    }
   ],
   "source": [
    "#len(listOfDataPerClass)\n",
    "#listOfDataPerClass[3]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "listOfDataFramesPerClass = {}\n",
    "dataFrameDictionary = {}\n",
    "dataFrames = []\n",
    "\n",
    "\n",
    "for c, d in zip(listOfClassNames, listOfDataPerClass):\n",
    "    \n",
    "    print(\"----------------- Word \" + c + \"-----------------\")\n",
    "    emgDataFrames = {}\n",
    "    emgDataFrames['right'] = []\n",
    "    emgDataFrames['left'] = []\n",
    "\n",
    "    accDataFrames = {}\n",
    "    accDataFrames['right'] = []\n",
    "    accDataFrames['left'] = []\n",
    "\n",
    "    gyroDataFrames = {}\n",
    "    gyroDataFrames['right'] = []\n",
    "    gyroDataFrames['left'] = []\n",
    "\n",
    "    dataFrameDictionary = {}\n",
    "    className = c\n",
    "    emgleftctr = 0\n",
    "    emgrightctr = 0\n",
    "    accleftctr = 0\n",
    "    accrightctr = 0\n",
    "    gyroleftctr = 0\n",
    "    gyrorightctr = 0\n",
    "\n",
    "    for fileName in d:\n",
    "        checker = False\n",
    "        fileLocation = path + className + \"/\" + fileName + \"\"\n",
    "        #print(fileLocation)\n",
    "        df = pd.read_csv(fileLocation)\n",
    "\n",
    "\n",
    "        if \"emg\" in fileName:   \n",
    "            if \"-Right\" in fileName:\n",
    "                emgDataFrames['right'].append(df)\n",
    "                emgrightctr+=1\n",
    "            else:\n",
    "                emgDataFrames['left'].append(df)\n",
    "                emgleftctr+=1\n",
    "        elif (\"acc\") in fileName:\n",
    "            if \"-Right\" in fileName:\n",
    "                accDataFrames['right'].append(df)\n",
    "                accrightctr+=1\n",
    "            else:\n",
    "                accDataFrames['left'].append(df)\n",
    "                accleftctr+=1\n",
    "        elif (\"gyro\") in fileName:\n",
    "            if \"-Right\" in fileName:\n",
    "                gyroDataFrames['right'].append(df)\n",
    "                gyrorightctr+=1\n",
    "            else:\n",
    "                gyroDataFrames['left'].append(df)\n",
    "                gyroleftctr+=1\n",
    "\n",
    "    dataFrameDictionary[\"emg\"] = emgDataFrames\n",
    "    dataFrameDictionary[\"acc\"] = accDataFrames\n",
    "    dataFrameDictionary[\"gyro\"] = gyroDataFrames\n",
    "\n",
    "    listOfDataFramesPerClass[className] = dataFrameDictionary\n",
    "    print(\"Total of \" + str(emgleftctr) + \" left arm emg files and \" + str(emgrightctr) + \" right arm emg files.\")\n",
    "    print(\"Total of \" + str(accleftctr) + \" left arm acc files and \" + str(accrightctr) + \" right arm acc files.\")\n",
    "    print(\"Total of \" + str(gyroleftctr) + \" left arm gyro files and \" + str(gyrorightctr) + \" right arm gyro files.\")\n",
    "\n",
    "\n",
    "print(\"Done converting to dataframes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# emgDataFrames = {}\n",
    "# emgDataFrames['right'] = []\n",
    "# emgDataFrames['left'] = []\n",
    "    \n",
    "# accDataFrames = {}\n",
    "# accDataFrames['right'] = []\n",
    "# accDataFrames['left'] = []\n",
    "\n",
    "# gyroDataFrames = {}\n",
    "# gyroDataFrames['right'] = []\n",
    "# gyroDataFrames['left'] = []\n",
    "\n",
    "# dataFrameDictionary = {}\n",
    "# className = c\n",
    "# emgleftctr = 0\n",
    "# emgrightctr = 0\n",
    "# accleftctr = 0\n",
    "# accrightctr = 0\n",
    "# gyroleftctr = 0\n",
    "# gyrorightctr = 0\n",
    "    \n",
    "# className = \"binebenta\"\n",
    "# d = listOfDataPerClass[43]\n",
    "# for fileName in d:\n",
    "#     checker = False\n",
    "#     fileLocation = path + className + \"/\" + fileName + \"\"\n",
    "#     #print(fileLocation)\n",
    "#     df = pd.read_csv(fileLocation)\n",
    "        \n",
    "        \n",
    "#     if \"emg\" in fileName:   \n",
    "#         if \"-Right\" in fileName:\n",
    "#             emgDataFrames['right'].append(df)\n",
    "#             emgrightctr+=1\n",
    "#         else:\n",
    "#             emgDataFrames['left'].append(df)\n",
    "#             emgleftctr+=1\n",
    "#     elif (\"acc\") in fileName:\n",
    "#         if \"-Right\" in fileName:\n",
    "#             accDataFrames['right'].append(df)\n",
    "#             accrightctr+=1\n",
    "#         else:\n",
    "#             accDataFrames['left'].append(df)\n",
    "#             accleftctr+=1\n",
    "#     elif (\"gyro\") in fileName:\n",
    "#         if \"-Right\" in fileName:\n",
    "#             gyroDataFrames['right'].append(df)\n",
    "#             gyrorightctr+=1\n",
    "#         else:\n",
    "#             gyroDataFrames['left'].append(df)\n",
    "#             gyroleftctr+=1\n",
    "    \n",
    "# dataFrameDictionary[\"emg\"] = emgDataFrames\n",
    "# dataFrameDictionary[\"acc\"] = accDataFrames\n",
    "# dataFrameDictionary[\"gyro\"] = gyroDataFrames\n",
    "\n",
    "# listOfDataFramesPerClass[className] = dataFrameDictionary\n",
    "# print(\"Total of \" + str(emgleftctr) + \" left arm emg files and \" + str(emgrightctr) + \" right arm emg files.\")\n",
    "# print(\"Total of \" + str(accleftctr) + \" left arm acc files and \" + str(accrightctr) + \" right arm acc files.\")\n",
    "# print(\"Total of \" + str(gyroleftctr) + \" left arm gyro files and \" + str(gyrorightctr) + \" right arm gyro files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For EMG Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band Pass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    for a in listOfDataFramesPerClass[k]['emg']:\n",
    "        print(k)\n",
    "        ctr = 0\n",
    "        for d in listOfDataFramesPerClass[k]['emg'][a]:\n",
    "            for r in d:\n",
    "                if \"time\" not in r:\n",
    "                    emg = np.array(d[r].values)\n",
    "\n",
    "                    emg_correctmean = emg - np.mean(emg)\n",
    "\n",
    "                    # create bandpass filter for EMG\n",
    "                    high = 2/(100/2)\n",
    "                    low = 45/(100/2)\n",
    "                    b, a = sp.signal.butter(4, [high,low], btype='bandpass')\n",
    "\n",
    "                    emg_filtered = sp.signal.filtfilt(b, a, emg_correctmean)\n",
    "\n",
    "                    emg_rectified = abs(emg_filtered)\n",
    "\n",
    "\n",
    "\n",
    "                    # create lowpass filter and apply to rectified signal to get EMG envelope\n",
    "                    sfreq = 100\n",
    "                    low_pass = 10/sfreq\n",
    "                    b2, a2 = sp.signal.butter(4, low_pass, btype='lowpass')\n",
    "                    emg_envelope = sp.signal.filtfilt(b2, a2, emg_rectified)\n",
    "\n",
    "                    d[r] = emg_envelope\n",
    "            ctr +=1\n",
    "        print(ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "listOfNormalizedDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    \n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        for d in listOfDataFramesPerClass[k]['emg'][a]:\n",
    "\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            \n",
    "          \n",
    "            ctr += 1\n",
    "\n",
    "        print(\"Done Normalizing \" + str(ctr) + a + \" arm files\")\n",
    "    dataFrameDictionary[\"emg\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfNormalizedDataFramesPerClass = listOfDataFramesPerClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Word ano-----------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2442\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-93303c2d9e82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mmeanDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mctr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0msdDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mctr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mrmsDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mctr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mctr\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2442\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2444\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "\n",
    "listOfVarianceDataFramePerClass = {}\n",
    "listOfVarianceDataFramePerClass['right'] = []\n",
    "listOfVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMavDataFramePerClass = {}\n",
    "listOfMavDataFramePerClass['right'] = []\n",
    "listOfMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMeanDataFramePerClass = {}\n",
    "listOfMeanDataFramePerClass['right'] = []\n",
    "listOfMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfSdDataFramePerClass = {}\n",
    "listOfSdDataFramePerClass['right'] = []\n",
    "listOfSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfRmsDataFramePerClass = {}\n",
    "listOfRmsDataFramePerClass['right'] = []\n",
    "listOfRmsDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "\n",
    "    for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm + 'variance of EMG1'), (arm + 'variance of EMG2'), (arm + 'variance of EMG3'), (arm + 'variance of EMG4'),\n",
    "                                 (arm + 'variance of EMG5'), (arm + 'variance of EMG6'), (arm + 'variance of EMG7'), (arm + 'variance of EMG8')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm + 'Mav of EMG1'), (arm + 'Mav of EMG2'), (arm + 'Mav of EMG3'), (arm + 'Mav of EMG4'),\n",
    "                                     (arm + 'Mav of EMG5'), (arm + 'Mav of EMG6'), (arm + 'Mav of EMG7'), (arm + 'Mav of EMG8')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm + 'Mean of EMG1'), (arm + 'Mean of EMG2'), (arm + 'Mean of EMG3'), (arm + 'Mean of EMG4'),\n",
    "                                     (arm + 'Mean of EMG5'), (arm + 'Mean of EMG6'), (arm + 'Mean of EMG7'), (arm + 'Mean of EMG8')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm + 'Sd of EMG1'), (arm + 'Sd of EMG2'), (arm + 'Sd of EMG3'), (arm + 'Sd of EMG4'),\n",
    "                                     (arm + 'Sd of EMG5'), (arm + 'Sd of EMG6'), (arm + 'Sd of EMG7'), (arm + 'Sd of EMG8')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm + 'Rms of EMG1'), (arm + 'Rms of EMG2'), (arm + 'Rms of EMG3'), (arm + 'Rms of EMG4'),\n",
    "                                     (arm + 'Rms of EMG5'), (arm + 'Rms of EMG6'), (arm + 'Rms of EMG7'), (arm + 'Rms of EMG8')])\n",
    "        for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg'][a]:\n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3], df_normalized.var()[4], df_normalized.var()[5], df_normalized.var()[6], df_normalized.var()[7], df_normalized.var()[8]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3], robust.mad(df_normalized)[4], robust.mad(df_normalized)[5], robust.mad(df_normalized)[6], robust.mad(df_normalized)[7], robust.mad(df_normalized)[8]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3], np.mean(df_normalized)[4], np.mean(df_normalized)[5], np.mean(df_normalized)[6], np.mean(df_normalized)[7], np.mean(df_normalized)[8]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3], np.std(df_normalized)[4], np.std(df_normalized)[5], np.std(df_normalized)[6], np.std(df_normalized)[7], np.std(df_normalized)[8]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2)), np.sqrt(np.mean(df_normalized[4].values**2)), np.sqrt(np.mean(df_normalized[5].values**2)), np.sqrt(np.mean(df_normalized[6].values**2)),  np.sqrt(np.mean(df_normalized[7].values**2)), np.sqrt(np.mean(df_normalized[8].values**2))]\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "    \n",
    "        print(\"Done computing the var, mav, mean , sd, and rms of \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing emg features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and Median Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "listOfMeanFreqDataFramePerClass = {}\n",
    "listOfMeanFreqDataFramePerClass['right'] = []\n",
    "listOfMeanFreqDataFramePerClass['left'] = []\n",
    "\n",
    "listOfMedFreqDataFramePerClass = {}\n",
    "listOfMedFreqDataFramePerClass['right'] = []\n",
    "listOfMedFreqDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    \n",
    "    for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        meanFreqDataFrame = pd.DataFrame(columns = [(arm + 'MeanFreq of EMG1'), (arm + 'MeanFreq of EMG2'), (arm + 'MeanFreq of EMG3'), (arm + 'MeanFreq of EMG4'),\n",
    "                                 (arm + 'MeanFreq of EMG5'), (arm + 'MeanFreq of EMG6'), (arm + 'MeanFreq of EMG7'), (arm + 'MeanFreq of EMG8')]) \n",
    "\n",
    "        medFreqDataFrame = pd.DataFrame(columns = [(arm + 'MedianFreq of EMG1'), (arm + 'MedianFreq of EMG2'), (arm + 'MedianFreq of EMG3'), (arm + 'MedianFreq of EMG4'),\n",
    "                                     (arm + 'MedianFreq of EMG5'), (arm + 'MedianFreq of EMG6'), (arm + 'MedianFreq of EMG7'), (arm + 'MedianFreq of EMG8')])\n",
    "\n",
    "        for df_normalized in listOfNormalizedDataFramesPerClass[k]['emg'][a]:\n",
    "            meanFreq = []\n",
    "            medFreq = []\n",
    "\n",
    "            for i in range(1, 9):\n",
    "                data = df_normalized[i].values\n",
    "                ps = np.abs(np.fft.fft(data))**2\n",
    "\n",
    "                freqs = np.fft.fftfreq(data.size, 1/100)\n",
    "\n",
    "                sumProd = 0\n",
    "                sumPs = 0\n",
    "\n",
    "                for f, p in zip(freqs,ps):\n",
    "                    sumProd += f*p\n",
    "                    sumPs += p\n",
    "                \n",
    "                sumProd = sumProd * 100000000\n",
    "                meanFreq.append(100000000*sumProd/sumPs)\n",
    "                medFreq.append(sumPs/2)\n",
    "                \n",
    "            \n",
    "            meanFreqDataFrame.loc[ctr] = [meanFreq[0], meanFreq[1], meanFreq[2], meanFreq[3], meanFreq[4], meanFreq[5], meanFreq[6], meanFreq[7]]\n",
    "            medFreqDataFrame.loc[ctr] = [medFreq[0], medFreq[1], medFreq[2], medFreq[3], medFreq[4], medFreq[5], medFreq[6], medFreq[7]]\n",
    "\n",
    "            ctr+=1\n",
    "        listOfMeanFreqDataFramePerClass[a].append(meanFreqDataFrame)\n",
    "        listOfMedFreqDataFramePerClass[a].append(medFreqDataFrame)\n",
    "        print(\"Done computing Mean and Median Frequency of \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing emg features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAMP, WL, ZC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# listOfWAMPDataFramePerClass = {}\n",
    "# listOfWAMPDataFramePerClass['right'] = []\n",
    "# listOfWAMPDataFramePerClass['left'] = []\n",
    "\n",
    "# listOfWLDataFramePerClass = {}\n",
    "# listOfWLDataFramePerClass['right'] = []\n",
    "# listOfWLDataFramePerClass['left'] = []\n",
    "\n",
    "# listOfZCDataFramePerClass = {}\n",
    "# listOfZCDataFramePerClass['right'] = []\n",
    "# listOfZCDataFramePerClass['left'] = []\n",
    "\n",
    "# for k in listOfNormalizedDataFramesPerClass.keys():\n",
    "#     print(\"----------------- Word \" + k + \"-----------------\")\n",
    "#     ctr = 0\n",
    "    \n",
    "    \n",
    "#     for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "#         ctr = 0\n",
    "#         arm = a + \" \"\n",
    "\n",
    "#         wampDataFrame = pd.DataFrame(columns = [(arm + 'WAMP of EMG1'), (arm + 'WAMP of EMG2'), (arm + 'WAMP of EMG3'), (arm + 'WAMP of EMG4'),\n",
    "#                                  (arm + 'WAMP of EMG5'), (arm + 'WAMP of EMG6'), (arm + 'WAMP of EMG7'), (arm + 'WAMP of EMG8')]) \n",
    "\n",
    "#         wlFreqDataFrame = pd.DataFrame(columns = [(arm + 'WL of EMG1'), (arm + 'WL of EMG2'), (arm + 'WL of EMG3'), (arm + 'WL of EMG4'),\n",
    "#                                      (arm + 'WL of EMG5'), (arm + 'WL of EMG6'), (arm + 'WL of EMG7'), (arm + 'WL of EMG8')])\n",
    "        \n",
    "#         zcFreqDataFrame = pd.DataFrame(columns = [(arm + 'ZC of EMG1'), (arm + 'ZC of EMG2'), (arm + 'ZC of EMG3'), (arm + 'ZC of EMG4'),\n",
    "#                                      (arm + 'ZC of EMG5'), (arm + 'ZC of EMG6'), (arm + 'ZC of EMG7'), (arm + 'ZC of EMG8')])\n",
    "\n",
    "       \n",
    "#             meanFreqDataFrame.loc[ctr] = [meanFreq[0], meanFreq[1], meanFreq[2], meanFreq[3], meanFreq[4], meanFreq[5], meanFreq[6], meanFreq[7]]\n",
    "#             medFreqDataFrame.loc[ctr] = [medFreq[0], medFreq[1], medFreq[2], medFreq[3], medFreq[4], medFreq[5], medFreq[6], medFreq[7]]\n",
    "\n",
    "#             ctr+=1\n",
    "#         listOfMeanFreqDataFramePerClass[a].append(meanFreqDataFrame)\n",
    "#         listOfMedFreqDataFramePerClass[a].append(medFreqDataFrame)\n",
    "#         print(\"Done computing Mean and Median Frequency of \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "# print(\"Done computing emg features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "\n",
    "listOfLabeledDataPerClass = {}\n",
    "listOfLabeledDataPerClass['right'] = {}\n",
    "listOfLabeledDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfNormalizedDataFramesPerClass[k]['emg']:\n",
    "\n",
    "    dataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        dataFramesPerFeature['variance'] = listOfVarianceDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['mav'] = listOfMavDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['rms'] = listOfRmsDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['sd'] = listOfSdDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['mean'] = listOfMeanDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['medFreq'] = listOfMedFreqDataFramePerClass[a][ctr]\n",
    "        dataFramesPerFeature['meanFreq'] = listOfMeanFreqDataFramePerClass[a][ctr]\n",
    "    \n",
    "\n",
    "        for k2 in dataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in dataFramesPerFeature[k2].columns:\n",
    "                    dataFramesPerFeature['variance'][i] = dataFramesPerFeature[k2][i]\n",
    "        \n",
    "        dataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledDataPerClass[a][k] = dataFramesPerFeature['variance']\n",
    "        print(\"Done labeling emg data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For IMU values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization (For Acceleration and Gyroscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedAccDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['acc']:\n",
    "        for d in listOfDataFramesPerClass[k]['acc'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"acc\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedAccDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Acc Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "listOfNormalizedGyroDataFramesPerClass = {}\n",
    "\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    NormalizedDataFramesPerClass = {}\n",
    "    NormalizedDataFramesPerClass['left'] = []\n",
    "    NormalizedDataFramesPerClass['right'] = []\n",
    "    dataFrameDictionary = {}\n",
    "\n",
    "    for a in listOfDataFramesPerClass[k]['gyro']:\n",
    "        for d in listOfDataFramesPerClass[k]['gyro'][a]:\n",
    "            #print(str(len(d.index)) + \" \" + str(ctr))\n",
    "            # Create x, where x the 'scores' column's values as floats\n",
    "           \n",
    "            x = d.values.astype(float)\n",
    "\n",
    "            # Create a minimum and maximum processor object\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            # Create an object to transform the data to fit minmax processor\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            # Run the normalizer on the dataframe\n",
    "            df_normalized = pd.DataFrame(x_scaled)\n",
    "            #df_normalized\n",
    "            NormalizedDataFramesPerClass[a].append(df_normalized)\n",
    "            ctr += 1\n",
    "        \n",
    "    print(\"Done Normalizing \" + str(ctr) + \" files\")\n",
    "    dataFrameDictionary[\"gyro\"] = NormalizedDataFramesPerClass\n",
    "    listOfNormalizedGyroDataFramesPerClass[k] = dataFrameDictionary  \n",
    "    \n",
    "print(\"Gyro Data Normalization done!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "#kurtosis\n",
    "#standarddev\n",
    "#mean\n",
    "#variance\n",
    "#entropy\n",
    "#meanabsval\n",
    "#rootmeansquare\n",
    "#Signal Magnitude Area\n",
    "#Integration\n",
    "\n",
    "listOfAccVarianceDataFramePerClass = {}\n",
    "listOfAccVarianceDataFramePerClass['right'] = []\n",
    "listOfAccVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccMavDataFramePerClass = {}\n",
    "listOfAccMavDataFramePerClass['right'] = []\n",
    "listOfAccMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccMeanDataFramePerClass = {}\n",
    "listOfAccMeanDataFramePerClass['right'] = []\n",
    "listOfAccMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccSdDataFramePerClass = {}\n",
    "listOfAccSdDataFramePerClass['right'] = []\n",
    "listOfAccSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccRmsDataFramePerClass = {}\n",
    "listOfAccRmsDataFramePerClass['right'] = []\n",
    "listOfAccRmsDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccEntropyDataFramePerClass = {}\n",
    "listOfAccEntropyDataFramePerClass['right'] = []\n",
    "listOfAccEntropyDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccKurtosisDataFramePerClass = {}\n",
    "listOfAccKurtosisDataFramePerClass['right'] = []\n",
    "listOfAccKurtosisDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccSkewnessDataFramePerClass = {}\n",
    "listOfAccSkewnessDataFramePerClass['right'] = []\n",
    "listOfAccSkewnessDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccSmaDataFramePerClass = {}\n",
    "listOfAccSmaDataFramePerClass['right'] = []\n",
    "listOfAccSmaDataFramePerClass['left'] = []\n",
    "\n",
    "listOfAccIntegrationDataFramePerClass = {}\n",
    "listOfAccIntegrationDataFramePerClass['right'] = []\n",
    "listOfAccIntegrationDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedAccDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm+ 'Variance of ACC x'), (arm+ 'Variance of ACC y'), (arm+ 'Variance of ACC z')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm + 'Mav of ACC x'), (arm + 'Mav of ACC y'), (arm + 'Mav of ACC z')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm + 'Mean of ACC x'), (arm + 'Mean of ACC y'), (arm + 'Mean of ACC z')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm + 'Sd of ACC x'), (arm + 'Sd of ACC y'), (arm + 'Sd of ACC z')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm + 'Rms of ACC x'), (arm + 'Rms of ACC y'), (arm + 'Rms of ACC z')])\n",
    "        entropyDataFrame = pd.DataFrame(columns = [(arm + 'Entropy of ACC x'), (arm + 'Entropy of ACC y'), (arm + 'Entropy of ACC z')])\n",
    "        kurtosisDataFrame = pd.DataFrame(columns = [(arm + 'Kurtosis of ACC x'), (arm + 'Kurtosis of ACC y'), (arm + 'Kurtosis of ACC z')])\n",
    "        skewnessDataFrame = pd.DataFrame(columns = [(arm + 'Skewness of ACC x'), (arm + 'Skewness of ACC y'), (arm + 'Skewness of ACC z')])\n",
    "        smaDataFrame = pd.DataFrame(columns = [(arm + 'SMA of ACC')])\n",
    "        integrationDataFrame = pd.DataFrame(columns = [(arm + 'Integration of ACC x'), (arm + 'Integration of ACC y'), (arm + 'Integration of ACC z')])\n",
    "\n",
    "        \n",
    "        for df_normalized in listOfNormalizedAccDataFramesPerClass[k]['acc'][a]:\n",
    "            \n",
    "#             print(\"df_normalized\")\n",
    "#             time.sleep(5.5) \n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2))]\n",
    "            entropyDataFrame.loc[ctr] = [sp.stats.entropy(df_normalized)[1], sp.stats.entropy(df_normalized)[2], sp.stats.entropy(df_normalized)[3]]\n",
    "            kurtosisDataFrame.loc[ctr] = [df_normalized.kurtosis()[1], df_normalized.kurtosis()[2], df_normalized.kurtosis()[3]]\n",
    "            skewnessDataFrame.loc[ctr] = [df_normalized.skew(axis=0)[1], df_normalized.skew(axis=0)[2], df_normalized.skew(axis=0)[3]]\n",
    "            length = df_normalized.shape[1]\n",
    "            sma = 0\n",
    "            for x in range(0, length):\n",
    "                # .iloc[x,0] is accessing row, column\n",
    "                sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "            sma = sma / length\n",
    "            smaDataFrame.loc[ctr] = [sma]\n",
    "            integrationDataFrame.loc[ctr] = [sp.integrate.simps(df_normalized, axis=0)[1],sp.integrate.simps(df_normalized, axis=0)[2], sp.integrate.simps(df_normalized, axis=0)[3]]\n",
    "\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfAccVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfAccMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfAccMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfAccSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfAccRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "        listOfAccEntropyDataFramePerClass[a].append(entropyDataFrame) \n",
    "        listOfAccKurtosisDataFramePerClass[a].append(kurtosisDataFrame) \n",
    "        listOfAccSkewnessDataFramePerClass[a].append(skewnessDataFrame) \n",
    "        listOfAccSmaDataFramePerClass[a].append(smaDataFrame) \n",
    "        listOfAccIntegrationDataFramePerClass[a].append(integrationDataFrame) \n",
    "        \n",
    "        print(\"Done computing acc features \" + str(ctr) + a + \" arm files\")\n",
    "\n",
    "print(\"Done computing acc features!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "#kurtosis\n",
    "#standarddev\n",
    "#mean\n",
    "#variance\n",
    "#entropy\n",
    "#meanabsval\n",
    "#rootmeansquare\n",
    "#Signal Magnitude Area\n",
    "#Integration\n",
    "\n",
    "listOfGyroVarianceDataFramePerClass = {}\n",
    "listOfGyroVarianceDataFramePerClass['right'] = []\n",
    "listOfGyroVarianceDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroMavDataFramePerClass = {}\n",
    "listOfGyroMavDataFramePerClass['right'] = []\n",
    "listOfGyroMavDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroMeanDataFramePerClass = {}\n",
    "listOfGyroMeanDataFramePerClass['right'] = []\n",
    "listOfGyroMeanDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSdDataFramePerClass = {}\n",
    "listOfGyroSdDataFramePerClass['right'] = []\n",
    "listOfGyroSdDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroRmsDataFramePerClass = {}\n",
    "listOfGyroRmsDataFramePerClass['right'] = []\n",
    "listOfGyroRmsDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroEntropyDataFramePerClass = {}\n",
    "listOfGyroEntropyDataFramePerClass['right'] = []\n",
    "listOfGyroEntropyDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroKurtosisDataFramePerClass = {}\n",
    "listOfGyroKurtosisDataFramePerClass['right'] = []\n",
    "listOfGyroKurtosisDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSkewnessDataFramePerClass = {}\n",
    "listOfGyroSkewnessDataFramePerClass['right'] = []\n",
    "listOfGyroSkewnessDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroSmaDataFramePerClass = {}\n",
    "listOfGyroSmaDataFramePerClass['right'] = []\n",
    "listOfGyroSmaDataFramePerClass['left'] = []\n",
    "\n",
    "listOfGyroIntegrationDataFramePerClass = {}\n",
    "listOfGyroIntegrationDataFramePerClass['right'] = []\n",
    "listOfGyroIntegrationDataFramePerClass['left'] = []\n",
    "\n",
    "for k in listOfNormalizedGyroDataFramesPerClass.keys():\n",
    "    print(\"----------------- Word \" + k + \"-----------------\")\n",
    "    ctr = 0\n",
    "    \n",
    "    for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "        ctr = 0\n",
    "        arm = a + \" \"\n",
    "        varianceDataFrame = pd.DataFrame(columns = [(arm + 'Variance of Gyro x'), (arm+ 'Variance of Gyro y'), (arm+ 'Variance of Gyro z')])\n",
    "        mavDataFrame = pd.DataFrame(columns = [(arm+ 'Mav of Gyro x'), (arm+ 'Mav of Gyro y'), (arm+ 'Mav of Gyro z')])\n",
    "        meanDataFrame = pd.DataFrame(columns = [(arm+ 'Mean of Gyro x'), (arm+ 'Mean of Gyro y'), (arm+ 'Mean of Gyro z')])\n",
    "        sdDataFrame = pd.DataFrame(columns = [(arm+ 'Sd of Gyro x'), (arm+ 'Sd of Gyro y'), (arm+ 'Sd of Gyro z')])\n",
    "        rmsDataFrame = pd.DataFrame(columns = [(arm+ 'Rms of Gyro x'), (arm+ 'Rms of Gyro y'), (arm+ 'Rms of Gyro z')])\n",
    "        entropyDataFrame = pd.DataFrame(columns = [(arm+ 'Entropy of Gyro x'), (arm+ 'Entropy of Gyro y'), (arm+ 'Entropy of Gyro z')])\n",
    "        kurtosisDataFrame = pd.DataFrame(columns = [(arm+ 'Kurtosis of Gyro x'), (arm+ 'Kurtosis of Gyro y'), (arm+ 'Kurtosis of Gyro z')])\n",
    "        skewnessDataFrame = pd.DataFrame(columns = [(arm+ 'Skewness of Gyro x'), (arm+ 'Skewness of Gyro y'), (arm+ 'Skewness of Gyro z')])\n",
    "        smaDataFrame = pd.DataFrame(columns = [(arm+ 'SMA of Gyro')])\n",
    "        integrationDataFrame = pd.DataFrame(columns = [(arm+ 'Integration of Gyro x'), (arm+ 'Integration of Gyro y'), (arm+ 'Integration of Gyro z')])\n",
    "\n",
    "        \n",
    "        for df_normalized in listOfNormalizedGyroDataFramesPerClass[k]['gyro'][a]:\n",
    "            varianceDataFrame.loc[ctr] = [df_normalized.var()[1], df_normalized.var()[2], df_normalized.var()[3]]\n",
    "            mavDataFrame.loc[ctr] = [robust.mad(df_normalized)[1], robust.mad(df_normalized)[2], robust.mad(df_normalized)[3]]\n",
    "            meanDataFrame.loc[ctr] = [np.mean(df_normalized)[1], np.mean(df_normalized)[2], np.mean(df_normalized)[3]]\n",
    "            sdDataFrame.loc[ctr] = [np.std(df_normalized)[1], np.std(df_normalized)[2], np.std(df_normalized)[3]]\n",
    "            rmsDataFrame.loc[ctr] = [np.sqrt(np.mean(df_normalized[1].values**2)), np.sqrt(np.mean(df_normalized[2].values**2)), np.sqrt(np.mean(df_normalized[3].values**2))]\n",
    "            entropyDataFrame.loc[ctr] = [sp.stats.entropy(df_normalized)[1], sp.stats.entropy(df_normalized)[2], sp.stats.entropy(df_normalized)[3],]\n",
    "            kurtosisDataFrame.loc[ctr] = [df_normalized.kurtosis()[1], df_normalized.kurtosis()[2], df_normalized.kurtosis()[3]]\n",
    "            skewnessDataFrame.loc[ctr] = [df_normalized.skew(axis=0)[1], df_normalized.skew(axis=0)[2], df_normalized.skew(axis=0)[3]]\n",
    "            length = df_normalized.shape[1]\n",
    "            sma = 0\n",
    "            for x in range(0, length):\n",
    "                # .iloc[x,0] is Gyroessing row, column\n",
    "                sma += abs(df_normalized.iloc[x,1]) + df_normalized.iloc[x,2] + df_normalized.iloc[x,3]\n",
    "            sma = sma / length\n",
    "            smaDataFrame.loc[ctr] = [sma]\n",
    "            integrationDataFrame.loc[ctr] = [sp.integrate.simps(df_normalized, axis=0)[1],sp.integrate.simps(df_normalized, axis=0)[2], sp.integrate.simps(df_normalized, axis=0)[3]]\n",
    "\n",
    "            ctr +=1 \n",
    "            \n",
    "        print(len(varianceDataFrame))\n",
    "        listOfGyroVarianceDataFramePerClass[a].append(varianceDataFrame)\n",
    "        listOfGyroMavDataFramePerClass[a].append(mavDataFrame)\n",
    "        listOfGyroMeanDataFramePerClass[a].append(meanDataFrame)\n",
    "        listOfGyroSdDataFramePerClass[a].append(sdDataFrame)\n",
    "        listOfGyroRmsDataFramePerClass[a].append(rmsDataFrame)\n",
    "        listOfGyroEntropyDataFramePerClass[a].append(entropyDataFrame) \n",
    "        listOfGyroKurtosisDataFramePerClass[a].append(kurtosisDataFrame) \n",
    "        listOfGyroSkewnessDataFramePerClass[a].append(skewnessDataFrame) \n",
    "        listOfGyroSmaDataFramePerClass[a].append(smaDataFrame) \n",
    "        listOfGyroIntegrationDataFramePerClass[a].append(integrationDataFrame) \n",
    "        \n",
    "        print(\"Done computing Gyro features \" + str(ctr) + a + \" arm files\")\n",
    "        \n",
    "print(\"Done computing gyro features!!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(listOfMavDataFramePerClass[0])\n",
    "#print(listOfRmsDataFramePerClass[0])\n",
    "ctr = 0\n",
    "\n",
    "listOfLabeledAccDataPerClass = {}\n",
    "listOfLabeledAccDataPerClass['right'] = {}\n",
    "listOfLabeledAccDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfDataFramesPerClass[k]['acc']:\n",
    "\n",
    "    accDataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        accDataFramesPerFeature['variance'] = listOfAccVarianceDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['mav'] = listOfAccMavDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['rms'] = listOfAccRmsDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['sd'] = listOfAccSdDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['mean'] = listOfAccMeanDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['entropy'] = listOfAccEntropyDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['kurtosis'] = listOfAccKurtosisDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['skewness'] = listOfAccSkewnessDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['sma'] = listOfAccSmaDataFramePerClass[a][ctr]\n",
    "        accDataFramesPerFeature['integration'] = listOfAccIntegrationDataFramePerClass[a][ctr]\n",
    "\n",
    "        for k2 in accDataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in accDataFramesPerFeature[k2].columns:\n",
    "                    accDataFramesPerFeature['variance'][i] = accDataFramesPerFeature[k2][i]\n",
    "        \n",
    "        accDataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledAccDataPerClass[a][k] = accDataFramesPerFeature['variance']\n",
    "        print(\"Done labeling acc data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "\n",
    "listOfLabeledGyroDataPerClass = {}\n",
    "listOfLabeledGyroDataPerClass['right'] = {}\n",
    "listOfLabeledGyroDataPerClass['left'] = {}\n",
    "\n",
    "\n",
    "for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "\n",
    "    GyroDataFramesPerFeature = {}\n",
    "    ctr = 0\n",
    "    for k in listOfDataFramesPerClass.keys():\n",
    "        GyroDataFramesPerFeature['variance'] = listOfGyroVarianceDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['mav'] = listOfGyroMavDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['rms'] = listOfGyroRmsDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['sd'] = listOfGyroSdDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['mean'] = listOfGyroMeanDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['entropy'] = listOfGyroEntropyDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['kurtosis'] = listOfGyroKurtosisDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['skewness'] = listOfGyroSkewnessDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['sma'] = listOfGyroSmaDataFramePerClass[a][ctr]\n",
    "        GyroDataFramesPerFeature['integration'] = listOfGyroIntegrationDataFramePerClass[a][ctr]\n",
    "\n",
    "        for k2 in GyroDataFramesPerFeature.keys():\n",
    "            if k2 != 'variance':\n",
    "                for i in GyroDataFramesPerFeature[k2].columns:\n",
    "                    GyroDataFramesPerFeature['variance'][i] = GyroDataFramesPerFeature[k2][i]\n",
    "        \n",
    "        GyroDataFramesPerFeature['variance']['Class'] = k\n",
    "        listOfLabeledGyroDataPerClass[a][k] = GyroDataFramesPerFeature['variance']\n",
    "        print(\"Done labeling Gyro data of \" + k +\" \"+ a + \" arm files\")\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = listOfLabeledGyroDataPerClass['left']['ano']\n",
    "testPerClass = {}\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    #print(('%s %s') % (a, k))\n",
    "    testPerClass[k] = []\n",
    "    test = listOfLabeledGyroDataPerClass['left'][k]\n",
    "    for i in listOfLabeledGyroDataPerClass['right'][k]:\n",
    "        test[i] = listOfLabeledGyroDataPerClass['right'][k][i]\n",
    "    for i in listOfLabeledAccDataPerClass['left'][k].columns:\n",
    "        test[i] = listOfLabeledAccDataPerClass['left'][k][i]\n",
    "    for i in listOfLabeledAccDataPerClass['right'][k].columns:\n",
    "        test[i] = listOfLabeledAccDataPerClass['right'][k][i]\n",
    "    for i in listOfLabeledDataPerClass['left'][k].columns:\n",
    "        test[i] = listOfLabeledDataPerClass['left'][k][i]\n",
    "    for i in listOfLabeledDataPerClass['right'][k].columns:\n",
    "        test[i] = listOfLabeledDataPerClass['right'][k][i]                        #emg data\n",
    "    testPerClass[k] = test\n",
    "# test\n",
    "# test.to_csv('/Users/user/Desktop/test.csv', encoding='utf-8', index=False)\n",
    "newDf = testPerClass['ano']\n",
    "for k in listOfDataFramesPerClass.keys():\n",
    "    if k != 'ano':\n",
    "        print(k)\n",
    "        newDf= newDf.append(testPerClass[k]) \n",
    "\n",
    "df = newDf\n",
    "df = df[pd.notnull(df['left MeanFreq of EMG1'])]\n",
    "df = df[pd.notnull(df['right MeanFreq of EMG1'])]\n",
    "df = df[pd.notnull(df['left MeanFreq of EMG5'])]\n",
    "\n",
    "classNames = df[\"Class\"].tolist()\n",
    "\n",
    "\n",
    "df = df.drop(\"Class\", axis=1)\n",
    "\n",
    "x = df.values.astype(np.float64)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "df = pd.DataFrame(x_scaled,columns=df.columns)\n",
    "\n",
    "df[\"Class\"] = classNames\n",
    "\n",
    "df.to_csv('WithEmgFilter-Onearm.csv', encoding='utf-8', index=False)\n",
    "newDf.to_csv('WithEmgFilter-NoNormalization.csv', encoding='utf-8', index=False)\n",
    "#df.to_csv('ConsolidatedData-Normalized(Trimmed).csv', encoding='utf-8', index=False)\n",
    "#newDf.to_csv('ConsolidatedData-Original(Trimmed).csv', encoding='utf-8', index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ((-7.493890 - np.mean(newDf[\"left MeanFreq of EMG1\"]))/np.max(newDf[\"left MeanFreq of EMG1\"])-np.min(newDf[\"left MeanFreq of EMG1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mFreq = newDf[\"left MeanFreq of EMG1\"]\n",
    "# for i in mFreq:\n",
    "#     maxFreq = np.max(mFreq)\n",
    "#     minFreq = np.min(mFreq)\n",
    "#     meanFreq = np.mean(mFreq)\n",
    "    \n",
    "#     print(\"(%f - %f) / (%f - %f) = %f\" % (i, meanFreq, maxFreq, minFreq, (i-meanFreq)/(maxFreq-minFreq)))\n",
    "#     print((i - np.mean(mFreq))/(np.max(mFreq)-np.min(mFreq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classNames = newDf[\"Class\"].tolist()\n",
    "\n",
    "# df = newDf.drop(\"Class\", axis=1)\n",
    "# df = df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "# df[\"Class\"] = classNames\n",
    "\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('ConsolidatedData.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDf.to_csv('ConsolidatedData-Original.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.isnull().T.any().T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df[df.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDf[225:] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDf.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(newDf[\"left MeanFreq of EMG1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# rightMeanFreq1 = df[\"right MeanFreq of EMG1\"].tolist()\n",
    "# rightMeanFreq2 = df[\"right MeanFreq of EMG2\"].tolist()\n",
    "# rightMeanFreq3 = df[\"right MeanFreq of EMG3\"].tolist()\n",
    "# rightMeanFreq4 = df[\"right MeanFreq of EMG4\"].tolist()\n",
    "# rightMeanFreq5 = df[\"right MeanFreq of EMG5\"].tolist()\n",
    "# rightMeanFreq6 = df[\"right MeanFreq of EMG6\"].tolist()\n",
    "# rightMeanFreq7 = df[\"right MeanFreq of EMG7\"].tolist()\n",
    "# rightMeanFreq8 = df[\"right MeanFreq of EMG8\"].tolist()\n",
    "\n",
    "# leftMeanFreq1 = df[\"left MeanFreq of EMG1\"].tolist()\n",
    "# leftMeanFreq2 = df[\"left MeanFreq of EMG2\"].tolist()\n",
    "# leftMeanFreq3 = df[\"left MeanFreq of EMG3\"].tolist()\n",
    "# leftMeanFreq4 = df[\"left MeanFreq of EMG4\"].tolist()\n",
    "# leftMeanFreq5 = df[\"left MeanFreq of EMG5\"].tolist()\n",
    "# leftMeanFreq6 = df[\"left MeanFreq of EMG6\"].tolist()\n",
    "# leftMeanFreq7 = df[\"left MeanFreq of EMG7\"].tolist()\n",
    "# leftMeanFreq8 = df[\"left MeanFreq of EMG8\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "# df = df.drop(\"right MeanFreq of EMG1\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG2\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG3\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG4\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG5\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG6\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG7\", axis=1)\n",
    "# df = df.drop(\"right MeanFreq of EMG8\", axis=1)\n",
    "\n",
    "# df = df.drop(\"left MeanFreq of EMG1\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG2\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG3\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG4\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG5\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG6\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG7\", axis=1)\n",
    "# df = df.drop(\"left MeanFreq of EMG8\", axis=1)\n",
    "\n",
    "# df[\"right MeanFreq of EMG1\"] = rightMeanFreq1\n",
    "# df[\"right MeanFreq of EMG2\"] = rightMeanFreq2\n",
    "# df[\"right MeanFreq of EMG3\"] = rightMeanFreq3\n",
    "# df[\"right MeanFreq of EMG4\"] = rightMeanFreq4\n",
    "# df[\"right MeanFreq of EMG5\"] = rightMeanFreq5\n",
    "# df[\"right MeanFreq of EMG6\"] = rightMeanFreq6\n",
    "# df[\"right MeanFreq of EMG7\"] = rightMeanFreq7\n",
    "# df[\"right MeanFreq of EMG8\"] = rightMeanFreq8\n",
    "\n",
    "# df[\"left MeanFreq of EMG1\"] = leftMeanFreq1\n",
    "# df[\"left MeanFreq of EMG2\"] = leftMeanFreq2\n",
    "# df[\"left MeanFreq of EMG3\"] = leftMeanFreq3\n",
    "# df[\"left MeanFreq of EMG4\"] = leftMeanFreq4\n",
    "# df[\"left MeanFreq of EMG5\"] = leftMeanFreq5\n",
    "# df[\"left MeanFreq of EMG6\"] = leftMeanFreq6\n",
    "# df[\"left MeanFreq of EMG7\"] = leftMeanFreq7\n",
    "# df[\"left MeanFreq of EMG8\"] = leftMeanFreq8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "    \n",
    "\n",
    "\n",
    "# for k2 in GyroDataFramesPerFeature.keys():\n",
    "#     for i in GyroDataFramesPerFeature[k2].columns:\n",
    "#         dataFramesPerFeature['variance'][i] = GyroDataFramesPerFeature[k2][i]\n",
    "            \n",
    "# for k2 in accDataFramesPerFeature.keys():\n",
    "#     for i in accDataFramesPerFeature[k2].columns:\n",
    "#         dataFramesPerFeature['variance'][i] = accDataFramesPerFeature[k2][i]\n",
    "\n",
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "#     newDf = listOfLabeledAccDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledAccDataPerClass[a][k])\n",
    "# dataFramesPerFeature.to_csv('/Users/user/Desktop/test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Consolidation (save to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedAccDataFramesPerClass[k]['acc']:\n",
    "#     newDf = listOfLabeledAccDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedAccDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledAccDataPerClass[a][k])\n",
    "    \n",
    "    \n",
    "#     newDf.to_csv('/Users/user/Desktop/'+ a +'ArmConsolidatedAcc.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a in listOfNormalizedGyroDataFramesPerClass[k]['gyro']:\n",
    "#     newDf = listOfLabeledGyroDataPerClass[a]['ano']\n",
    "#     for k in listOfTrimmedGyroDataFramesPerClass.keys():\n",
    "#         if k != 'ano':\n",
    "#             print(k)\n",
    "#             newDf= newDf.append(listOfLabeledGyroDataPerClass[a][k])\n",
    "    \n",
    "    \n",
    "#     newDf.to_csv('/Users/user/Desktop/'+ a +'ArmConsolidatedGyro.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
